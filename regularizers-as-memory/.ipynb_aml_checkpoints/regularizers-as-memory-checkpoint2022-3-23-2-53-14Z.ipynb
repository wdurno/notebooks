{
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# Regularizers as memory\n",
        "\n",
        "The greatest challenge in modern AI research is the limiting returns computational work. \n",
        "While the greatest advances can only be afforded by large technology firms, even they \n",
        "cannot afford to push results further. A clear plateau has developed. \n",
        "Insufficient computational efficiency motivates a return to theory, begs a question: \n",
        "_where is waste most significant?_ \n",
        "\n",
        "The advent of catestrophic forgetting shows raw, non-compressed information must be continually re-applied \n",
        "if it is not to be forgotten. If important information could be preserved--even partially--we would expect \n",
        "more efficient computation. In short, _this work targets the realization of memory_.\n",
        "\n",
        "Regularized likelihood equations have a Lagrangian form, so implicitly describe geometric constraints on estimates.\n",
        "For example, here's an estimate constrained to an L2-sphere in $\\Theta$-space.\n",
        "\n",
        "$$ \\hat \\theta_{L_2} = \\text{arg max}_{\\theta \\in \\Theta} n^{-1} \\sum_{i=1}^n \\log f_X(X_i;\\theta) - \\lambda \\| \\theta \\|_2^2 $$\n",
        "\n",
        "In this work, we'll generalize the regularizer $\\| \\cdot \\|_2^2$ to support alternative geometries, \n",
        "in attempting to construct numerically convenient memory approximations. \n",
        "Particulary, we'll seek to approximate the following equation.\n",
        "Note that it introduces quadratic geometric constraints on the estimate. \n",
        "\n",
        "$$ \\hat \\theta = \\text{arg max}_{\\theta \\in \\Theta} n^{-1} \\sum_{i=1}^n \\log f_X(X_i;\\theta) - \\frac{\\lambda}{2} (\\theta - \\theta_0)^T \\mathcal{I}_{\\theta_0} (\\theta - \\theta_0) $$"
      ],
      "metadata": {
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## RL-reweighted (RLR) estimates \n",
        "\n",
        "This first estimate is designed to improve efficiency of sampling in reinforcement learning (RL) by \n",
        "up-weighting more-important observations. We'll use this estimate:\n",
        "\n",
        "$$ \\hat \\theta_{RLR} = \\hat \\theta_{n_1+n_2} = \\text{arg max}_\\theta \\left( \\sum_{i=1}^{n_1+n_2} \\| \\hat r_i \\|_2^{2b} \\right)^{-1} \\left( \\sum_{i=n_1+1}^{n_1+n_2} \\| \\hat r_i \\|_2^{2b} \\log f_X(X_i; \\theta) - \\sum_{i=1}^{n_1} \\frac{\\lambda}{2} (\\theta - \\hat \\theta_{n_1+n_2-1})^T H_i (\\theta - \\hat \\theta_{n_1+n_2-1}) \\right) $$\n",
        "\n",
        "where \n",
        "- $n_1$ is the number of priviously observed sameples, \n",
        "- $n_2$ is the number of newly observed samples, \n",
        "- $\\hat r_i$ is the estimated reward for observation $i$, \n",
        "- $b > 0$ is a bias term,  \n",
        "- $H_i = \\| \\hat r_i \\|^{2b}_2 \\left( \\nabla_\\theta \\log f_X(X_j; \\theta)|_{\\theta = \\hat \\theta_{j-1}} \\right) \\left( \\nabla_\\theta \\log f_X(X_j; \\theta)|_{\\theta = \\hat \\theta_{j-1}} \\right)^T$ is a Hessian approximation, and\n",
        "- $\\hat \\theta_0$ is an initial estimate guess, commonly required in optimization routines. \n",
        "\n",
        "Define $ M:= \\sum_{i=1}^{n_1}(\\theta - \\theta_{n_1+n_2-1})^TH_i(\\theta - \\theta_{n_1+n_2-1})$, which we'll refer to as the \"memory term\". \n",
        "The key heuristic is that $M$, a quadratic regularizer, approximates large-sample likelihoods under maximization. \n",
        "This insight can be seen through a Taylor approximation near true $\\theta$, designated $\\theta_T$.\n",
        "\n",
        "$\\hat \\theta_{MLE} = \\text{arg max}_\\theta n^{-1} \\sum_{i=1}^n \\log f_X(X_i;\\theta) $\n",
        "\n",
        "$ \\approx \\text{arg max}_\\theta n^{-1}\\sum_i \\log f_X(X_i; \\theta_T) + n^{-1}\\sum_i (\\theta - \\theta_T)^T \\nabla_\\theta \\log f_X(X_i; \\theta_T) + n^{-1}2^{-1} \\sum_i (\\theta - \\theta_T)^T (\\nabla_\\theta^2 \\log f_X(X_i; \\theta_T))(\\theta - \\theta_T) $\n",
        "\n",
        "$ \\approx \\text{arg max}_\\theta n^{-1}\\sum_i \\log f_X(X_i; \\theta_T) + 0 + n^{-1}2^{-1} \\sum_i (\\theta - \\theta_T)^T (\\nabla_\\theta^2 \\log f_X(X_i; \\theta_T))(\\theta - \\theta_T) $\n",
        "\n",
        "$ \\approx \\text{arg max}_\\theta n^{-1}2^{-1} \\sum_i (\\theta - \\theta_T)^T (\\nabla_\\theta^2 \\log f_X(X_i; \\theta_T))(\\theta - \\theta_T) $\n",
        "\n",
        "This work basically tests the quality of our $M \\approx \\sum_i (\\theta - \\theta_T)^T (\\nabla_\\theta)^2 \\log f_X(X_i; \\theta_T)(\\theta - \\theta_T) $ heuristic.\n",
        "If true, then we should see that the quadratic regularizer, $M$, affects memory through geometric constraints on the estimator.\n",
        "\n",
        "Later, we'll experiment with recency bias and rank reductions for $M$.\n",
        "\n",
        "Notice that $\\hat \\theta_{RLR}$ is asymptotically equivalent to a redistributed sampling, \n",
        "with more observations when they are more important. \n",
        "Hence, the essence of this computational efficiency strategy is to \n",
        "- add frequency bias to important observations, \n",
        "- and preserve their information via geometric estimator constraints."
      ],
      "metadata": {
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## $M$ and almost-stationary processes\r\n",
        "\r\n",
        "$M$ is an asymptotic result, so only applies when observations are sufficiently many and produced by a stationary or i.i.d process.\r\n",
        "While most applied asymptotic theory assumes $\\theta_T$ is static, it could also be possible to work with a $\\theta_{T_n}$ on a continuous path in $\\Theta$ over $n$.\r\n",
        "Let us define an _almost-stationary process_ $X_n$ as satisfying the following.\r\n",
        "\r\n",
        "$$ \\forall \\tau \\in \\mathbb{R}, \\left(t_1, t_2, \\ldots, t_m\\right) \\in \\mathbb{R}_{\\geq 0}^m, \\mathbb{P}\\left[ X_{t_{1+\\tau}}, X_{t_{2+\\tau}}, \\ldots, X_{t_{m+\\tau}} ; \\theta_{t_1+\\tau} \\right] \\text{is continuous in } \\tau$$\r\n",
        "\r\n",
        "The question of whether $\\theta_{T_n}$ moves \"too quickly\" is dependent on an given process. \r\n",
        "If, for $n$ large, $M$ still approximates $\\sum_i (\\theta - \\theta_{T_n})^T (\\nabla_\\theta^2 \\log f_X(X_i; \\theta_{T_n}))(\\theta - \\theta_{T_n})$, \r\n",
        "then we'll say $\\theta_{T_n}$ is \"sufficiently slow\". Here are some examples relating to **transfer learning**.\r\n",
        "- If we withheld digits 1 & 2 from MNIST for the first 10000 observations, then started including them afterward, \r\n",
        "we should expect $\\theta_{T_n}$ to move too quickly. \r\n",
        "- As reinforcement learning (RL) agent explores its world, it's sampling process indeed deforms, albeit slowly. \r\n",
        "This context should have good opportunities for sufficiently slow changes in $\\theta_{T_n}$. \r\n",
        "So, our experiments will focus on RL applications.\r\n",
        "\r\n",
        "Developing transfer learning mechanisms for RL is particularly valuable, \r\n",
        "since it is frequently imagined to be a path to artificial general intelligence (AGI).\r\n",
        "\r\n",
        "Side node: almost-stationary process theory clearly needs development. \r\n",
        "My experience has taught me to test the value of theoretical hypotheses before developing them, \r\n",
        "since theoretical development is far more expensive than computational experimentation.\r\n",
        "I am confident in this hypothesis, because my previous theoretical developments are very similar. \r\n",
        "Any new proofs would not be very novel, and would be mere adaptations of prior work. "
      ],
      "metadata": {
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Experiment 1: Cartpole\r\n",
        "\r\n",
        "We start with a _very_ simple example, proving-out concepts."
      ],
      "metadata": {
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "## Define model \n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import torch.optim as optim\n",
        "import random \n",
        "import gym \n",
        "from tqdm import tqdm \n",
        "import numpy as np \n",
        "import matplotlib.pyplot as plt \n",
        "import copy \n",
        "\n",
        "INPUT_DIM = 4\n",
        "N_ACTIONS = 2\n",
        "MAX_SAMPLE = 100000\n",
        "DISCOUNT = .95 \n",
        "EPS = 1e-5\n",
        "EXPLORE_PROBABILITY_FUNC = lambda idx: 0.99**idx \n",
        "BATCH_SIZE = 30 \n",
        "LEARNING_RATE = 0.001 \n",
        "GRAD_CLIP = 10.0 \n",
        "SHORT_TERM_MEMORY_LENGTH = 3 \n",
        "LBFGS = False \n",
        "ENV_NAME = 'CartPole-v1' \n",
        "\n",
        "class Model(nn.Module): \n",
        "    def __init__(self, \n",
        "            input_dim=INPUT_DIM, \n",
        "            n_actions=N_ACTIONS, \n",
        "            max_sample=MAX_SAMPLE, \n",
        "            discount = DISCOUNT, \n",
        "            eps=EPS, \n",
        "            explore_probability_func=EXPLORE_PROBABILITY_FUNC, \n",
        "            batch_size=BATCH_SIZE, \n",
        "            learning_rate=LEARNING_RATE, \n",
        "            grad_clip=GRAD_CLIP, \n",
        "            short_term_memory_length=SHORT_TERM_MEMORY_LENGTH, \n",
        "            lbfgs=LBFGS, \n",
        "            env_name=ENV_NAME): \n",
        "        super(Model, self).__init__() \n",
        "        ## store config \n",
        "        self.input_dim = input_dim \n",
        "        self.n_actions = n_actions \n",
        "        self.max_sample = max_sample \n",
        "        self.discount = discount \n",
        "        self.eps = eps \n",
        "        self.explore_probability_func = explore_probability_func \n",
        "        self.batch_size = batch_size \n",
        "        self.learning_rate = learning_rate \n",
        "        self.grad_clip = grad_clip \n",
        "        self.short_term_memory_length = short_term_memory_length \n",
        "        self.lbfgs = lbfgs \n",
        "        self.env_name = env_name \n",
        "        ## init feed forward net \n",
        "        self.fc1 = nn.Linear(input_dim * short_term_memory_length, 32) \n",
        "        self.fc1_bn = nn.BatchNorm1d(32) \n",
        "        self.fc2 = nn.Linear(32, 32) \n",
        "        self.fc2_bn = nn.BatchNorm1d(32) \n",
        "        self.fc3 = nn.Linear(32, n_actions) \n",
        "        ## init data structures \n",
        "        self.observations = [] \n",
        "        self.env = None \n",
        "        if self.lbfgs: \n",
        "            ## Misbehavior observed with large `history_size`, ie. >20 \n",
        "            ## RAM req = O(history_size * model_dim) \n",
        "            self.optimizer = optim.LBFGS(self.parameters(), history_size=5) \n",
        "        else: \n",
        "            ## LBFGS was giving nan parameters \n",
        "            self.optimizer = optim.Adam(self.parameters(), lr=self.learning_rate) \n",
        "            pass \n",
        "        pass \n",
        "    \n",
        "    def copy(self): \n",
        "        out = Model(input_dim=self.input_dim, \n",
        "                n_actions=self.n_actions, \n",
        "                max_sample=self.max_sample, \n",
        "                discount=self.discount, \n",
        "                eps=self.eps, \n",
        "                explore_probability_func=self.explore_probability_func, \n",
        "                batch_size=self.batch_size, \n",
        "                learning_rate=self.learning_rate, \n",
        "                grad_clip=self.grad_clip, \n",
        "                short_term_memory_length=self.short_term_memory_length, \n",
        "                lbfgs=self.lbfgs) \n",
        "        out.load_state_dict(self.state_dict()) \n",
        "        return out \n",
        "\n",
        "    def forward(self, x): \n",
        "        x = x.reshape([-1, self.input_dim * self.short_term_memory_length]) \n",
        "        x = self.fc1(x)\n",
        "        x = self.fc1_bn(x) \n",
        "        x = torch.relu(x) \n",
        "        x = self.fc2(x) \n",
        "        x = self.fc2_bn(x)  \n",
        "        x = torch.relu(x) \n",
        "        x = self.fc3(x) \n",
        "        x = x*x \n",
        "        return x \n",
        "    \n",
        "    def get_action(self, env_state): \n",
        "        env_state = torch.tensor(env_state).float() \n",
        "        env_state = env_state.reshape([1, -1]) \n",
        "        predicted_reward_per_action_idx = self.forward(env_state) \n",
        "        return int(predicted_reward_per_action_idx.argmax()) \n",
        "    \n",
        "    def store_observation(self, observation): \n",
        "        if len(observation) > self.max_sample: \n",
        "            observation = observation[1:] \n",
        "        self.observations.append(observation) \n",
        "        pass \n",
        "    \n",
        "    def clear_observations(self): \n",
        "        self.observations = [] \n",
        "        pass \n",
        "\n",
        "    def convert_observations_to_memory(self): \n",
        "        ## convert current observations to a Hessian matrix\n",
        "        ## TODO implement and try this \n",
        "        pass \n",
        "    \n",
        "    def __memory_replay(self, target_model, batch_size=None, fit=True): \n",
        "        ## random sample \n",
        "        obs = self.observations \n",
        "        if batch_size is not None: \n",
        "            if batch_size < len(self.observations): \n",
        "                obs = random.sample(self.observations, batch_size) \n",
        "        ## unpack samples \n",
        "        samples = [(torch.tensor(env_state).float(), \\\n",
        "                torch.tensor(reward).float(), \\\n",
        "                torch.tensor(done).int(), \\\n",
        "                torch.tensor(prev_env_state).float(), \\\n",
        "                torch.tensor(action).int()) for \\\n",
        "                (env_state, reward, done, info, prev_env_state, action) in obs] \n",
        "        ## build matrices \n",
        "        env_state = torch.stack([obs[0] for obs in samples], dim=0) ## inserts dim 0 \n",
        "        observed_rewards = torch.stack([obs[1] for obs in samples], dim=0) \n",
        "        done = torch.stack([obs[2] for obs in samples], dim=0) \n",
        "        prev_env_state = torch.stack([obs[3] for obs in samples], dim=0) \n",
        "        action = torch.stack([obs[4] for obs in samples], dim=0).reshape([-1, 1]).type(torch.int64) \n",
        "        ## calculate target \n",
        "        with torch.no_grad(): \n",
        "            predicted_rewards = target_model.forward(env_state) \n",
        "            predicted_rewards = torch.max(predicted_rewards, dim=1, keepdim=True).values.reshape([-1]) \n",
        "            target = observed_rewards + (1 - done) * self.discount * predicted_rewards \n",
        "            target = target.reshape([-1, 1]).detach() \n",
        "            pass \n",
        "        ## calculate prediction \n",
        "        self.zero_grad() \n",
        "        if fit: \n",
        "            self.train() \n",
        "        else:\n",
        "            self.eval() \n",
        "        predicted_rewards = self.forward(prev_env_state) \n",
        "        prediction = predicted_rewards.gather(1, action) \n",
        "        return prediction, target \n",
        "    \n",
        "    def get_parameter_vector(self): \n",
        "        return nn.utils.parameters_to_vector(self.parameters()) \n",
        "    \n",
        "    def optimize(self, max_iter=None, batch_size=None): \n",
        "        iter_n = 0 \n",
        "        n_dels = 30 \n",
        "        dels = [None]*n_dels \n",
        "        continue_iterating = True \n",
        "        halt_method = None \n",
        "        loss_f = None \n",
        "        mean_reward = None \n",
        "        target_model = self.copy() \n",
        "        target_model.eval() \n",
        "        while continue_iterating: \n",
        "            prev_theta = self.get_parameter_vector() \n",
        "            predicted, target = self.__memory_replay(target_model=target_model, batch_size=batch_size) \n",
        "            mean_reward = predicted.mean() \n",
        "            #loss = F.mse_loss(predicted, target) \n",
        "            loss = F.smooth_l1_loss(predicted, target) \n",
        "            loss_f = float(loss) \n",
        "            loss.backward() \n",
        "            if not self.lbfgs: \n",
        "                ## lbfgs really doesn't like this \n",
        "                nn.utils.clip_grad_norm_(model.parameters(), self.grad_clip) \n",
        "            ## lbfgs must re-evaluate target, hence lambda \n",
        "            if self.lbfgs:\n",
        "                self.optimizer.step(lambda: float(F.smooth_l1_loss(predicted, target))) \n",
        "            else:\n",
        "                self.optimizer.step() \n",
        "                pass \n",
        "            updated_theta = self.get_parameter_vector() \n",
        "            ## decide to continue iterating or not \n",
        "            if max_iter is not None: \n",
        "                if iter_n > max_iter: \n",
        "                    ## halt: iters have hit limit \n",
        "                    continue_iterating = False \n",
        "                    halt_method = 'max-iter' \n",
        "            if iter_n >= n_dels: \n",
        "                ## test convergence with chebyshev ineq \n",
        "                dels = dels[1:] + [(updated_theta - prev_theta).abs().sum()] \n",
        "                sigma = torch.tensor(dels).square().mean().sqrt() \n",
        "                if (sigma/self.eps)**2 < .95: \n",
        "                    ## halt: convergance \n",
        "                    continue_iterating = False \n",
        "                    halt_method = 'cauchy-convergence' \n",
        "            else: \n",
        "                ## collect data for variance estimate \n",
        "                dels[iter_n] = (updated_theta - prev_theta).abs().sum() \n",
        "                pass \n",
        "            iter_n += 1 \n",
        "            pass \n",
        "        return loss_f, halt_method, mean_reward  \n",
        "    \n",
        "    def simulate(self, fit=True, total_iters=10000, plot_rewards=True, plot_prob_func=True): \n",
        "        if plot_prob_func:\n",
        "            plt.plot([self.explore_probability_func(idx) for idx in range(total_iters)]) \n",
        "            plt.show()\n",
        "            pass \n",
        "        env = gym.make(self.env_name) \n",
        "        env_state = env.reset() \n",
        "        env_state_list = [torch.tensor(env_state) for _ in range(self.short_term_memory_length)] \n",
        "        env_state = torch.cat(env_state_list) \n",
        "        last_start = 0 \n",
        "        last_total_reward = 0 \n",
        "        n_restarts = 0 \n",
        "        self.total_rewards = [] \n",
        "        ## run experiment \n",
        "        iters = tqdm(range(total_iters), disable=False) \n",
        "        for iter_idx in iters: \n",
        "            prev_env_state = env_state \n",
        "            if self.explore_probability_func(iter_idx) > np.random.uniform(): ## TODO move to get_action \n",
        "                ## explore \n",
        "                action = env.action_space.sample()\n",
        "            else: \n",
        "                ## exploit \n",
        "                self.eval() \n",
        "                action = self.get_action(env_state) \n",
        "                pass \n",
        "            env_state, reward, done, info = env.step(action) \n",
        "            env_state_list = env_state_list[1:] + [torch.tensor(env_state)] \n",
        "            env_state = torch.cat(env_state_list) \n",
        "            if done: \n",
        "                reward = 0 \n",
        "                pass \n",
        "            last_total_reward += reward \n",
        "            observation = env_state, reward, done, info, prev_env_state, action \n",
        "            self.store_observation(observation) \n",
        "\n",
        "            if iter_idx > 30 and iter_idx % 1 == 0: \n",
        "                loss, halt_method, mean_reward = self.optimize(max_iter=1, batch_size=self.batch_size) \n",
        "                loss = float(loss) \n",
        "                mean_reward = float(mean_reward) \n",
        "                param_nan = self.get_parameter_vector().isnan().sum() \n",
        "                iters.set_description(f'n_restarts: {n_restarts}, last_total_reward: {last_total_reward}, '+\\\n",
        "                    f'loss: {round(loss,4)}, halt: {halt_method}, mean_reward: {round(mean_reward,2)}, action: {action}') \n",
        "                pass \n",
        "\n",
        "            if done: \n",
        "                env_state = env.reset() \n",
        "                env_state_list = [torch.tensor(env_state) for _ in range(self.short_term_memory_length)] \n",
        "                env_state = torch.cat(env_state_list) \n",
        "                self.total_rewards.append(last_total_reward) \n",
        "                last_total_reward = 0 \n",
        "                n_restarts += 1 \n",
        "                pass \n",
        "            pass \n",
        "        env.close() \n",
        "\n",
        "        if plot_rewards: \n",
        "            plt.plot(self.total_rewards) \n",
        "            plt.show()\n",
        "        pass "
      ],
      "outputs": [],
      "execution_count": 1,
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "gather": {
          "logged": 1650682143688
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model = Model() \r\n",
        "model.simulate(total_iters=10000, plot_prob_func=False) "
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": "  0%|          | 0/10000 [00:00<?, ?it/s]/anaconda/envs/azureml_py36/lib/python3.6/site-packages/ipykernel_launcher.py:101: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n/anaconda/envs/azureml_py36/lib/python3.6/site-packages/ipykernel_launcher.py:133: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\nn_restarts: 174, last_total_reward: 1.0, loss: 0.6924, halt: max-iter, mean_reward: 21.7, action: 1: 100%|██████████| 10000/10000 [02:27<00:00, 67.95it/s]  \n"
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": "<Figure size 432x288 with 1 Axes>",
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ],
      "execution_count": 2,
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "gather": {
          "logged": 1650682291221
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "## \r\n",
        "t = model.get_parameter_vector()\r\n",
        "t"
      ],
      "outputs": [
        {
          "output_type": "execute_result",
          "execution_count": 3,
          "data": {
            "text/plain": "tensor([-0.3399, -0.2543, -0.6376,  ..., -0.0989,  0.6687, -0.6901],\n       grad_fn=<CatBackward>)"
          },
          "metadata": {}
        }
      ],
      "execution_count": 3,
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "gather": {
          "logged": 1650682291280
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "predicted, target = model._Model__memory_replay(target_model=model, batch_size=1, fit=False) \n",
        "loss = F.smooth_l1_loss(predicted, target) \n",
        "loss.backward() \n",
        "grad_vec = torch.cat([p.grad.reshape([-1]) for p in model.parameters()]) \n",
        "grad_vec.shape"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": "/anaconda/envs/azureml_py36/lib/python3.6/site-packages/ipykernel_launcher.py:133: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n"
        },
        {
          "output_type": "error",
          "ename": "ValueError",
          "evalue": "Expected more than 1 value per channel when training, got input size torch.Size([1, 32])",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-4-2e9fc025e5b8>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mpredicted\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_Model__memory_replay\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtarget_model\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfit\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mF\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msmooth_l1_loss\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpredicted\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mgrad_vec\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgrad\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreshape\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mp\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mparameters\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mgrad_vec\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-1-70baa4f01a62>\u001b[0m in \u001b[0;36m__memory_replay\u001b[0;34m(self, target_model, batch_size, fit)\u001b[0m\n\u001b[1;32m    140\u001b[0m         \u001b[0;31m## calculate target\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    141\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mno_grad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 142\u001b[0;31m             \u001b[0mpredicted_rewards\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtarget_model\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0menv_state\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    143\u001b[0m             \u001b[0mpredicted_rewards\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmax\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpredicted_rewards\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdim\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkeepdim\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreshape\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    144\u001b[0m             \u001b[0mtarget\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mobserved_rewards\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mdone\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdiscount\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mpredicted_rewards\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-1-70baa4f01a62>\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m     89\u001b[0m         \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreshape\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minput_dim\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshort_term_memory_length\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     90\u001b[0m         \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfc1\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 91\u001b[0;31m         \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfc1_bn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     92\u001b[0m         \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrelu\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     93\u001b[0m         \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfc2\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/anaconda/envs/azureml_py36/lib/python3.6/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1049\u001b[0m         if not (self._backward_hooks or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks\n\u001b[1;32m   1050\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1051\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1052\u001b[0m         \u001b[0;31m# Do not call functions when jit is used\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1053\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/anaconda/envs/azureml_py36/lib/python3.6/site-packages/torch/nn/modules/batchnorm.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    176\u001b[0m             \u001b[0mbn_training\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    177\u001b[0m             \u001b[0mexponential_average_factor\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 178\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0meps\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    179\u001b[0m         )\n\u001b[1;32m    180\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/anaconda/envs/azureml_py36/lib/python3.6/site-packages/torch/nn/functional.py\u001b[0m in \u001b[0;36mbatch_norm\u001b[0;34m(input, running_mean, running_var, weight, bias, training, momentum, eps)\u001b[0m\n\u001b[1;32m   2277\u001b[0m         )\n\u001b[1;32m   2278\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mtraining\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2279\u001b[0;31m         \u001b[0m_verify_batch_size\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2280\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2281\u001b[0m     return torch.batch_norm(\n",
            "\u001b[0;32m/anaconda/envs/azureml_py36/lib/python3.6/site-packages/torch/nn/functional.py\u001b[0m in \u001b[0;36m_verify_batch_size\u001b[0;34m(size)\u001b[0m\n\u001b[1;32m   2245\u001b[0m         \u001b[0msize_prods\u001b[0m \u001b[0;34m*=\u001b[0m \u001b[0msize\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;36m2\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2246\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0msize_prods\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2247\u001b[0;31m         \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Expected more than 1 value per channel when training, got input size {}\"\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msize\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2248\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2249\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mValueError\u001b[0m: Expected more than 1 value per channel when training, got input size torch.Size([1, 32])"
          ]
        }
      ],
      "execution_count": 4,
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "gather": {
          "logged": 1650682291353
        }
      }
    }
  ],
  "metadata": {
    "kernelspec": {
      "name": "python3-azureml",
      "language": "python",
      "display_name": "Python 3.6 - AzureML"
    },
    "language_info": {
      "name": "python",
      "version": "3.6.9",
      "mimetype": "text/x-python",
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "pygments_lexer": "ipython3",
      "nbconvert_exporter": "python",
      "file_extension": ".py"
    },
    "nteract": {
      "version": "nteract-front-end@1.0.0"
    },
    "kernel_info": {
      "name": "python3-azureml"
    },
    "microsoft": {
      "host": {
        "AzureML": {
          "notebookHasBeenCompleted": true
        }
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 2
}