{
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# online nets\r\n",
        "\r\n",
        "Deep learning is powerful but computationally expensive, frequently requiring massive compute budgets. In persuit of cost-effective-yet-powerful AI, this work explores and evaluates a heuristic which should lend to more-efficient use of data through online learning.\r\n",
        "\r\n",
        "Goal: evaluate a deep learning alternative capable of true online learning. Solution requirements:\r\n",
        "\r\n",
        "1. catastrophic forgetting should be impossible;\r\n",
        "2. all data is integrated into sufficient statistics of fixed dimension;\r\n",
        "3. and our solution should have predictive power comparable to deep learning.\r\n",
        "\r\n",
        "## modeling strategy\r\n",
        "\r\n",
        "We will not attempt to derive sufficient statistics for an entire deep net, but instead leverage well-known sufficient statistics for least squares models, \r\n",
        "so will have sufficient statistics per deep net layer. If this can be empirically shown effective, we'll build-out the theory afterwards. \r\n",
        "\r\n",
        "Recognizing a deep net as a series of compositions, as follows.\r\n",
        "\r\n",
        "$ Y + \\varepsilon \\approx \\mathbb{E}Y = \\sigma_3 \\circ \\beta_3^T \\circ \\sigma_2 \\circ \\beta_2^T \\circ \\sigma_1 \\circ \\beta_1^T X $\r\n",
        "\r\n",
        "So, we can isolate invidivdual $\\beta_j$ matrices using (psuedo-)inverses $\\beta_j^{-1}$ like so.\r\n",
        "\r\n",
        "$ \\sigma_2^{-1} \\circ \\beta_3^{-1} \\circ \\sigma_3^{-1} (Y) \\approx  \\beta_2^T \\circ \\sigma_1 \\circ \\beta_1^T X $\r\n",
        "\r\n",
        "In this example, if we freeze all $\\beta_j$'s except $\\beta_2$, we are free to update $\\hat \\beta_2$ using $\\tilde Y = \\sigma_2^{-1} \\circ \\beta_3^{-1} \\circ \\sigma_3^{-1} (Y) $\r\n",
        "and $\\tilde X = \\sigma_1 \\circ \\beta_1^T X $.\r\n",
        "\r\n",
        "Using a least squares formulation for fitting to $\\left( \\tilde X, \\tilde Y \\right)$, we get sufficient statistics per layer."
      ],
      "metadata": {
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# model code definitions"
      ],
      "metadata": {
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "\n",
        "TORCH_TENSOR_TYPE = type(torch.tensor(1)) \n",
        "\n",
        "def iterated_diagonals(diag_value, n_rows, n_cols): \n",
        "    ## construct diagonal matrix \n",
        "    n_diag = min(n_rows, n_cols)\n",
        "    diag = torch.diag(torch.tensor([diag_value]*n_diag))\n",
        "    if n_rows > n_cols: \n",
        "        ## pad rows \n",
        "        pad = n_rows//n_cols + 1\n",
        "        return torch.cat([diag]*pad, 0)[:n_rows, :n_cols] \n",
        "    if n_cols > n_rows: \n",
        "        ## pad cols \n",
        "        pad = n_cols//n_rows + 1 \n",
        "        return torch.cat([diag]*pad, 1)[:n_rows, :n_cols] \n",
        "    ## no padding \n",
        "    return diag \n",
        "\n",
        "class OnlineDenseLayer: \n",
        "    ''' \n",
        "    A single dense net, formulated as a least squares model. \n",
        "    ''' \n",
        "    def __init__(self, p, q, activation=lambda x:x, activation_inverse=lambda x:x, lam=1., clip=10000., dlamdn=0.): \n",
        "        ''' \n",
        "        inputs: \n",
        "        - p: input dimension \n",
        "        - q: output dimension \n",
        "        - activation: non-linear function, from R^p to R^q. Default is identity. \n",
        "        - activation_inverse: inverse of the activation function. Default is identity. \n",
        "        - lam: regularization term \n",
        "        - clip: predicted value clipping limit \n",
        "        - dlamdn: rate of lambda growth relative to n for online regularization \n",
        "        ''' \n",
        "        lam = float(lam) \n",
        "        clip = float(clip) \n",
        "        if dlamdn is not None: \n",
        "            dlamdn = float(dlamdn)\n",
        "        self.__validate_inputs(p=p, q=q, lam=lam, clip=clip, dlamdn=dlamdn) \n",
        "        self.p = p \n",
        "        self.q = q \n",
        "        self.n_fits = 0 \n",
        "        self.clip = clip \n",
        "        self.trainable = True \n",
        "        self.activation = activation \n",
        "        self.activation_inverse = activation_inverse \n",
        "        self.batch_norm_forward_mean = None \n",
        "        self.batch_norm_forward_std = None \n",
        "        self.batch_norm_forward_n = 0 \n",
        "        self.batch_norm_backward_mean = None \n",
        "        self.batch_norm_backward_std = None \n",
        "        self.batch_norm_backward_n = 0 \n",
        "        self.lam = lam \n",
        "        self.dlamdn = dlamdn \n",
        "        self.xTy = iterated_diagonals(lam, p+1,q) # +1 for intercept \n",
        "        self.yTx = iterated_diagonals(lam, q+1,p) \n",
        "        self.xTx_inv = torch.diag(torch.tensor([1./lam]*(p+1))) \n",
        "        self.yTy_inv = torch.diag(torch.tensor([1./lam]*(q+1))) \n",
        "        self.xTy_temp = None \n",
        "        self.yTx_temp = None \n",
        "        self.xTx_inv_temp = None \n",
        "        self.yTy_inv_temp = None \n",
        "        self.betaT_forward = torch.matmul(self.xTx_inv, self.xTy) \n",
        "        self.betaT_forward = torch.transpose(self.betaT_forward, 0, 1) \n",
        "        self.betaT_backward = torch.matmul(self.yTy_inv, self.yTx) \n",
        "        self.betaT_backward = torch.transpose(self.betaT_backward, 0, 1) \n",
        "        self.x_forward = None \n",
        "        self.y_forward = None \n",
        "        self.x_backward = None \n",
        "        self.y_backward = None \n",
        "        pass \n",
        "    def copy(self): \n",
        "        copied_layer = OnlineDenseLayer(self.p, self.q)\n",
        "        copied_layer.p = self.p \n",
        "        copied_layer.q = self.q \n",
        "        copied_layer.n_fits = self.n_fits \n",
        "        copied_layer.clip = self.clip \n",
        "        copied_layer.trainable = self.trainable \n",
        "        copied_layer.activation = self.activation \n",
        "        copied_layer.activation_inverse = self.activation_inverse \n",
        "        copied_layer.batch_norm_forward_mean = self.batch_norm_forward_mean \n",
        "        copied_layer.batch_norm_forward_std = self.batch_norm_forward_std \n",
        "        copied_layer.batch_norm_forward_n = self.batch_norm_forward_n \n",
        "        copied_layer.batch_norm_backward_mean = self.batch_norm_backward_mean \n",
        "        copied_layer.batch_norm_backward_std = self.batch_norm_backward_std \n",
        "        copied_layer.batch_norm_backward_n = self.batch_norm_backward_n \n",
        "        copied_layer.lam = self.lam \n",
        "        copied_layer.dlamdn = self.dlamdn \n",
        "        copied_layer.xTy = self.xTy.clone() \n",
        "        copied_layer.yTx = self.yTx.clone()\n",
        "        copied_layer.betaT_forward = self.betaT_forward.clone()\n",
        "        copied_layer.betaT_backward = self.betaT_backward.clone()\n",
        "        self.x_forward = None \n",
        "        self.y_forward = None \n",
        "        self.x_backward = None \n",
        "        self.y_backward = None\n",
        "        return copied_layer \n",
        "    def forward(self, x): \n",
        "        'creates and stores x_forward and y_forward, then returns activation(y_forward)' \n",
        "        self.__validate_inputs(x=x, p=self.p)  \n",
        "        x = self.batch_norm(x, forward=True) ## TODO use fitting or not \n",
        "        self.x_forward = x\n",
        "        x = torch.cat((torch.tensor([[1.]]), x), dim=0) # intercept \n",
        "        self.y_forward = torch.matmul(self.betaT_forward, x) # predict \n",
        "        self.y_forward = torch.clip(self.y_forward, -self.clip, self.clip)\n",
        "        return self.activation(self.y_forward) \n",
        "    def backward(self, y): \n",
        "        'creates and stores x_backward and y_backward, then returns y_backward' \n",
        "        y = self.activation_inverse(y) \n",
        "        self.__validate_inputs(y=y, q=self.q) \n",
        "        y = self.batch_norm(y, forward=False) ## TODO use fitting or not\n",
        "        self.y_backward = y \n",
        "        y = torch.cat((torch.tensor([[1.]]), y), dim=0) \n",
        "        self.x_backward = torch.matmul(self.betaT_backward, y) \n",
        "        self.x_backward = torch.clip(self.x_backward, -self.clip, self.clip)\n",
        "        return self.x_backward \n",
        "    def forward_fit(self): \n",
        "        'uses x_forward and y_backward to update forward model, then returns Sherman Morrison denominator' \n",
        "        if self.trainable: \n",
        "            self.__validate_inputs(x=self.x_forward, y=self.y_backward, p=self.p, q=self.q) \n",
        "            self.xTx_inv_temp = None \n",
        "            self.xTy_temp = None \n",
        "            x = torch.cat((torch.tensor([[1.]]), self.x_forward), dim=0) \n",
        "            self.xTx_inv, sm_denom = self.sherman_morrison(self.xTx_inv, x, x) \n",
        "            ##self.xTx_inv = self.reregularizer(self.xTx_inv, self.dlamdn) ## real online regularization too slow \n",
        "            self.xTy += torch.matmul(x, torch.transpose(self.y_backward, 0, 1)) \n",
        "            self.betaT_forward = torch.matmul(self.xTx_inv, self.xTy) \n",
        "            self.betaT_forward = torch.transpose(self.betaT_forward, 0, 1) \n",
        "        return sm_denom \n",
        "    def backward_fit(self):\n",
        "        'uses x_backward and y_forward to update backward model, then returns Sherman Morrison denominator' \n",
        "        if self.trainable: \n",
        "            self.__validate_inputs(x=self.x_forward, y=self.y_backward, p=self.p, q=self.q) \n",
        "            self.yTy_inv_temp = None \n",
        "            self.yTx_temp = None \n",
        "            y = torch.cat((torch.tensor([[1.]]), self.y_backward), dim=0) \n",
        "            self.yTy_inv, sm_denom = self.sherman_morrison(self.yTy_inv, y, y) \n",
        "            ##self.yTy_inv = self.reregularizer(self.yTy_inv, self.dlamdn) \n",
        "            self.yTx += torch.matmul(y, torch.transpose(self.x_backward, 0, 1)) \n",
        "            self.betaT_backward = torch.matmul(self.yTy_inv, self.yTx) \n",
        "            self.betaT_backward = torch.transpose(self.betaT_backward, 0, 1) \n",
        "            self.n_fits += 1 ## TODO write general fitting function \n",
        "        return sm_denom \n",
        "    def forward_fit_temp(self): \n",
        "        'uses x_forward and y_backward to update forward model, then returns Sherman Morrison denominator' \n",
        "        if self.trainable: \n",
        "            self.__validate_inputs(x=self.x_forward, y=self.y_backward, p=self.p, q=self.q) \n",
        "            if self.xTx_inv_temp is None or self.xTy_temp is None:\n",
        "                self.xTx_inv_temp = self.xTx_inv\n",
        "                self.xTy_temp = self.xTy \n",
        "            x = torch.cat((torch.tensor([[1.]]), self.x_forward), dim=0) \n",
        "            self.xTx_inv_temp, sm_denom = self.sherman_morrison(self.xTx_inv_temp, x, x) \n",
        "            ##self.xTx_inv = self.reregularizer(self.xTx_inv, self.dlamdn) ## real online regularization too slow \n",
        "            self.xTy_temp = self.xTy_temp + torch.matmul(x, torch.transpose(self.y_backward, 0, 1)) \n",
        "            self.betaT_forward_temp = torch.matmul(self.xTx_inv_temp, self.xTy_temp) \n",
        "            self.betaT_forward_temp = torch.transpose(self.betaT_forward_temp, 0, 1) \n",
        "        return sm_denom \n",
        "    def backward_fit_temp(self):\n",
        "        'uses x_backward and y_forward to update backward model, then returns Sherman Morrison denominator' \n",
        "        if self.trainable: \n",
        "            self.__validate_inputs(x=self.x_forward, y=self.y_backward, p=self.p, q=self.q) \n",
        "            if self.yTy_inv_temp is None or self.yTx_temp is None:\n",
        "                self.yTy_inv_temp = self.yTy_inv \n",
        "                self.yTx_temp = self.yTx \n",
        "            y = torch.cat((torch.tensor([[1.]]), self.y_backward), dim=0) \n",
        "            self.yTy_inv_temp, sm_denom = self.sherman_morrison(self.yTy_inv, y, y) \n",
        "            ##self.yTy_inv = self.reregularizer(self.yTy_inv, self.dlamdn) \n",
        "            self.yTx_temp = self.yTx + torch.matmul(y, torch.transpose(self.x_backward, 0, 1)) \n",
        "            self.betaT_backward_temp = torch.matmul(self.yTy_inv_temp, self.yTx_temp) \n",
        "            self.betaT_backward_temp = torch.transpose(self.betaT_backward_temp, 0, 1) \n",
        "            #self.n_fits += 1 ## TODO write general fitting function \n",
        "        return sm_denom \n",
        "    def forward_temp(self, x): \n",
        "        'creates and stores x_forward and y_forward, then returns activation(y_forward)' \n",
        "        self.__validate_inputs(x=x, p=self.p)  \n",
        "        x = self.batch_norm(x, forward=True) ## TODO use fitting or not \n",
        "        self.x_forward = x\n",
        "        x = torch.cat((torch.tensor([[1.]]), x), dim=0) # intercept \n",
        "        self.y_forward = torch.matmul(self.betaT_forward_temp, x) # predict \n",
        "        self.y_forward = torch.clip(self.y_forward, -self.clip, self.clip)\n",
        "        return self.activation(self.y_forward) \n",
        "    def backward_temp(self, y): \n",
        "        'creates and stores x_backward and y_backward, then returns y_backward' \n",
        "        y = self.activation_inverse(y) \n",
        "        self.__validate_inputs(y=y, q=self.q) \n",
        "        y = self.batch_norm(y, forward=False) ## TODO use fitting or not\n",
        "        self.y_backward = y \n",
        "        y = torch.cat((torch.tensor([[1.]]), y), dim=0) \n",
        "        self.x_backward = torch.matmul(self.betaT_backward_temp, y) \n",
        "        self.x_backward = torch.clip(self.x_backward, -self.clip, self.clip)\n",
        "        return self.x_backward \n",
        "    def set_n_fits(self, n):\n",
        "        'resizes sufficient statistic matrices to sample size n'\n",
        "        if n < 1 or self.n_fits < 1:\n",
        "            return None \n",
        "        self.xTy *= n/self.n_fits \n",
        "        self.yTx *= n/self.n_fits \n",
        "        self.xTx_inv *= self.n_fits/n \n",
        "        self.yTy_inv *= self.n_fits/n \n",
        "        self.n_fits = n \n",
        "        pass\n",
        "    def batch_norm(self, x, forward, fitting=True):\n",
        "        '''\n",
        "        batch normalize tensor\n",
        "        inputs:\n",
        "        - x: (tensor) to be normalized \n",
        "        - forward: (boolean) indicates prediction is forward, instead of backward \n",
        "        - fitting: (boolean) if in model fitting, update values \n",
        "        '''\n",
        "        ## retrieve \n",
        "        if forward:\n",
        "            m = self.batch_norm_forward_mean \n",
        "            s = self.batch_norm_forward_std\n",
        "            n = self.batch_norm_forward_n \n",
        "        else: \n",
        "            m = self.batch_norm_backward_mean \n",
        "            s = self.batch_norm_backward_std\n",
        "            n = self.batch_norm_backward_n \n",
        "        ## caculate \n",
        "        if n == 0: \n",
        "            n = 1 \n",
        "            m = x.mean() \n",
        "            s = x.std() \n",
        "        else: \n",
        "            n += 1 \n",
        "            m = x.mean()/n + m*(n-1)/n \n",
        "            s = x.std()/n + s*(n-1)/n \n",
        "        ## store \n",
        "        if fitting:\n",
        "            if forward: \n",
        "                self.batch_norm_forward_mean = m \n",
        "                self.batch_norm_forward_std = s \n",
        "                self.batch_norm_forward_n = n \n",
        "            else: \n",
        "                self.batch_norm_backward_mean = m\n",
        "                self.batch_norm_backward_std = s \n",
        "                self.batch_norm_backward_n = n \n",
        "        ## no dividing by zero \n",
        "        if s < 1e-3:\n",
        "            s = 1e-3 \n",
        "        return (x - m)/s \n",
        "    def reregularize(self, dlamdn=None): \n",
        "        if dlamdn is None:\n",
        "            dlamdn = self.dlamdn \n",
        "        self.xTx_inv = self.online_regularizer(self.xTx_inv, dlamdn) \n",
        "        self.yTy_inv = self.online_regularizer(self.yTy_inv, dlamdn) \n",
        "        pass \n",
        "    @staticmethod\n",
        "    def online_regularizer(m_inv, dlam):\n",
        "        '''\n",
        "        Used to expand the regularization sphere as samples grow.\n",
        "        Applies modified Sherman Morrison formula for numerical efficiency. \n",
        "        inputs\n",
        "        - m_inv: inverse matrix of m \n",
        "        - dlam: regularizer to be added on the diagonal \n",
        "        returns\n",
        "         - (m + 1/dlam)^{-1} \n",
        "        '''\n",
        "        if dlam == 0. or dlam is None:\n",
        "            ## avoid degeneracy \n",
        "            return m_inv \n",
        "        if callable(dlam):\n",
        "            dlam = dlam(self.n_fits) \n",
        "        dlam_inv = 1/dlam \n",
        "        for i in range(m_inv.shape[0]): \n",
        "            m_inv -= dlam_inv * torch.matmul(m_inv[:,i].reshape((-1,1)), m_inv[i,:].reshape((1,-1))) / (1. + dlam_inv * m_inv[i,i]) \n",
        "        return m_inv  \n",
        "    @staticmethod \n",
        "    def sherman_morrison(inv_mat, vec1, vec2): \n",
        "        ''' \n",
        "        applies Sherman Morrison updates, (mat + vec1 vec2^T)^{-1} \n",
        "        inputs: \n",
        "        - inv_mat: an inverted matrix \n",
        "        - vec1: a column vector \n",
        "        - vec2: a column vector \n",
        "        returns: \n",
        "        - updated matrix \n",
        "        - the Sherman Morrison denominator, for tracking numerical stability \n",
        "        ''' \n",
        "        v2t = torch.transpose(vec2, 0, 1)\n",
        "        denominator = 1. + torch.matmul(torch.matmul(v2t, inv_mat), vec1) \n",
        "        numerator = torch.matmul(torch.matmul(inv_mat, vec1), torch.matmul(v2t, inv_mat)) \n",
        "        updated_inv_mat = inv_mat - numerator / denominator \n",
        "        return updated_inv_mat, float(denominator) \n",
        "    def __validate_inputs(self, p=None, q=None, lam=None, x=None, y=None, clip=None, dlamdn=None): \n",
        "        'raises value exceptions if provided parameters are invalid'\n",
        "        if q is not None:\n",
        "            if not isinstance(q, int):\n",
        "                raise ValueError('`q` must be int!')\n",
        "            if q <= 0:\n",
        "                raise ValueError('`q` must be greater than zero!')\n",
        "        if p is not None:\n",
        "            if not isinstance(p, int): \n",
        "                raise ValueError('`p` must be int!')\n",
        "            if p <= 0: \n",
        "                raise ValueError('`p` must be greater than zero!')\n",
        "        if lam is not None:\n",
        "            if not (isinstance(lam, float) or isinstance(lam, int)):\n",
        "                raise ValueError('`lam` must be float or int!')\n",
        "            if lam < 0:\n",
        "                raise ValueError('`lam` must be non-negative!')\n",
        "        if x is not None and p is not None: \n",
        "            if type(x) != TORCH_TENSOR_TYPE:\n",
        "                raise ValueError('`x` must be of type `torch.tensor`!') \n",
        "            if list(x.shape) != [p,1]: \n",
        "                raise ValueError('`x.shape` must be `[p,1]`!') \n",
        "            if torch.isnan(x).any():\n",
        "                raise ValueError('`x` contains `nan`!')\n",
        "            pass \n",
        "        if y is not None and q is not None: \n",
        "            if type(y) != TORCH_TENSOR_TYPE:\n",
        "                raise ValueError('`y` must be of type `torch.tensor`!') \n",
        "            if list(y.shape) != [q,1]: \n",
        "                raise ValueError('`y.shape` must be `[q,1]`') \n",
        "            if torch.isnan(y).any():\n",
        "                raise ValueError('`y` contains `nan`!')\n",
        "            pass  \n",
        "        if clip is not None: \n",
        "            if type(clip) != float:\n",
        "                raise ValueError('`clip` my be of type `float`!') \n",
        "            if clip <= 0.: \n",
        "                raise ValueError('`clip` must be positive!')\n",
        "            pass\n",
        "        if dlamdn is not None: \n",
        "            if type(dlamdn) not in [float, callable]: \n",
        "                raise ValueError('`dlamdn` my be of type `float` or `callable`!') \n",
        "            if type(dlamdn) == float:\n",
        "                if dlamdn < 0.: \n",
        "                    raise ValueError('`dlamdn` must be non-negative!') \n",
        "            pass\n",
        "        pass\n",
        "    pass\n",
        "\n",
        "class OnlineNet: \n",
        "    'online, sequential dense net' \n",
        "    def __init__(self, layer_list, dlamdn=0., reregularization_frequency=1000): \n",
        "        '''\n",
        "        initialize an online dense net\n",
        "        inputs:\n",
        "        - layer_list: list of OnlineDenseLayers \n",
        "        - dlamdn: (float >= 0) regularization rate per n. Disabled if zero \n",
        "        - reregularization_frequency: (int > 0) reregularize after fitting this number of samples, since reregularization is computationally expensive\n",
        "        '''\n",
        "        ## validate inputs \n",
        "        if type(layer_list) != list: \n",
        "            raise ValueError('`layer_list` must be of type list!') \n",
        "        for layer in layer_list: \n",
        "            if not issubclass(type(layer), OnlineDenseLayer):\n",
        "                raise ValueError('each item in `layer_list` must be an instance of a subclass of `OnlineDenseLayer`!') \n",
        "        if type(dlamdn) != float: \n",
        "            raise ValueError('`dlamdn` must of type `float`!') \n",
        "        if dlamdn < 0.: \n",
        "            raise ValueError('`dlamdn` must be non-negative!') \n",
        "        if type(reregularization_frequency) != int: \n",
        "            raise ValueError('`reregularization_frequency` must be of type `int`!') \n",
        "        if reregularization_frequency <= 0: \n",
        "            raise ValueError('`reregularization_frequency` must be postive!') \n",
        "        ## assign \n",
        "        self.layer_list = layer_list \n",
        "        self.fit_count = 0 \n",
        "        self.dlamdn = dlamdn \n",
        "        self.reregularization_frequency = reregularization_frequency \n",
        "        pass \n",
        "    def copy(self):\n",
        "        copied_layers = [] \n",
        "        for layer in self.layer_list:\n",
        "            copied_layers.append(layer.copy()) \n",
        "        copied_net = OnlineNet(copied_layers, \n",
        "                dlamdn=self.dlamdn, \n",
        "                reregularization_frequency=self.reregularization_frequency)\n",
        "        return copied_net \n",
        "    def forward(self, x): \n",
        "        'predict forward'\n",
        "        for layer in self.layer_list:\n",
        "            x = layer.forward(x) \n",
        "        return x \n",
        "    def backward(self, y):\n",
        "        'predict backward'\n",
        "        for layer in reversed(self.layer_list): \n",
        "            y = layer.backward(y) \n",
        "        return y \n",
        "    def forward_temp(self, x): \n",
        "        'predicts forward with temporary statistics, returns errors' \n",
        "        err = 0. \n",
        "        n_layers = len(self.layer_list) \n",
        "        for idx, layer in enumerate(self.layer_list):\n",
        "            x_old = layer.activation(layer.y_forward) \n",
        "            x = layer.forward_temp(x) \n",
        "            if idx + 1 < n_layers:\n",
        "                ## ignore observed variables \n",
        "                err += (x_old - x).abs().sum() \n",
        "        return err \n",
        "    def backward_temp(self, y):\n",
        "        'predicts backward with temporary statistics, returns errors' \n",
        "        err = 0.\n",
        "        n_layers = len(self.layer_list) \n",
        "        for idx, layer in enumerate(reversed(self.layer_list)):\n",
        "            y_old = layer.x_backward \n",
        "            y = layer.backward_temp(y)\n",
        "            if idx + 1 < n_layers: \n",
        "                ## ignore observed variables \n",
        "                err += (y_old - y).abs().sum() \n",
        "            #print(f'DEBUG 3: cumulative err: {err}')\n",
        "        return err \n",
        "    def set_n_fits(self, n):\n",
        "        'resizes sufficient statistic matrices to sample size n'\n",
        "        for layer in self.layer_list:\n",
        "            layer.set_n_fits(n)\n",
        "        pass \n",
        "    def fit(self, x, y, eps=.01):#1e-6): ## TODO get convergance guarantee, & remove cherry-picked eps\n",
        "        'integrates observation pair. Returns Sherman Morrison denominators per layer in (forward, backward) pairs in a list'\n",
        "        ## set intermediary predictions \n",
        "        self.set_ends(x,y)\n",
        "        self.forward(x) \n",
        "        self.backward(y) \n",
        "        ## infer intermediary vectors before keeping them \n",
        "        ## this'll keep matrix sizes aligned with sample sizes \n",
        "        err = 1. + eps  \n",
        "        idx = 0 \n",
        "        while err > eps: \n",
        "            idx += 1 \n",
        "            self.set_ends(x,y)\n",
        "            for layer in self.layer_list: \n",
        "                layer.forward_fit_temp() \n",
        "                layer.backward_fit_temp() \n",
        "            self.set_ends(x,y) \n",
        "            err_forward = self.forward_temp(x)\n",
        "            err_backward = self.backward_temp(y) \n",
        "            err = err_forward + err_backward \n",
        "            if idx % 1000 == 0:\n",
        "                print(f'DEBUG 1: err: {err}') \n",
        "                print(f'DEBUG 2: err_forward: {err_forward}, err_backward: {err_backward}') \n",
        "        ## iterate once more, but keep sufficient statistics \n",
        "        sherman_morrison_denominator_list = [] \n",
        "        for layer in self.layer_list: \n",
        "            forward_smd = layer.forward_fit() \n",
        "            backward_smd = layer.backward_fit() \n",
        "            sherman_morrison_denominator_list.append((forward_smd, backward_smd)) \n",
        "        return sherman_morrison_denominator_list \n",
        "    def reregularize(self, dlamdn=None): \n",
        "        for layer in self.layer_list: \n",
        "            layer.reregularize(dlamdn) \n",
        "            pass \n",
        "        pass \n",
        "    def set_ends(self, x, y):\n",
        "        'resets observations at network ends'\n",
        "        self.layer_list[0].x_forward = x \n",
        "        self.layer_list[0].x_backward = x \n",
        "        self.layer_list[-1].y_forward = y \n",
        "        self.layer_list[-1].y_backward = y \n",
        "        pass \n",
        "    def __reduce_sherman_morrison_denominator_list(self, smd_pair_list):\n",
        "        'returns the value closest to zero'\n",
        "        if type(smd_pair_list) != list: \n",
        "            raise ValueError('`smd_pair_list` must be of type `list`!')\n",
        "        if len(smd_pair_list) == 0:\n",
        "            return None \n",
        "        smallest_smd = None \n",
        "        for smd_pair in smd_pair_list:\n",
        "            if type(smd_pair) != tuple:\n",
        "                raise ValueError('`smd_pair_list` must be list of tuples!')\n",
        "            if smallest_smd is None: \n",
        "                smallest_smd = smd_pair[0] \n",
        "            if abs(smallest_smd) > abs(smd_pair[0]): \n",
        "                smallest_smd = smd_pair[0] \n",
        "            if abs(smallest_smd) > abs(smd_pair[1]):\n",
        "                smallest_smd = smd_pair[1] \n",
        "        return float(smallest_smd) \n",
        "    def __call__(self, x, y=None): \n",
        "        '''\n",
        "        If only x is given, a prediction is made and returned.\n",
        "        If x and y are given, then the model is updated, and returns\n",
        "        - the prediction\n",
        "        - the sherman morrison denominator closest to zero, for tracking numerical stability\n",
        "        '''\n",
        "        y_hat = self.forward(x) \n",
        "        if y is None: \n",
        "            return y_hat \n",
        "        self.backward(y) \n",
        "        smd_pair_list = self.fit(x,y) \n",
        "        smallest_smd = self.__reduce_sherman_morrison_denominator_list(smd_pair_list) \n",
        "        self.fit_count += 1 \n",
        "        if self.fit_count % self.reregularization_frequency == 0:\n",
        "            if self.dlamdn is not None: \n",
        "                ## dividing by self.reregularization_frequency ensures mathematical equivalency to reregularizing with every step \n",
        "                self.reregularize(self.dlamdn/self.reregularization_frequency) \n",
        "            else:\n",
        "                ## use per-layer dlamdn values \n",
        "                self.reregularize() \n",
        "        return y_hat, smallest_smd \n",
        "\n",
        "## tests \n",
        "\n",
        "## test 1: sherman morrison \n",
        "a = torch.tensor([[2., 1.], [1., 2.]]) \n",
        "b = torch.tensor([[.1],[.2]]) \n",
        "sm_inv, _ = OnlineDenseLayer.sherman_morrison(torch.inverse(a),b,b) \n",
        "num_inv = torch.inverse(a+torch.matmul(b, torch.transpose(b,0,1))) \n",
        "err = float(torch.abs(sm_inv - num_inv).sum()) \n",
        "assert(err < 1e-5) \n",
        "\n",
        "## test 2: online regularization sherman morrison \n",
        "a = torch.tensor([[2., 1.], [1., 2.]]) \n",
        "b = torch.tensor([[.1, 0.], [0., .1]])\n",
        "or_inv = OnlineDenseLayer.online_regularizer(torch.inverse(a), 10.) \n",
        "num_inv = torch.inverse(a+b) \n",
        "err = float(torch.abs(or_inv - num_inv).sum()) \n",
        "assert(err < 1e-5) "
      ],
      "outputs": [],
      "execution_count": 1,
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "gather": {
          "logged": 1645155310031
        }
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# first experiment: mnist classification"
      ],
      "metadata": {
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from tqdm import tqdm\r\n",
        "from torchvision import datasets, transforms\r\n",
        "\r\n",
        "transform=transforms.Compose([\r\n",
        "    transforms.ToTensor(),\r\n",
        "    transforms.Normalize((0.1307,), (0.3081,))\r\n",
        "    ])\r\n",
        "\r\n",
        "dataset1 = datasets.MNIST('../../data', train=True, download=True, transform=transform)\r\n",
        "dataset2 = datasets.MNIST('../../data', train=False, transform=transform)\r\n",
        "\r\n",
        "train_loader = torch.utils.data.DataLoader(dataset1)\r\n",
        "test_loader = torch.utils.data.DataLoader(dataset2)\r\n",
        "\r\n",
        "n_labels = 10 \r\n",
        "lam = 100. \r\n",
        "dlamdn = 10. \r\n",
        "reregularization_frequency = 1000 \r\n",
        "clip = 100. \r\n",
        "\r\n",
        "## activation functions \r\n",
        "## torch.sigmoid \r\n",
        "inv_sigmoid = lambda x: -torch.log((1/(x+1e-8))-1) \r\n",
        "leaky_relu_alpha = .1 \r\n",
        "leaky_relu = lambda x: (x > 0)*x + (x <= 0)*x*leaky_relu_alpha \r\n",
        "inv_leaky_relu = lambda x: (x > 0)*x + (x <= 0)*x/leaky_relu_alpha \r\n",
        "\r\n",
        "model = OnlineNet( \r\n",
        "    layer_list = [ \r\n",
        "        OnlineDenseLayer(p=1*1*28*28, q=100, activation=leaky_relu, activation_inverse=inv_leaky_relu, lam=lam, clip=clip), \r\n",
        "        OnlineDenseLayer(p=100, q=100, activation=leaky_relu, activation_inverse=inv_leaky_relu, lam=lam, clip=clip), \r\n",
        "        OnlineDenseLayer(p=100, q=100, activation=leaky_relu, activation_inverse=inv_leaky_relu, lam=lam, clip=clip), \r\n",
        "        OnlineDenseLayer(p=100, q=n_labels, activation=torch.sigmoid, activation_inverse=inv_sigmoid, lam=lam, clip=clip) \r\n",
        "    ], \r\n",
        "    reregularization_frequency = reregularization_frequency, \r\n",
        "    dlamdn = dlamdn \r\n",
        ") \r\n",
        "\r\n",
        "def build_data(image, label): \r\n",
        "    'format data from iterator for model' \r\n",
        "    y = torch.tensor([1. if int(label[0]) == idx else 0. for idx in range(n_labels)]) ## one-hot representation \r\n",
        "    x = image.reshape([-1]) ## flatten \r\n",
        "    ## shrink so sigmoid inverse is well-defined \r\n",
        "    y = y*.90 + .05 \r\n",
        "    ## reshape to column vectors \r\n",
        "    x = x.reshape([-1,1]) \r\n",
        "    y = y.reshape([-1,1]) \r\n",
        "    return x, y \r\n",
        "\r\n",
        "def match(y, y_hat):\r\n",
        "    y = y.reshape(-1)\r\n",
        "    y_hat = y_hat.reshape(-1)\r\n",
        "    if y.argmax() == y_hat.argmax():\r\n",
        "        return 1.\r\n",
        "    return 0. \r\n",
        "\r\n",
        "def run(data_iterable, fit=True, max_iters=None, model=model):\r\n",
        "    '''\r\n",
        "    fit or predict on dataset \r\n",
        "    inputs:\r\n",
        "    - data_iterable: an iterable of (image, label) pairs\r\n",
        "    - fit: (bool) are we integrating the (image, label) pair into the model or just predicting?\r\n",
        "    - max_iters: (int or None) if int then cap fit/predict iters at this amount, otherwise run the whole iterable \r\n",
        "    - model: (OnlineDenseNet) the model to update in-place \r\n",
        "    output: \r\n",
        "    - errs: a list of model errors \r\n",
        "    - stab: a list of numerical stability statistics \r\n",
        "    - y_std: a list of y_hat standard deviations \r\n",
        "    - acc: a list of running average accuracies \r\n",
        "    side-effects: \r\n",
        "    - model is updated in-place \r\n",
        "    '''\r\n",
        "    ## init stats \r\n",
        "    errs = [] \r\n",
        "    stab = [] \r\n",
        "    y_std = [] \r\n",
        "    acc = [0.] \r\n",
        "    ## get data \r\n",
        "    pbar = tqdm(data_iterable)\r\n",
        "    n_iters = 0 \r\n",
        "    for [image, label] in pbar: \r\n",
        "        n_iters += 1 \r\n",
        "        ## get a datum \r\n",
        "        x, y = build_data(image, label) \r\n",
        "        ## fit or predict \r\n",
        "        if fit: \r\n",
        "            y_hat, stability = model(x, y) \r\n",
        "        else:\r\n",
        "            y_hat = model(x) \r\n",
        "            stability = 1. \r\n",
        "        ## stats \r\n",
        "        err = float((y - y_hat).abs().sum()) \r\n",
        "        errs.append(err) \r\n",
        "        stab.append(stability) \r\n",
        "        std = float(y_hat.std()) \r\n",
        "        y_std.append(std) \r\n",
        "        acc_n = max(len(acc), 1000) \r\n",
        "        acc.append(match(y,y_hat)/acc_n + acc[-1]*(acc_n-1)/acc_n) \r\n",
        "        pbar.set_description(f'acc: {acc[-1]:.5f}, err: {err:.5f}, y_std: {std:.5f}, stab: {stability:.5f}') \r\n",
        "        if max_iters is not None: \r\n",
        "            if n_iters > max_iters:\r\n",
        "                return errs, stab, y_std, acc\r\n",
        "    return errs, stab, y_std, acc \r\n",
        "\r\n",
        "def test(data_iterable, model, max_iters=None): \r\n",
        "    'calculates accuracy correctly' \r\n",
        "    hits = 0 \r\n",
        "    n = 0 \r\n",
        "    n_iters = 0 \r\n",
        "    for image, label in tqdm(data_iterable):\r\n",
        "        x, y = build_data(image, label) \r\n",
        "        y_hat = model(x) \r\n",
        "        if match(y, y_hat) == 1:\r\n",
        "            hits += 1 \r\n",
        "        n += 1\r\n",
        "    return hits/n  \r\n",
        "\r\n",
        "errs, stab, y_std, acc = run(train_loader, fit=True, max_iters=10000) "
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": "acc: 0.80069, err: 3.16764, y_std: 0.18383, stab: 1.00088:  17%|█▋        | 10000/60000 [07:22<36:50, 22.62it/s] \n"
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": "DEBUG 1: err: 0.019080467522144318\nDEBUG 2: err_forward: 0.019023723900318146, err_backward: 5.6743621826171875e-05\nDEBUG 1: err: 0.012225122191011906\nDEBUG 2: err_forward: 0.01204907987266779, err_backward: 0.0001760423183441162\nDEBUG 1: err: 0.011011244729161263\nDEBUG 2: err_forward: 0.010947020724415779, err_backward: 6.42240047454834e-05\nDEBUG 1: err: 0.011487305164337158\nDEBUG 2: err_forward: 0.011305928230285645, err_backward: 0.00018137693405151367\nDEBUG 1: err: 0.020195767283439636\nDEBUG 2: err_forward: 0.02017320692539215, err_backward: 2.256035804748535e-05\nDEBUG 1: err: 0.013092681765556335\nDEBUG 2: err_forward: 0.012798115611076355, err_backward: 0.00029456615447998047\nDEBUG 1: err: 0.015155226923525333\nDEBUG 2: err_forward: 0.015117795206606388, err_backward: 3.743171691894531e-05\nDEBUG 1: err: 0.010802241042256355\nDEBUG 2: err_forward: 0.010590704157948494, err_backward: 0.00021153688430786133\nDEBUG 1: err: 0.01284831017255783\nDEBUG 2: err_forward: 0.012805603444576263, err_backward: 4.270672798156738e-05\nDEBUG 1: err: 0.011726210825145245\nDEBUG 2: err_forward: 0.011662344448268414, err_backward: 6.386637687683105e-05\nDEBUG 1: err: 0.010917427018284798\nDEBUG 2: err_forward: 0.010855736210942268, err_backward: 6.16908073425293e-05\n"
        }
      ],
      "execution_count": 2,
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "gather": {
          "logged": 1645155756542
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as plt \r\n",
        "\r\n",
        "print('acc')\r\n",
        "plt.plot(acc[100:])\r\n",
        "plt.show()"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": "acc\n"
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": "<Figure size 432x288 with 1 Axes>",
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXcAAAD4CAYAAAAXUaZHAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4yLjEsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy+j8jraAAAgAElEQVR4nO3deZydZXn/8c81Z/Y922SZZEggE0IEEmAIoKCsGqiSUhcCKIraGJFW22qJpWpbtdVaFf2JjRFT20qNYFEjRrCCsgiETFizQhZJJuskmUwms5851++P8zA5DJPMSXImz1m+79drXnPO89xz5ronyTfP3Od+7tvcHRERyS55YRcgIiKpp3AXEclCCncRkSykcBcRyUIKdxGRLJQf1jcePXq0T548OaxvLyKSkVatWrXX3ccM1S60cJ88eTKNjY1hfXsRkYxkZq8m007DMiIiWUjhLiKShRTuIiJZSOEuIpKFFO4iIlkoqXA3szlmtsHMNprZwkHOV5nZL83sBTNbY2a3pL5UERFJ1pDhbmYR4C7gamAGcIOZzRjQ7BPAWnefCVwKfN3MClNcq4iIJCmZee6zgY3uvhnAzJYCc4G1CW0cqDAzA8qB/UA0xbWKiGSUzp4+9rR1sa+9h92tXbR1R9nd2sWsumouqR/yPqQTkky41wLbEp43ARcMaPMdYBmwA6gArnf32MAXMrP5wHyAurq646lXRGRYdfX2sf1AJ719Mbp6Y7R3RznQ0Us0Fo+0nmiMvYd6aO+O0tsXo6cvRltXvM3ug11sa+mgvTtKnhnd0TfEIAAfv/S0tAh3G+TYwB0+3gE8D1wOnAb8n5k97u4HX/dF7ouBxQANDQ3aJUREjtmh7ig90Ritnb3sONDJ9gOdbG/ppKWjh4rifMqLCpg8qpTKkgIKInn9AVxRlE9+JK8/rJvbumhq6WRnaxetnb20dvbS1NJBS0dvUnXkGRRE8iiI5FFZnE9lSQE1lcWcPbGKypICYjGPH6soYnR5ETWVRVQUFVBTWURxQWSYf0rJhXsTMCnh+UTiV+iJbgG+4vFtnTaa2RZgOvBMSqoUkazi7hzqjtLR00dbVy/NbT20dPSQZ8aBjh56+mJE+5w9bd39odvU0klbV5S9h7rf8HpmUF6Uz6HuKMeyuVxRfh611SVUlhQwoqyQsyZWMb6ymNoRJRTlRyguyKOsKJ+q4D8Kd6cwP48xFUWUFESIj0Snp2TCfSVQb2ZTgO3APODGAW22AlcAj5vZWOB0YHMqCxWR9NXeHWVT8yEOdPTS3h2lqaWTve3dNLd1ByHdRVdvjLauXjp6+mjtjH8eSn6eUVlSQG11CW+aUElZYT51o0opKYhQVVLA+Kp4EI+tLKa4INL/n8ar+zo41B0l2ufkR4yCiHGou4++WIySgnxGlBUwqqyI0eWFaR3QJ2LIcHf3qJndBjwERIAl7r7GzBYE5xcBXwR+aGYvER/Gud3d9w5j3SKSYu5OU0snW/d3sPdQPJirSwuZUFUMwL72Hg509LD7YDfbWjrYc7Cb5kPdbN3fQc8gY8uFkTxGlxeSH8mjpqKIiuJ8xlYWUVYYH8IYX1VMaVE+lcX5jCorYmRZITF3qksLKMqPkGcwsuzYwtfMqCgu4MzaqpT9XDKVhbVBdkNDg2tVSJHU23uom7U7DrKp+RC7Wrt4dV8HTQc66OjpIxZzigsi9ERjdEdjRGMx+mJOUX6EAx09tCdxNR3JM8ZXFfePJU+oLmFUWSH1Y8sZVV5EaWGEidWlVBTnk5eXnVfFYTKzVe7eMFS70Jb8FZET09sXY8OuNrYf6GTN9lae23aANTsOsr+9p79NYSSP2hElTBxRQt3I/P4ZHPl5RmF+HpE8wzBi7lSVFDBtbAWTR5cyqqyIsZVF7D7Yzb72btzjV9GjygupKolfWUt6U7iLpCF3Z9fBLg509LJmx0HW7TxIbzDlbtv+Dva0xYdDXpNncPq4Sq48o4ZpYyuYMb6S+rEVjCorPKGr5+rSQuKzmyXTKNxFQtTZ08eO1k627uvghaYDbNjVxtYgvJvbDs8KieQZ+XnGiNJC6kaWctbEKt41c3z8SntUGafVlFNepH/Ocpj+NoicJLGYs2VfO2t2HOSZLft4sak1uCKPv+9lBpNHlTFxRAnTxlYwa1I11aXxoZLTx1Zo/FqOicJdJEU6eqJs2tNOZ28fr+xp40BHLztbO+M3yhyI37n42vS/ssIIZ0+s5sMXT2FaTQW1I+JT/SqKC0LuhWQLhbvIcdi2v4PNe9vpicbY3HyI329oZtXWljdMCawozqe2uoRJI0u44NSRnDmhihkTKjl9XAUFEa24LcNH4S5yBAe7etnS3E5HTx9rdrSyqbmdtTsPsmHXQbp6Xx/i08dV8IELT+H8ySMoyo8wNRgDry4tyNqbZCS9Kdwl5+1q7eLZrS08+2oL63e1sbO1k20tnW+4Cq8szmdqTTk3zK6jbmQpp4+roKQgQu2IEmoqikOqXmRwCnfJWu5OZ28f2/Z30tnbx6v72tmwq40/7mtnZ2sXnT19dPT09U8pLIgY9TUVnDKqjEtPr2FEaQGTRpZSXpTPWbVV1FQqwCVzKNwlq0T7Yjy8fg+/fGEHK7bsf910wteMryqmurSQmspiivPzuOmCOs47ZQRn1ladlNX6RE4GhbtkvFf3tfPYy82s3XmQB1fvoqWjl6qSAi6eOppTx8SnFlaVFFBbXcq0ceW6u1JygsJdMsqeg12s39XGq/vaWbuzjWe27GNTczsAJQURLp9ew7WzJnDF9BryNRtFcpjCXdKau7Niy37+sHEvq7e38tgre+mLxW/6KS/K57xTRvDu8yZy5Rljqa8p18wUkYDCXdJKLOa8sucQT27ay/PbDvDs1ha27e8EYEJVMe+/oI7zp4xk+rhKThtTpjAXOQKFu4Suq7ePXzy/neUv7WLFln39c8hLCiLMmlTNrZdO5cozxjKmoijkSkUyh8JdQrP9QCc/WbmNpc9sZU9bNxOqirl25gSmj6vkkvrR1I/VaoQixyupcDezOcC3iO/EdLe7f2XA+c8ANyW85hnAGHffn8JaJcNF+2I8tXkfT7yyl0dfbmb9rjYALp46mq+9dyaXTB2txbFEUmTIcDezCHAXcBXxzbJXmtkyd1/7Wht3/xrwtaD9u4C/UrALQHe0jyVP/JGv/2YD0djhXb9mTqrmU1fW886zxzO1RlfoIqmWzJX7bGCju28GMLOlwFxg7RHa3wD8ODXlSSZq7ejlH3+5hvuf2/664+8+dyKX1I/msuk1VJVo9UOR4ZRMuNcC2xKeNwEXDNbQzEqBOcBtRzg/H5gPUFdXd0yFSvp7sekAH/3PRvYMuCv0zutnce3MCRpyETmJkgn3wf5FHmlX7XcBfzjSkIy7LwYWQ3yD7KQqlLTW1dvH39z7Ar96aWf/sbqRpXzozZOZN3sSpYV6z14kDMn8y2sCJiU8nwjsOELbeWhIJie4O8te2MEnlz7ff+zqM8fxd9ecwaSRpSFWJiKQXLivBOrNbAqwnXiA3ziwkZlVAW8D3p/SCiWtdEf7WPT7zXzzty/3H/veB87jHW8aF2JVIjLQkOHu7lEzuw14iPhUyCXuvsbMFgTnFwVNrwN+4+7tw1athCbaF+OOn63mJ42H335573kT+ae5Z1JSqIW4RNKNuYcz9N3Q0OCNjY2hfG9JXm9fjDt+9hL3Njb1H7t9znQ+9tZT9QapSAjMbJW7NwzVTu92yaDuWfEqd/xs9euOfeXPzuL68ydpPReRDKBwl37uzhMb9/Kppc+zr72n//i88yfxD9e+SRtZiGQQhbsA8Mj63Xz4h4eHyWZOqmbJBxsYVa7FukQykcI9x728u43P3PcCLzS1AjCitID7b30LU0aXhVyZiJwIhXsO2tR8iDl3PkZv3+E30y86dRTfu/k8Kou1LIBINlC455gvPbCWu5/Y0v98fFUx377hHM6fPDLEqkQk1RTuOaKppYMbv7+Crfs7APjWvFnMnVUbclUiMlwU7jngvsZtfOanLwIwa1I1937sIgrztXm0SDZTuGexWMz56H818sj6PQD87NY3c07diJCrEpGTQeGepfpizo3ff5oVW+ILdL7w+bdTVao3S0VyhcI9C+091E3Dl34LwLl11dy34M1EtFSASE5RuGeZ23/6Yv/iXn95RT1/fdW0kCsSkTAo3LNEX8x5+zcfZVNzfFHO//jQ+Vw2vSbkqkQkLAr3LNAd7WPOnY+zZW882Nf84zsoK9IfrUguUwJkuN6+GBf+88O0dPRy3Tm1fON9M7Vqo4go3DNZTzTGtL//NQDXnVPLN6+fFXJFIpIukrqTxczmmNkGM9toZguP0OZSM3vezNaY2aOpLVMGau3s7Q/2ubMmKNhF5HWGvHI3swhwF3AV8c2yV5rZMndfm9CmGvguMMfdt5qZ3skbRht2tfGOOx8D4NZLT+Nv50wPuSIRSTfJDMvMBja6+2YAM1sKzAXWJrS5Ebjf3bcCuPueVBcqcRv3HOoP9n++7ixuvKAu5IpEJB0lMyxTC2xLeN4UHEs0DRhhZr83s1VmdnOqCpTD4rNi4sH+H7ecr2AXkSNK5sp9sKkXA3fVzgfOA64ASoCnzOxpd3/5dS9kNh+YD1BXp2A6Fu7O5f/2KNGY86/vPpvLTtfIl4gcWTJX7k3ApITnE4Edg7R50N3b3X0v8Bgwc+ALuftid29w94YxY8Ycb8056cu/Wsf2A51cO3MC7zt/0tBfICI5LZlwXwnUm9kUMysE5gHLBrT5BXCJmeWbWSlwAbAutaXmrvcuepK7n9hCeVE+d2pWjIgkYchhGXePmtltwENABFji7mvMbEFwfpG7rzOzB4EXgRhwt7uvHs7Cc8UHfrCClX9sAeCRT7+NPC0AJiJJMPeBw+cnR0NDgzc2NobyvTPFp5Y+x8+fj4+Avfylq7XBhohgZqvcvWGodrpDNU3dsPhpntq8D4ANX5qjYBeRY6LESEO/W7+nP9hf+PzbKcqPhFyRiGQahXua+cPGvdzyw5UAPPe5q7R7kogcF4V7GtlxoJOb7l4BwH99eDYjygpDrkhEMpXCPU30xZw3f+URAP7i8qm8dZruAxCR46dwTxMzPv8gAJeePoa/efvpIVcjIplO4Z4GVv5xP93RGBDfHk9E5EQp3EPW1dvHexc9BcRnxmgXJRFJBYV7yKZ/Lj4c8/FLT9PMGBFJGYV7iD7xP8/2P75dG26ISAop3EOydV8Hv3pxJwDrvzgn5GpEJNso3EPypV/FN7L69ScvobhAd6CKSGop3EOw/UAnv1m7mz85ezxnjK8MuxwRyUIK9xC8JbhZ6dOazy4iw0ThfpKd9Q8PATC2sogpo8tCrkZEspXC/SS68ftP09YVBeB3n7403GJEJKslFe5mNsfMNpjZRjNbOMj5S82s1cyeDz4+n/pSM9uDq3fx5Kb4Mr6PfuZSSgu1lL6IDJ8hE8bMIsBdwFXEN8JeaWbL3H3tgKaPu/s7h6HGjLeztZMFP1oFwIOfuoRTRmk4RkSGVzJX7rOBje6+2d17gKXA3OEtK7u889tPAPDnl0xh+jjNjhGR4ZdMuNcC2xKeNwXHBrrIzF4ws1+b2ZtSUl0WWLvjIPvaewC4409mhFyNiOSKZAZ+B1vJauCu2s8Cp7j7ITO7Bvg5UP+GFzKbD8wHqKurO8ZSM08s5lzz7ceB+HCMiMjJksyVexMwKeH5RGBHYgN3P+juh4LHy4ECMxs98IXcfbG7N7h7w5gx2b8ZxR827QXgLVNHaThGRE6qZMJ9JVBvZlPMrBCYByxLbGBm4yxYq9bMZgevuy/VxWaaD/zgGQCWaI12ETnJhhyWcfeomd0GPAREgCXuvsbMFgTnFwHvAT5uZlGgE5jn7gOHbnLKqlf3AzC1ppyifK0dIyInl4WVwQ0NDd7Y2BjK9x5usZhz6t8tB+CFL7ydqhKt0y4iqWFmq9y9Yah2ukN1GHzvsc0AjKkoUrCLSCgU7inW2xfjqw+uB+CphZeHXI2I5CqFe4rd2xi/JeATl51GfkQ/XhEJh9InhaJ9Mf7995uYNalay/mKSKgU7il01+820dTSyYK3nUYwM1REJBQK9xRpbuvmm799GYCrZowNuRoRyXUK9xS5/N9+D8CXrzuTSJ6u2kUkXAr3FGjt7KWtO74Jx00XnBJyNSIiCveUuC+YIfO/H78o5EpEROIU7inwpV+tA+CcSSNCrkREJE7hfoLW7jgIxFd+zNNYu4ikCYX7Cbrlh/GVH7/+3lkhVyIicpjC/QQsf2knuw92AzCuqjjkakREDlO4n4Bb73kWgO/fPOQCbSIiJ5XC/Ti1dvQCMLKsUDctiUjaUbgfp9e20Fv8gfNCrkRE5I2SCnczm2NmG8xso5ktPEq7882sz8zek7oS09Pv1u+hsjifWZOqwy5FROQNhgx3M4sAdwFXAzOAG8xsxhHafZX4dnxZrS/m3LeqiYvrR2tZXxFJS8kk02xgo7tvdvceYCkwd5B2fwH8L7AnhfWlpS8HNy29aUJVyJWIiAwumXCvBbYlPG8KjvUzs1rgOmBR6kpLX0tXbgXgY289NeRKREQGl0y4D3bb5cBdte8Ebnf3vqO+kNl8M2s0s8bm5uZka0wr+9t76OjpY+6sCRqSEZG0lZ9EmyZgUsLzicCOAW0agKXBBhWjgWvMLOruP09s5O6LgcUADQ0NA/+DyAjvWfQkALOnjAy5EhGRI0sm3FcC9WY2BdgOzANuTGzg7lNee2xmPwQeGBjs2aC9O8rm5nYAbpxdF3I1IiJHNmS4u3vUzG4jPgsmAixx9zVmtiA4nxPj7ABPbdoHwJ+cNV7b6IlIWkvmyh13Xw4sH3Bs0FB39w+deFnp6R9+uQaAr79vZsiViIgcnd4RTFJvX4ymlk4AigsiIVcjInJ0Cvckzf7ybwG445ozQq5ERGRoCvckuDstwUJhH7l4yhCtRUTCp3BPwtb9HQBcecZY7bYkIhlB4Z6Eq77xGAALrz495EpERJKjcE9CT18MgNPGlIdciYhIchTuQ3h43W4ArjunVnPbRSRjKNyH8NUH1wPwl1fUh1yJiEjyFO5DeHn3IQCmjC4LuRIRkeQp3I9i36FuAO22JCIZR+F+FA+vi+87cvuc6SFXIiJybBTuR3H3E5sBOGuidlwSkcyicD+K18bby4uSWl9NRCRtKNyPoKW9B4APvXlyuIWIiBwHhfsRnPPF/wPgHW8aF3IlIiLHTuE+CPfDOwCeU6eZMiKSeZIKdzObY2YbzGyjmS0c5PxcM3vRzJ4PNsC+OPWlnjz/75GNANx22VSt3S4iGWnIdwrNLALcBVxFfLPslWa2zN3XJjR7GFjm7m5mZwP3Ahk7f/DRl5sBuO3yqSFXIiJyfJK5cp8NbHT3ze7eAywF5iY2cPdDfngsowxwMlQs5qx6tQXQjksikrmSCfdaYFvC86bg2OuY2XVmth74FfDh1JR38t3zzFYA3jptTMiViIgcv2TCfbClEN9wZe7uP3P36cCfAl8c9IXM5gdj8o3Nzc3HVulJ8rmfrwbgW9fPCrkSEZHjl0y4NwGTEp5PBHYcqbG7PwacZmajBzm32N0b3L1hzJj0uzJu6+rtfzyirDDESkRETkwy4b4SqDezKWZWCMwDliU2MLOpFix2bmbnAoXAvlQXO9y+9tAGAP7lz84KuRIRkRMz5GwZd4+a2W3AQ0AEWOLua8xsQXB+EfBu4GYz6wU6ges9cbJ4hli74yAAfzrrDW8piIhklKQWTXH35cDyAccWJTz+KvDV1JZ2crk7jcEsmZJCzZIRkcymO1QDTS2dANRUFIVciYjIiVO4B1ZvbwXg+zc3hFyJiMiJU7gH1uw4SCTPOH1cRdiliIicMC1UHvjO7+LryeiuVBHJBrpyB6J9MQBOGVUaciUiIqmhcAf+sCk+Jf/68ycN0VJEJDMo3IEPLnkGgPecOzHkSkREUiPnw7072tf/uKayOMRKRERSJ+fD/UdPx1eBrK8pD7kSEZHUyflw/+ID8T1H7vnzC0KuREQkdXI+3F9TU6EhGRHJHjkd7tv2dwBww2zNkhGR7JLT4f7th18B4IbZdSFXIiKSWjkd7vetagLgrNqqkCsREUmtnA33Z7e29D8O9hkREckaORvu33kkvpbMf39kdsiViIikXs6G+8ot+wG4pD799nIVETlRSYW7mc0xsw1mttHMFg5y/iYzezH4eNLMZqa+1NRpaumgrTsadhkiIsNmyHA3swhwF3A1MAO4wcxmDGi2BXibu58NfBFYnOpCU+k3a3YD8OXrzgy5EhGR4ZHMlftsYKO7b3b3HmApMDexgbs/6e6vvUP5NJDWK3Dd/1x8lsy7tVCYiGSpZMK9FtiW8LwpOHYkHwF+PdgJM5tvZo1m1tjc3Jx8lSm0q7WL1dsPAtqYQ0SyVzLhPtg8QR+0odllxMP99sHOu/tid29w94YxY8J5I/PCf3kYgHFaAVJEslgy2+w1AYn3508EdgxsZGZnA3cDV7v7vtSUl1rPJcxtf3Lh5SFWIiIyvJK5cl8J1JvZFDMrBOYByxIbmFkdcD/wAXd/OfVlpsbnfrEagC+8awZ5ebpxSUSy15BX7u4eNbPbgIeACLDE3deY2YLg/CLg88Ao4LvB3Z5Rd28YvrKPz2tj7be8ZUrIlYiIDK9khmVw9+XA8gHHFiU8/ijw0dSWllqdPfEdl66dOSHkSkREhl/O3KG66tX4ePt5p4wIuRIRkeGXE+HeE43x/h+sAHTlLiK5ISfC/dZ7nu1/PKKsMMRKREROjqwP996+GL9dF19uoPHvrwy5GhGRkyPrw/2mu+PDMVfNGMvo8qKQqxEROTmyOtxb2nt4Jlja97s3nRtyNSIiJ09Wh/uPV24F4IIpIymIZHVXRUReJ6sT718f3ADA//z5hSFXIiJycmVtuMdih9c2i2ipARHJMVkb7k0tnYA25BCR3JS14f5PD6wFYPq4ypArERE5+bI23F+b235uXXXIlYiInHxZGe7twebX72uYSLBKpYhITsnKcP/F8/G9RK44Y2zIlYiIhCMrw339rvi67W+bFs5WfiIiYcvKcL+3cRvTxpZrA2wRyVlJhbuZzTGzDWa20cwWDnJ+upk9ZWbdZvbp1JeZvL6Y09UbY6RWfxSRHDbkTkxmFgHuAq4ivln2SjNb5u5rE5rtB/4S+NNhqfIYbNnbDsCfnTsx5EpERMKTzJX7bGCju2929x5gKTA3sYG773H3lUDvMNR4TJ7atBeAMzS/XURyWDLhXgtsS3jeFBw7ZmY238wazayxubn5eF5iSOt3tQEwY4LCXURyVzLhPthEcR/k2JDcfbG7N7h7w5gxwzOTZflLOxlVVqj1ZEQkpyUT7k3ApITnE4Edw1POiYnFnJaOXs7RXakikuOSCfeVQL2ZTTGzQmAesGx4yzo+X1i2BoBL6jW/XURy25CzZdw9ama3AQ8BEWCJu68xswXB+UVmNg5oBCqBmJl9Cpjh7geHsfY3ePyV+Dj+u8/TTBkRyW1DhjuAuy8Hlg84tijh8S7iwzWhicWcP+7rYOakasqLkuqWiEjWypo7VNcFSw6cf8qIkCsREQlf1oT7is3xjbDfOXNCyJWIiIQva8L97sc3A3Cm5reLiGRHuLs7O1q7KC/KJz+SFV0SETkhWZGELza1AvDJK+pDrkREJD1kRbj/4IktAFx+Rk3IlYiIpIeMD/c9bV0seyF+w+xpY8pDrkZEJD1kfLhf/72nAQ3JiIgkyuhwj8W8f/32v7pqWsjViIikj4wO90eD5QY+9tZTQ65ERCS9ZHS4P7JuDwAfuWRKyJWIiKSXjA73h9ftJj/PqKkoDrsUEZG0krHhvnHPIXa0dlE/tiLsUkRE0k5Ghvuu1i6u/MajAHzistNCrkZEJP1kZLh//J5VAMyePJJ3nq2FwkREBsq4cP/9hj08t/UAAPcuuCjkakRE0lNS4W5mc8xsg5ltNLOFg5w3M/t2cP5FMzs39aXGVZYUcN05tfzoIxcM17cQEcl4Q25ZZGYR4C7gKuKbZa80s2Xuvjah2dVAffBxAfDvweeUO7duBOfWaUMOEZGjSebKfTaw0d03u3sPsBSYO6DNXOC/PO5poNrMxqe4VhERSVIy4V4LbEt43hQcO9Y2mNl8M2s0s8bm5uZjrVVERJKUTLjbIMf8ONrg7ovdvcHdG8aMGZNMfSIichySCfcmYFLC84nAjuNoIyIiJ0ky4b4SqDezKWZWCMwDlg1oswy4OZg1cyHQ6u47U1yriIgkacjZMu4eNbPbgIeACLDE3deY2YLg/CJgOXANsBHoAG4ZvpJFRGQoQ4Y7gLsvJx7giccWJTx24BOpLU1ERI5Xxt2hKiIiQ7P4RXcI39isGXj1OL98NLA3heVkilzsdy72GXKz37nYZzj2fp/i7kNONwwt3E+EmTW6e0PYdZxsudjvXOwz5Ga/c7HPMHz91rCMiEgWUriLiGShTA33xWEXEJJc7Hcu9hlys9+52GcYpn5n5Ji7iIgcXaZeuYuIyFEo3EVEslDGhftQu0JlEjObZGa/M7N1ZrbGzD4ZHB9pZv9nZq8En0ckfM1ng75vMLN3JBw/z8xeCs5928wGW6kzbZhZxMyeM7MHgue50OdqM/upma0P/swvyvZ+m9lfBX+3V5vZj82sOBv7bGZLzGyPma1OOJayfppZkZn9JDi+wswmD1mUu2fMB/G1bTYBpwKFwAvAjLDrOoH+jAfODR5XAC8DM4B/BRYGxxcCXw0ezwj6XARMCX4WkeDcM8BFxJdf/jVwddj9G6Lvfw38D/BA8DwX+vyfwEeDx4VAdTb3m/ieDluAkuD5vcCHsrHPwFuBc4HVCcdS1k/gVmBR8Hge8JMhawr7h3KMP8CLgIcSnn8W+GzYdaWwf78gvp3hBmB8cGw8sGGw/hJfzO2ioM36hOM3AN8Luz9H6edE4GHg8oRwz/Y+VwZBZwOOZ22/ObyJz0ji61g9ALw9W/sMTB4Q7inr52ttgsf5xO9otaPVk2nDMknt+JSJgl+zzgFWAGM9WDI5+FwTNDtS/2uDxwOPp6s7gb8FYgnHsr3PpwLNwH8Ew690YwkAAAIOSURBVFF3m1kZWdxvd98O/BuwFdhJfCnw35DFfR4glf3s/xp3jwKtwKijffNMC/ekdnzKNGZWDvwv8Cl3P3i0poMc86McTztm9k5gj7uvSvZLBjmWUX0O5BP/tf3f3f0coJ34r+pHkvH9DsaY5xIfepgAlJnZ+4/2JYMcy6g+J+l4+nnMP4NMC/es2/HJzAqIB/s97n5/cHi3BRuMB5/3BMeP1P+m4PHA4+noLcC1ZvZH4putX25mPyK7+wzxepvcfUXw/KfEwz6b+30lsMXdm929F7gfeDPZ3edEqexn/9eYWT5QBew/2jfPtHBPZleojBG8E/4DYJ27fyPh1DLgg8HjDxIfi3/t+LzgnfMpQD3wTPArX5uZXRi85s0JX5NW3P2z7j7R3ScT//N7xN3fTxb3GcDddwHbzOz04NAVwFqyu99bgQvNrDSo9QpgHdnd50Sp7Gfia72H+L+bo//2EvabEMfxpsU1xGeVbALuCLueE+zLxcR/tXoReD74uIb4WNrDwCvB55EJX3NH0PcNJMwYABqA1cG57zDEmy3p8AFcyuE3VLO+z8AsoDH48/45MCLb+w38I7A+qPe/ic8Qybo+Az8m/r5CL/Gr7I+ksp9AMXAf8d3ungFOHaomLT8gIpKFMm1YRkREkqBwFxHJQgp3EZEspHAXEclCCncRkSykcBcRyUIKdxGRLPT/AVzd9SsTx1kEAAAAAElFTkSuQmCC\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ],
      "execution_count": 3,
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "gather": {
          "logged": 1645155835165
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "print('errs')\r\n",
        "plt.plot(errs)\r\n",
        "plt.show()"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": "errs\n"
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": "<Figure size 432x288 with 1 Axes>",
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ],
      "execution_count": 4,
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "gather": {
          "logged": 1645155838130
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "print('y_std')\r\n",
        "plt.plot(y_std)\r\n",
        "plt.show()"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": "y_std\n"
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": "<Figure size 432x288 with 1 Axes>",
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ],
      "execution_count": 5,
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "gather": {
          "logged": 1645155843578
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "print('stab')\r\n",
        "plt.plot(stab)\r\n",
        "plt.show()"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": "stab\n"
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": "<Figure size 432x288 with 1 Axes>",
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ],
      "execution_count": 6,
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "gather": {
          "logged": 1645155846045
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "## test dataset \r\n",
        "errs, stab, y_std, acc = run(test_loader, fit=False, max_iters=10000) "
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": "acc: 0.82612, err: 3.17989, y_std: 0.18274, stab: 1.00000: 100%|██████████| 10000/10000 [00:35<00:00, 284.18it/s]\n"
        }
      ],
      "execution_count": 7,
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "gather": {
          "logged": 1645155895424
        }
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# hypothesis test 1: does this solve catestrophic forgetting? \r\n",
        "\r\n",
        "Least squares' sufficient statistics have finite dimension and closed-form online update equations which guarantee perfect transfer learning. \r\n",
        "Our use of one least squares estimator per deep net layer enjoys a series of such sufficient statistics, but is only heuristically simlar to the mathematical guarantees of least squares. \r\n",
        "Nevertheless, we have proceeded hypothesizing some degree of a transfer learning benefit. \r\n",
        "In this section, we test this hypothesis. \r\n",
        "\r\n",
        "To test our hypothesis, we will subsample MNIST into two parts: initial and expanded. \r\n",
        "The initial portion will include digits 0 through 7, and expanded will only include digits 8 and 9. \r\n",
        "We will first fit our model to the initial dataset and then _transfer learn_ by fitting to the expanded dataset. \r\n",
        "If our hypothesis is true, transfer learning should be maintained and thus catastrophic forgetting avoided, so we'd expect the updated model to retain the ability to predict on digits 0 through 7."
      ],
      "metadata": {
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "## build data \r\n",
        "min_train_samples = 10000 \r\n",
        "min_test_samples = 10000 \r\n",
        "\r\n",
        "def hypothesis_1_sampler(data_loader, min_samples):\r\n",
        "    '''\r\n",
        "    randomly samples data for hypothesis test 1\r\n",
        "    '''\r\n",
        "    ## init empty datasets \r\n",
        "    initial = [] \r\n",
        "    expanded = [] \r\n",
        "    for pair in tqdm(data_loader): \r\n",
        "        if pair[1] > 7: \r\n",
        "            expanded.append(pair) \r\n",
        "        else: \r\n",
        "            initial.append(pair) \r\n",
        "            pass \r\n",
        "        if len(expanded) > min_samples and len(initial) > min_samples: \r\n",
        "            return initial, expanded \r\n",
        "    return initial, expanded \r\n",
        "\r\n",
        "train_initial, train_expanded = hypothesis_1_sampler(train_loader, min_train_samples) \r\n",
        "test_initial, test_expanded = hypothesis_1_sampler(test_loader, min_test_samples) "
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": " 85%|████████▍ | 50798/60000 [00:18<00:03, 2677.87it/s]\n100%|██████████| 10000/10000 [00:03<00:00, 2931.21it/s]\n"
        }
      ],
      "execution_count": 8,
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "gather": {
          "logged": 1645155924160
        }
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Fitting on 0 through 7 "
      ],
      "metadata": {
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "## Get a fresh model \r\n",
        "hypothesis_1_model = OnlineNet( \r\n",
        "    layer_list = [ \r\n",
        "        OnlineDenseLayer(p=1*1*28*28, q=100, activation=leaky_relu, activation_inverse=inv_leaky_relu, lam=lam, clip=clip), \r\n",
        "        OnlineDenseLayer(p=100, q=100, activation=leaky_relu, activation_inverse=inv_leaky_relu, lam=lam, clip=clip), \r\n",
        "        OnlineDenseLayer(p=100, q=100, activation=leaky_relu, activation_inverse=inv_leaky_relu, lam=lam, clip=clip), \r\n",
        "        OnlineDenseLayer(p=100, q=n_labels, activation=torch.sigmoid, activation_inverse=inv_sigmoid, lam=lam, clip=clip) \r\n",
        "    ], \r\n",
        "    reregularization_frequency = reregularization_frequency, \r\n",
        "    dlamdn = dlamdn \r\n",
        ") \r\n",
        "\r\n",
        "print('fit on 0-7') \r\n",
        "_, _, _, acc_train_initial = run(train_initial, fit=True, max_iters=10000, model=hypothesis_1_model) "
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": "fit on 0-7\nDEBUG 1: err: 0.019080467522144318\nDEBUG 2: err_forward: 0.019023723900318146, err_backward: 5.6743621826171875e-05\nDEBUG 1: err: 0.012225122191011906\nDEBUG 2: err_forward: 0.01204907987266779, err_backward: 0.0001760423183441162\nDEBUG 1: err: 0.011011244729161263\nDEBUG 2: err_forward: 0.010947020724415779, err_backward: 6.42240047454834e-05\nDEBUG 1: err: 0.029025599360466003\nDEBUG 2: err_forward: 0.028838321566581726, err_backward: 0.00018727779388427734\nDEBUG 1: err: 0.016740145161747932\nDEBUG 2: err_forward: 0.016698570922017097, err_backward: 4.157423973083496e-05\nDEBUG 1: err: 0.017069635912775993\nDEBUG 2: err_forward: 0.017048684880137444, err_backward: 2.0951032638549805e-05\nDEBUG 1: err: 0.011699298396706581\nDEBUG 2: err_forward: 0.011635908856987953, err_backward: 6.338953971862793e-05\nDEBUG 1: err: 0.014313631691038609\nDEBUG 2: err_forward: 0.014283322729170322, err_backward: 3.0308961868286133e-05\nDEBUG 1: err: 0.01219306979328394\nDEBUG 2: err_forward: 0.012147561646997929, err_backward: 4.550814628601074e-05\nDEBUG 1: err: 0.01103866845369339\nDEBUG 2: err_forward: 0.01103169471025467, err_backward: 6.973743438720703e-06\nDEBUG 1: err: 0.010177083313465118\nDEBUG 2: err_forward: 0.010132409632205963, err_backward: 4.4673681259155273e-05\n"
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": "acc: 0.84589, err: 4.09607, y_std: 0.09167, stab: 1.00030:  25%|██▍       | 10000/40798 [06:56<21:22, 24.01it/s] \n"
        }
      ],
      "execution_count": 9,
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "gather": {
          "logged": 1645156354677
        }
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### test on 0 through 7 before transfer learning "
      ],
      "metadata": {
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "print('test on 0-7 before transfer learning') \r\n",
        "_, _, _, acc_test_initial_before = run(test_initial, fit=False, max_iters=10000, model=hypothesis_1_model) "
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": "acc: 0.85993, err: 3.19252, y_std: 0.18219, stab: 1.00000: 100%|██████████| 8017/8017 [00:26<00:00, 302.08it/s]\n"
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": "test on 0-7 before transfer learning\n"
        }
      ],
      "execution_count": 10,
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "gather": {
          "logged": 1645156410099
        }
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### fit on 8 and 9 "
      ],
      "metadata": {
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "print('fit on 8-9') \r\n",
        "hypothesis_1_model_copy = hypothesis_1_model.copy() \r\n",
        "## TODO\r\n",
        "hypothesis_1_model_copy.set_n_fits(100)\r\n",
        "hypothesis_1_model_copy.dlamdn = 10.\r\n",
        "_, _, _, acc_train_expanded = run(train_expanded, fit=True, max_iters=3000, model=hypothesis_1_model_copy) "
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": "fit on 8-9\nDEBUG 1: err: 40261.1953125\nDEBUG 2: err_forward: 19701.640625, err_backward: 20559.552734375\nDEBUG 1: err: 15340.6796875\nDEBUG 2: err_forward: 14863.44140625, err_backward: 477.23876953125\nDEBUG 1: err: 42995.15234375\nDEBUG 2: err_forward: 6018.93408203125, err_backward: 36976.21875\nDEBUG 1: err: 40930.86328125\nDEBUG 2: err_forward: 14528.4140625, err_backward: 26402.44921875\nDEBUG 1: err: 37543.30078125\nDEBUG 2: err_forward: 13099.775390625, err_backward: 24443.525390625\nDEBUG 1: err: 15814.798828125\nDEBUG 2: err_forward: 8149.5791015625, err_backward: 7665.21923828125\nDEBUG 1: err: 35529.0546875\nDEBUG 2: err_forward: 10784.322265625, err_backward: 24744.734375\nDEBUG 1: err: 44399.3203125\nDEBUG 2: err_forward: 22516.072265625, err_backward: 21883.24609375\nDEBUG 1: err: 34019.421875\nDEBUG 2: err_forward: 19194.6171875, err_backward: 14824.8046875\nDEBUG 1: err: 27243.560546875\nDEBUG 2: err_forward: 22439.7890625, err_backward: 4803.771484375\nDEBUG 1: err: 27798.4609375\nDEBUG 2: err_forward: 14992.97265625, err_backward: 12805.4892578125\nDEBUG 1: err: 11873.08203125\nDEBUG 2: err_forward: 9032.931640625, err_backward: 2840.15087890625\nDEBUG 1: err: 33468.57421875\nDEBUG 2: err_forward: 19950.626953125, err_backward: 13517.9462890625\nDEBUG 1: err: 958.334228515625\nDEBUG 2: err_forward: 774.3729858398438, err_backward: 183.96124267578125\nDEBUG 1: err: 36316.18359375\nDEBUG 2: err_forward: 19361.50390625, err_backward: 16954.6796875\nDEBUG 1: err: 20557.6171875\nDEBUG 2: err_forward: 16375.50390625, err_backward: 4182.11279296875\nDEBUG 1: err: 10647.2412109375\nDEBUG 2: err_forward: 9791.3701171875, err_backward: 855.871337890625\nDEBUG 1: err: 28750.208984375\nDEBUG 2: err_forward: 21111.44921875, err_backward: 7638.76025390625\nDEBUG 1: err: 30516.56640625\nDEBUG 2: err_forward: 12267.51953125, err_backward: 18249.046875\nDEBUG 1: err: 12794.80859375\nDEBUG 2: err_forward: 12358.6904296875, err_backward: 436.1185302734375\nDEBUG 1: err: 32294.880859375\nDEBUG 2: err_forward: 11755.0859375, err_backward: 20539.794921875\nDEBUG 1: err: 29621.572265625\nDEBUG 2: err_forward: 12257.4296875, err_backward: 17364.142578125\nDEBUG 1: err: 20029.02734375\nDEBUG 2: err_forward: 16908.6484375, err_backward: 3120.378173828125\nDEBUG 1: err: 7397.4248046875\nDEBUG 2: err_forward: 6154.1962890625, err_backward: 1243.228515625\nDEBUG 1: err: 10411.275390625\nDEBUG 2: err_forward: 9258.4765625, err_backward: 1152.7984619140625\n"
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": "  0%|          | 0/10001 [06:00<?, ?it/s]\n"
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-14-215f0394d37f>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mhypothesis_1_model_copy\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mset_n_fits\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m100\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mhypothesis_1_model_copy\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdlamdn\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m10.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 6\u001b[0;31m \u001b[0m_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0macc_train_expanded\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mrun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_expanded\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfit\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmax_iters\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m3000\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mhypothesis_1_model_copy\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m<ipython-input-2-da5cacace19a>\u001b[0m in \u001b[0;36mrun\u001b[0;34m(data_iterable, fit, max_iters, model)\u001b[0m\n\u001b[1;32m     85\u001b[0m         \u001b[0;31m## fit or predict\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     86\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mfit\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 87\u001b[0;31m             \u001b[0my_hat\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstability\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     88\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     89\u001b[0m             \u001b[0my_hat\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-1-2b2bab3d60fd>\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, x, y)\u001b[0m\n\u001b[1;32m    464\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0my_hat\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    465\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 466\u001b[0;31m         \u001b[0msmd_pair_list\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    467\u001b[0m         \u001b[0msmallest_smd\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__reduce_sherman_morrison_denominator_list\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msmd_pair_list\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    468\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit_count\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-1-2b2bab3d60fd>\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, eps)\u001b[0m\n\u001b[1;32m    408\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mset_ends\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    409\u001b[0m             \u001b[0;32mfor\u001b[0m \u001b[0mlayer\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlayer_list\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 410\u001b[0;31m                 \u001b[0mlayer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward_fit_temp\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    411\u001b[0m                 \u001b[0mlayer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward_fit_temp\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    412\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mset_ends\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-1-2b2bab3d60fd>\u001b[0m in \u001b[0;36mforward_fit_temp\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    139\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__validate_inputs\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mx_forward\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0my_backward\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mp\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mp\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mq\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mq\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    140\u001b[0m             \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1.\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mx_forward\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdim\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 141\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mxTx_inv_temp\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msm_denom\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msherman_morrison\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mxTx_inv\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    142\u001b[0m             \u001b[0;31m##self.xTx_inv = self.reregularizer(self.xTx_inv, self.dlamdn) ## real online regularization too slow\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    143\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mxTy_temp\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mxTy\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmatmul\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtranspose\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0my_backward\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-1-2b2bab3d60fd>\u001b[0m in \u001b[0;36msherman_morrison\u001b[0;34m(inv_mat, vec1, vec2)\u001b[0m\n\u001b[1;32m    266\u001b[0m         \u001b[0mv2t\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtranspose\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvec2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    267\u001b[0m         \u001b[0mdenominator\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m1.\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmatmul\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmatmul\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mv2t\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minv_mat\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvec1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 268\u001b[0;31m         \u001b[0mnumerator\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmatmul\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmatmul\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minv_mat\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvec1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmatmul\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mv2t\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minv_mat\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    269\u001b[0m         \u001b[0mupdated_inv_mat\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0minv_mat\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mnumerator\u001b[0m \u001b[0;34m/\u001b[0m \u001b[0mdenominator\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    270\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mupdated_inv_mat\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfloat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdenominator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ],
      "execution_count": 14,
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "gather": {
          "logged": 1640725684605
        }
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### test on 0 through 7 after transfer learning"
      ],
      "metadata": {
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "print('test on 0-7 after transfer learning') \r\n",
        "_, _, _, acc_train_initial_after = run(test_initial, fit=False, max_iters=10000, model=hypothesis_1_model_copy) "
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "gather": {
          "logged": 1640725705692
        }
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### test on 8 and 9 after transfer learning "
      ],
      "metadata": {
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "print('test on 8-9 after transfer learning') \r\n",
        "_, _, _, acc_test_expanded = run(test_expanded, fit=False, max_iters=10000, model=hypothesis_1_model_copy) "
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "gather": {
          "logged": 1640725710810
        }
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# scratch space\r\n",
        "\r\n",
        "ideas\r\n",
        "- to improve accuracies:\r\n",
        "  - larger models, likely needs GPUs \r\n",
        "  - hyperparamter tuning: try different paths for $\\frac{\\partial \\lambda}{\\partial n}(n)$\r\n",
        "- to explore strength of transfer learning result\r\n",
        "  - compare against a good competing method \r\n",
        "  - ... $\\leftarrow$ really need more here"
      ],
      "metadata": {
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "## trying to improve accuracy: using a dense net architecture found online \r\n",
        "## this is turning-out to be difficult... \r\n",
        "\r\n",
        "lam = 100. \r\n",
        "dlamdn = 10. \r\n",
        "reregularization_frequency = 1000 \r\n",
        "clip = 100. \r\n",
        "\r\n",
        "model_3 = OnlineNet( \r\n",
        "    layer_list = [ \r\n",
        "        OnlineDenseLayer(p=1*1*28*28, q=512, activation=leaky_relu, activation_inverse=inv_leaky_relu, lam=lam, clip=clip), \r\n",
        "        OnlineDenseLayer(p=512, q=n_labels, activation=torch.sigmoid, activation_inverse=inv_sigmoid, lam=lam, clip=clip) \r\n",
        "    ], \r\n",
        "    reregularization_frequency = reregularization_frequency, \r\n",
        "    dlamdn = dlamdn \r\n",
        ") \r\n",
        "\r\n",
        "print('fit on train data') \r\n",
        "_, _, _, acc_3 = run(train_loader, fit=True, max_iters=10000, model=model_3)"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": "acc: 0.76777, err: 4.23754, y_std: 0.09292, stab: 1.00047:  17%|█▋        | 10000/60000 [01:54<09:32, 87.30it/s]\n"
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": "fit on train data\n"
        }
      ],
      "execution_count": 14,
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "gather": {
          "logged": 1640725825410
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model_3_1 = model_3.copy() \r\n",
        "model_3_1.dlamdn = 100000 \r\n",
        "\r\n",
        "_, _, _, acc_3_1 = run(train_loader, fit=True, max_iters=3000, model=model_3_1)"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": "acc: 0.13335, err: 5.78938, y_std: 0.10098, stab: 1.00166:   5%|▌         | 3000/60000 [00:35<11:07, 85.40it/s]\n"
        }
      ],
      "execution_count": 15,
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "gather": {
          "logged": 1640725860508
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "## inspect \r\n",
        "p = train_initial[0]\r\n",
        "x, y = build_data(p[0], p[1]) \r\n",
        "y_hat = model_3_1(x) \r\n",
        "torch.cat((y, y_hat), dim=1) "
      ],
      "outputs": [
        {
          "output_type": "execute_result",
          "execution_count": 16,
          "data": {
            "text/plain": "tensor([[0.0500, 0.7424],\n        [0.0500, 0.8904],\n        [0.0500, 0.8776],\n        [0.0500, 0.8693],\n        [0.0500, 0.7748],\n        [0.9500, 0.7470],\n        [0.0500, 0.8215],\n        [0.0500, 0.8227],\n        [0.0500, 0.7933],\n        [0.0500, 0.7836]])"
          },
          "metadata": {}
        }
      ],
      "execution_count": 16,
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "gather": {
          "logged": 1640725860632
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "## hypothesis 2: transfer learning is robust \r\n",
        "## fit on 8-9, then 0-7 \r\n",
        "\r\n",
        "lam = 100. \r\n",
        "dlamdn = 10. \r\n",
        "reregularization_frequency = 1000 \r\n",
        "clip = 100. \r\n",
        "\r\n",
        "model_4 = OnlineNet( \r\n",
        "    layer_list = [ \r\n",
        "        OnlineDenseLayer(p=1*1*28*28, q=100, activation=leaky_relu, activation_inverse=inv_leaky_relu, lam=lam, clip=clip), \r\n",
        "        OnlineDenseLayer(p=100, q=100, activation=leaky_relu, activation_inverse=inv_leaky_relu, lam=lam, clip=clip), \r\n",
        "        OnlineDenseLayer(p=100, q=100, activation=leaky_relu, activation_inverse=inv_leaky_relu, lam=lam, clip=clip), \r\n",
        "        OnlineDenseLayer(p=100, q=n_labels, activation=torch.sigmoid, activation_inverse=inv_sigmoid, lam=lam, clip=clip) \r\n",
        "    ], \r\n",
        "    reregularization_frequency = reregularization_frequency, \r\n",
        "    dlamdn = dlamdn \r\n",
        ") \r\n",
        "\r\n",
        "print('fit on 8-9') \r\n",
        "_, _, _, _ = run(train_expanded, fit=True, max_iters=10000, model=model_4) \r\n",
        "\r\n",
        "print('test on 8-9') \r\n",
        "_, _, _, _ = run(test_expanded, fit=False, max_iters=10000, model=model_4) \r\n",
        "\r\n",
        "print('fit on 0-7') \r\n",
        "_, _, _, _ = run(train_initial, fit=True, max_iters=10000, model=model_4) \r\n",
        "\r\n",
        "print('test on 0-7') \r\n",
        "_, _, _, _ = run(test_initial, fit=False, max_iters=10000, model=model_4) \r\n",
        "\r\n",
        "print('test on 8-9') \r\n",
        "_, _, _, _ = run(test_expanded, fit=False, max_iters=10000, model=model_4) "
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": "acc: 0.80397, err: 4.42073, y_std: 0.06614, stab: 1.00017: 100%|█████████▉| 10000/10001 [01:10<00:00, 142.04it/s]\nacc: 0.76474, err: 4.31255, y_std: 0.07799, stab: 1.00000: 100%|██████████| 1983/1983 [00:05<00:00, 386.35it/s]\nacc: 0.00920, err: 4.74959, y_std: 0.01047, stab: 1.00009:  25%|██▍       | 10000/40798 [01:10<03:36, 142.38it/s]\nacc: 0.01686, err: 4.69201, y_std: 0.03374, stab: 1.00000: 100%|██████████| 8017/8017 [00:20<00:00, 385.09it/s]\nacc: 0.25299, err: 4.63899, y_std: 0.03366, stab: 1.00000: 100%|██████████| 1983/1983 [00:05<00:00, 392.06it/s]\n"
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": "fit on 8-9\ntest on 8-9\nfit on 0-7\ntest on 0-7\ntest on 8-9\n"
        }
      ],
      "execution_count": 17,
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "gather": {
          "logged": 1640726032270
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "## Does freezing lower layers help transfer learning? \r\n",
        "\r\n",
        "lam = 100. \r\n",
        "dlamdn = 10. \r\n",
        "reregularization_frequency = 1000 \r\n",
        "clip = 100. \r\n",
        "\r\n",
        "model_5 = OnlineNet( \r\n",
        "    layer_list = [ \r\n",
        "        OnlineDenseLayer(p=1*1*28*28, q=100, activation=leaky_relu, activation_inverse=inv_leaky_relu, lam=lam, clip=clip), \r\n",
        "        OnlineDenseLayer(p=100, q=100, activation=leaky_relu, activation_inverse=inv_leaky_relu, lam=lam, clip=clip), \r\n",
        "        OnlineDenseLayer(p=100, q=100, activation=leaky_relu, activation_inverse=inv_leaky_relu, lam=lam, clip=clip), \r\n",
        "        OnlineDenseLayer(p=100, q=n_labels, activation=torch.sigmoid, activation_inverse=inv_sigmoid, lam=lam, clip=clip) \r\n",
        "    ], \r\n",
        "    reregularization_frequency = reregularization_frequency, \r\n",
        "    dlamdn = dlamdn \r\n",
        ") \r\n",
        "\r\n",
        "#print('fit on 0-7') \r\n",
        "_, _, _, _ = run(train_initial, fit=True, max_iters=10000, model=model_5) \r\n",
        "\r\n",
        "#print('test on 0-7') \r\n",
        "_, _, _, _ = run(test_initial, fit=False, max_iters=10000, model=model_5) \r\n",
        "\r\n",
        "model_5.layer_list[0].trainable = False \r\n",
        "model_5.layer_list[1].trainable = False \r\n",
        "model_5.layer_list[2].trainable = False \r\n",
        "\r\n",
        "#print('fit on 8-9') \r\n",
        "_, _, _, _ = run(train_expanded, fit=True, max_iters=10000, model=model_5) \r\n",
        "\r\n",
        "#print('test on 8-9') \r\n",
        "_, _, _, _ = run(test_expanded, fit=False, max_iters=10000, model=model_5) \r\n",
        "#print('test on 0-7') \r\n",
        "_, _, _, _ = run(test_initial, fit=False, max_iters=10000, model=model_5) "
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": "acc: 0.66772, err: 4.67209, y_std: 0.02354, stab: 5.00000:  25%|██▍       | 10000/40798 [01:05<03:23, 151.59it/s]\nacc: 0.68942, err: 4.20784, y_std: 0.09580, stab: 1.00000: 100%|██████████| 8017/8017 [00:21<00:00, 381.67it/s]\nacc: 0.57032, err: 4.62903, y_std: 0.03707, stab: 5.00000: 100%|█████████▉| 10000/10001 [00:40<00:00, 245.54it/s]\nacc: 0.58905, err: 4.67013, y_std: 0.03525, stab: 1.00000: 100%|██████████| 1983/1983 [00:05<00:00, 371.48it/s]\nacc: 0.39470, err: 4.24401, y_std: 0.09614, stab: 1.00000: 100%|██████████| 8017/8017 [00:21<00:00, 380.89it/s]\n"
        }
      ],
      "execution_count": 24,
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "gather": {
          "logged": 1640727298020
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "## Does freezing lower layers help transfer learning? This time, without reregularization. \r\n",
        "\r\n",
        "lam = 100. \r\n",
        "dlamdn = 10. \r\n",
        "reregularization_frequency = 1000 \r\n",
        "clip = 100. \r\n",
        "\r\n",
        "model_6 = OnlineNet( \r\n",
        "    layer_list = [ \r\n",
        "        OnlineDenseLayer(p=1*1*28*28, q=100, activation=leaky_relu, activation_inverse=inv_leaky_relu, lam=lam, clip=clip), \r\n",
        "        OnlineDenseLayer(p=100, q=100, activation=leaky_relu, activation_inverse=inv_leaky_relu, lam=lam, clip=clip), \r\n",
        "        OnlineDenseLayer(p=100, q=100, activation=leaky_relu, activation_inverse=inv_leaky_relu, lam=lam, clip=clip), \r\n",
        "        OnlineDenseLayer(p=100, q=n_labels, activation=torch.sigmoid, activation_inverse=inv_sigmoid, lam=lam, clip=clip) \r\n",
        "    ], \r\n",
        "    reregularization_frequency = reregularization_frequency, \r\n",
        "    dlamdn = dlamdn \r\n",
        ") \r\n",
        "\r\n",
        "#print('fit on 0-7') \r\n",
        "_, _, _, _ = run(train_initial, fit=True, max_iters=10000, model=model_6) \r\n",
        "\r\n",
        "#print('test on 0-7') \r\n",
        "_, _, _, _ = run(test_initial, fit=False, max_iters=10000, model=model_6) \r\n",
        "\r\n",
        "model_6.dlamdn = None \r\n",
        "model_6.layer_list[0].trainable = False \r\n",
        "model_6.layer_list[1].trainable = False \r\n",
        "model_6.layer_list[2].trainable = False \r\n",
        "model_6.layer_list[3].dlamdn = None \r\n",
        "\r\n",
        "#print('fit on 8-9') \r\n",
        "_, _, _, _ = run(train_expanded, fit=True, max_iters=10000, model=model_6) \r\n",
        "\r\n",
        "#print('test on 8-9') \r\n",
        "_, _, _, _ = run(test_expanded, fit=False, max_iters=10000, model=model_6) \r\n",
        "#print('test on 0-7') \r\n",
        "_, _, _, _ = run(test_initial, fit=False, max_iters=10000, model=model_6) "
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": "acc: 0.66772, err: 4.67209, y_std: 0.02354, stab: 5.00000:  25%|██▍       | 10000/40798 [01:08<03:30, 146.21it/s]\nacc: 0.68942, err: 4.20784, y_std: 0.09580, stab: 1.00000: 100%|██████████| 8017/8017 [00:21<00:00, 378.78it/s]\nacc: 0.57082, err: 4.62437, y_std: 0.03780, stab: 5.00000: 100%|█████████▉| 10000/10001 [00:36<00:00, 275.91it/s]\nacc: 0.59003, err: 4.65936, y_std: 0.03680, stab: 1.00000: 100%|██████████| 1983/1983 [00:05<00:00, 376.05it/s]\nacc: 0.39056, err: 4.23951, y_std: 0.09700, stab: 1.00000: 100%|██████████| 8017/8017 [00:21<00:00, 381.20it/s]\n"
        }
      ],
      "execution_count": 25,
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "gather": {
          "logged": 1640727762587
        }
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Conclusion\r\n",
        "\r\n",
        "In theory, a least squares model should be capable of perfect transfer learning. That's not showing-up here. There's a little potential shown in "
      ],
      "metadata": {
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# scatch space \r\n",
        "\r\n",
        "$\\hat \\theta_{MLE} := \\text{arg max}_\\theta f_X(X; \\theta) = \\text{arg max}_\\theta n^{-1} f_X(X; \\theta) \\to \\text{arg max}_\\theta \\mathbb{E} f_X(X; \\theta) \\text{ as } {n \\to \\infty} $\r\n",
        "\r\n",
        "$\\hat \\beta := \\text{arg min}_\\beta \\|y - x \\beta \\|^2 + \\lambda(n) \\| \\beta \\|^2 = \\left( x^Tx + \\lambda(n) \\right)^{-1} x^Ty = \\left(X_{n-1}^TX_{n-1} + x_n^T x_n + \\lambda(n) \\right)^{-1} \\left(X_{n-1}^TY_{n-1} + x_n^T y_n \\right) $\r\n",
        "\r\n",
        "$ = \\frac{n}{n} \\left( x^Tx + \\lambda(n) \\right)^{-1} x^Ty $\r\n",
        "\r\n",
        "$ = \\left( \\frac{x^Tx}{n} + \\frac{\\lambda(n)}{n} \\right)^{-1} \\frac{x^Ty}{n} $\r\n",
        "\r\n",
        "Apply the SLLN $\\left( n^{-1}\\sum_{i=1}^n X_i \\to \\mathbb{E}X_1 \\text{ a.s. if } X_i \\text{ iid} \\right)$.\r\n",
        "\r\n",
        "$ = \\left( \\mathbb{E}X^TX + \\frac{\\lambda(n)}{n} \\right)^{-1} \\mathbb{E}X^TY $"
      ],
      "metadata": {
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      }
    }
  ],
  "metadata": {
    "kernelspec": {
      "name": "python3-azureml",
      "language": "python",
      "display_name": "Python 3.6 - AzureML"
    },
    "language_info": {
      "name": "python",
      "version": "3.6.9",
      "mimetype": "text/x-python",
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "pygments_lexer": "ipython3",
      "nbconvert_exporter": "python",
      "file_extension": ".py"
    },
    "kernel_info": {
      "name": "python3-azureml"
    },
    "nteract": {
      "version": "nteract-front-end@1.0.0"
    },
    "microsoft": {
      "host": {
        "AzureML": {
          "notebookHasBeenCompleted": true
        }
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 2
}