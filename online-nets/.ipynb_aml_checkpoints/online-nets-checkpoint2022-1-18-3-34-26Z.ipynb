{
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# online nets\r\n",
        "\r\n",
        "Deep learning is powerful but computationally expensive, frequently requiring massive compute budgets. In persuit of cost-effective-yet-powerful AI, this work explores and evaluates a heuristic which should lend to more-efficient use of data through online learning.\r\n",
        "\r\n",
        "Goal: evaluate a deep learning alternative capable of true online learning. Solution requirements:\r\n",
        "\r\n",
        "1. catastrophic forgetting should be impossible;\r\n",
        "2. all data is integrated into sufficient statistics of fixed dimension;\r\n",
        "3. and our solution should have predictive power comparable to deep learning.\r\n",
        "\r\n",
        "## modeling strategy\r\n",
        "\r\n",
        "We will not attempt to derive sufficient statistics for an entire deep net, but instead leverage well-known sufficient statistics for least squares models, \r\n",
        "so will have sufficient statistics per deep net layer. If this can be empirically shown effective, we'll build-out the theory afterwards. \r\n",
        "\r\n",
        "Recognizing a deep net as a series of compositions, as follows.\r\n",
        "\r\n",
        "$ Y + \\varepsilon \\approx \\mathbb{E}Y = \\sigma_3 \\circ \\beta_3^T \\circ \\sigma_2 \\circ \\beta_2^T \\circ \\sigma_1 \\circ \\beta_1^T X $\r\n",
        "\r\n",
        "So, we can isolate invidivdual $\\beta_j$ matrices using (psuedo-)inverses $\\beta_j^{-1}$ like so.\r\n",
        "\r\n",
        "$ \\sigma_2^{-1} \\circ \\beta_3^{-1} \\circ \\sigma_3^{-1} (Y) \\approx  \\beta_2^T \\circ \\sigma_1 \\circ \\beta_1^T X $\r\n",
        "\r\n",
        "In this example, if we freeze all $\\beta_j$'s except $\\beta_2$, we are free to update $\\hat \\beta_2$ using $\\tilde Y = \\sigma_2^{-1} \\circ \\beta_3^{-1} \\circ \\sigma_3^{-1} (Y) $\r\n",
        "and $\\tilde X = \\sigma_1 \\circ \\beta_1^T X $.\r\n",
        "\r\n",
        "Using a least squares formulation for fitting to $\\left( \\tilde X, \\tilde Y \\right)$, we get sufficient statistics per layer."
      ],
      "metadata": {
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# model code definitions"
      ],
      "metadata": {
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "\n",
        "TORCH_TENSOR_TYPE = type(torch.tensor(1)) \n",
        "\n",
        "def iterated_diagonals(diag_value, n_rows, n_cols): \n",
        "    ## construct diagonal matrix \n",
        "    n_diag = min(n_rows, n_cols)\n",
        "    diag = torch.diag(torch.tensor([diag_value]*n_diag))\n",
        "    if n_rows > n_cols: \n",
        "        ## pad rows \n",
        "        pad = n_rows//n_cols + 1\n",
        "        return torch.cat([diag]*pad, 0)[:n_rows, :n_cols] \n",
        "    if n_cols > n_rows: \n",
        "        ## pad cols \n",
        "        pad = n_cols//n_rows + 1 \n",
        "        return torch.cat([diag]*pad, 1)[:n_rows, :n_cols] \n",
        "    ## no padding \n",
        "    return diag \n",
        "\n",
        "class OnlineDenseLayer: \n",
        "    ''' \n",
        "    A single dense net, formulated as a least squares model. \n",
        "    ''' \n",
        "    def __init__(self, p, q, activation=lambda x:x, activation_inverse=lambda x:x, lam=1., clip=10000., dlamdn=0.): \n",
        "        ''' \n",
        "        inputs: \n",
        "        - p: input dimension \n",
        "        - q: output dimension \n",
        "        - activation: non-linear function, from R^p to R^q. Default is identity. \n",
        "        - activation_inverse: inverse of the activation function. Default is identity. \n",
        "        - lam: regularization term \n",
        "        - clip: predicted value clipping limit \n",
        "        - dlamdn: rate of lambda growth relative to n for online regularization \n",
        "        ''' \n",
        "        lam = float(lam) \n",
        "        clip = float(clip) \n",
        "        if dlamdn is not None: \n",
        "            dlamdn = float(dlamdn)\n",
        "        self.__validate_inputs(p=p, q=q, lam=lam, clip=clip, dlamdn=dlamdn) \n",
        "        self.p = p \n",
        "        self.q = q \n",
        "        self.n_fits = 0 \n",
        "        self.clip = clip \n",
        "        self.trainable = True \n",
        "        self.activation = activation \n",
        "        self.activation_inverse = activation_inverse \n",
        "        self.batch_norm_forward_mean = None \n",
        "        self.batch_norm_forward_std = None \n",
        "        self.batch_norm_forward_n = 0 \n",
        "        self.batch_norm_backward_mean = None \n",
        "        self.batch_norm_backward_std = None \n",
        "        self.batch_norm_backward_n = 0 \n",
        "        self.lam = lam \n",
        "        self.dlamdn = dlamdn \n",
        "        self.xTy = iterated_diagonals(lam, p+1,q) # +1 for intercept \n",
        "        self.yTx = iterated_diagonals(lam, q+1,p) \n",
        "        self.xTx_inv = torch.diag(torch.tensor([1./lam]*(p+1))) \n",
        "        self.yTy_inv = torch.diag(torch.tensor([1./lam]*(q+1))) \n",
        "        self.betaT_forward = torch.matmul(self.xTx_inv, self.xTy) \n",
        "        self.betaT_forward = torch.transpose(self.betaT_forward, 0, 1) \n",
        "        self.betaT_backward = torch.matmul(self.yTy_inv, self.yTx) \n",
        "        self.betaT_backward = torch.transpose(self.betaT_backward, 0, 1) \n",
        "        self.x_forward = None \n",
        "        self.y_forward = None \n",
        "        self.x_backward = None \n",
        "        self.y_backward = None \n",
        "        pass \n",
        "    def copy(self): \n",
        "        copied_layer = OnlineDenseLayer(self.p, self.q)\n",
        "        copied_layer.p = self.p \n",
        "        copied_layer.q = self.q \n",
        "        copied_layer.n_fits = self.n_fits \n",
        "        copied_layer.clip = self.clip \n",
        "        copied_layer.trainable = self.trainable \n",
        "        copied_layer.activation = self.activation \n",
        "        copied_layer.activation_inverse = self.activation_inverse \n",
        "        copied_layer.batch_norm_forward_mean = self.batch_norm_forward_mean \n",
        "        copied_layer.batch_norm_forward_std = self.batch_norm_forward_std \n",
        "        copied_layer.batch_norm_forward_n = self.batch_norm_forward_n \n",
        "        copied_layer.batch_norm_backward_mean = self.batch_norm_backward_mean \n",
        "        copied_layer.batch_norm_backward_std = self.batch_norm_backward_std \n",
        "        copied_layer.batch_norm_backward_n = self.batch_norm_backward_n \n",
        "        copied_layer.lam = self.lam \n",
        "        copied_layer.dlamdn = self.dlamdn \n",
        "        copied_layer.xTy = self.xTy.clone() \n",
        "        copied_layer.yTx = self.yTx.clone()\n",
        "        copied_layer.betaT_forward = self.betaT_forward.clone()\n",
        "        copied_layer.betaT_backward = self.betaT_backward.clone()\n",
        "        self.x_forward = None \n",
        "        self.y_forward = None \n",
        "        self.x_backward = None \n",
        "        self.y_backward = None\n",
        "        return copied_layer \n",
        "    def forward(self, x): \n",
        "        'creates and stores x_forward and y_forward, then returns activation(y_forward)' \n",
        "        self.__validate_inputs(x=x, p=self.p)  \n",
        "        x = self.batch_norm(x, forward=True) ## TODO use fitting or not \n",
        "        self.x_forward = x\n",
        "        x = torch.cat((torch.tensor([[1.]]), x), dim=0) # intercept \n",
        "        self.y_forward = torch.matmul(self.betaT_forward, x) # predict \n",
        "        self.y_forward = torch.clip(self.y_forward, -self.clip, self.clip)\n",
        "        return self.activation(self.y_forward) \n",
        "    def backward(self, y): \n",
        "        'creates and stores x_backward and y_backward, then returns y_backward' \n",
        "        y = self.activation_inverse(y) \n",
        "        self.__validate_inputs(y=y, q=self.q) \n",
        "        y = self.batch_norm(y, forward=False) ## TODO use fitting or not\n",
        "        self.y_backward = y \n",
        "        y = torch.cat((torch.tensor([[1.]]), y), dim=0) \n",
        "        self.x_backward = torch.matmul(self.betaT_backward, y) \n",
        "        self.x_backward = torch.clip(self.x_backward, -self.clip, self.clip)\n",
        "        return self.x_backward \n",
        "    def forward_fit(self): \n",
        "        'uses x_forward and y_backward to update forward model, then returns Sherman Morrison denominator' \n",
        "        if self.trainable: \n",
        "            self.__validate_inputs(x=self.x_forward, y=self.y_backward, p=self.p, q=self.q) \n",
        "            x = torch.cat((torch.tensor([[1.]]), self.x_forward), dim=0) \n",
        "            self.xTx_inv, sm_denom = self.sherman_morrison(self.xTx_inv, x, x) \n",
        "            ##self.xTx_inv = self.reregularizer(self.xTx_inv, self.dlamdn) ## real online regularization too slow \n",
        "            self.xTy += torch.matmul(x, torch.transpose(self.y_backward, 0, 1)) \n",
        "            self.betaT_forward = torch.matmul(self.xTx_inv, self.xTy) \n",
        "            self.betaT_forward = torch.transpose(self.betaT_forward, 0, 1) \n",
        "        return sm_denom \n",
        "    def backward_fit(self):\n",
        "        'uses x_backward and y_forward to update backward model, then returns Sherman Morrison denominator' \n",
        "        if self.trainable: \n",
        "            self.__validate_inputs(x=self.x_forward, y=self.y_backward, p=self.p, q=self.q) \n",
        "            y = torch.cat((torch.tensor([[1.]]), self.y_backward), dim=0) \n",
        "            self.yTy_inv, sm_denom = self.sherman_morrison(self.yTy_inv, y, y) \n",
        "            ##self.yTy_inv = self.reregularizer(self.yTy_inv, self.dlamdn) \n",
        "            self.yTx += torch.matmul(y, torch.transpose(self.x_backward, 0, 1)) \n",
        "            self.betaT_backward = torch.matmul(self.yTy_inv, self.yTx) \n",
        "            self.betaT_backward = torch.transpose(self.betaT_backward, 0, 1) \n",
        "            self.n_fits += 1 ## TODO write general fitting function \n",
        "        return sm_denom \n",
        "    def forward_fit_temp(self): \n",
        "        'uses x_forward and y_backward to update forward model, then returns Sherman Morrison denominator' \n",
        "        if self.trainable: \n",
        "            self.__validate_inputs(x=self.x_forward, y=self.y_backward, p=self.p, q=self.q) \n",
        "            x = torch.cat((torch.tensor([[1.]]), self.x_forward), dim=0) \n",
        "            self.xTx_inv_temp, sm_denom = self.sherman_morrison(self.xTx_inv, x, x) \n",
        "            ##self.xTx_inv = self.reregularizer(self.xTx_inv, self.dlamdn) ## real online regularization too slow \n",
        "            self.xTy_temp = self.xTy + torch.matmul(x, torch.transpose(self.y_backward, 0, 1)) \n",
        "            self.betaT_forward_temp = torch.matmul(self.xTx_inv_temp, self.xTy_temp) \n",
        "            self.betaT_forward_temp = torch.transpose(self.betaT_forward_temp, 0, 1) \n",
        "        return sm_denom \n",
        "    def backward_fit_temp(self):\n",
        "        'uses x_backward and y_forward to update backward model, then returns Sherman Morrison denominator' \n",
        "        if self.trainable: \n",
        "            self.__validate_inputs(x=self.x_forward, y=self.y_backward, p=self.p, q=self.q) \n",
        "            y = torch.cat((torch.tensor([[1.]]), self.y_backward), dim=0) \n",
        "            self.yTy_inv_temp, sm_denom = self.sherman_morrison(self.yTy_inv, y, y) \n",
        "            ##self.yTy_inv = self.reregularizer(self.yTy_inv, self.dlamdn) \n",
        "            self.yTx_temp = self.yTx + torch.matmul(y, torch.transpose(self.x_backward, 0, 1)) \n",
        "            self.betaT_backward_temp = torch.matmul(self.yTy_inv_temp, self.yTx_temp) \n",
        "            self.betaT_backward_temp = torch.transpose(self.betaT_backward_temp, 0, 1) \n",
        "            #self.n_fits += 1 ## TODO write general fitting function \n",
        "        return sm_denom \n",
        "    def forward_temp(self, x): \n",
        "        'creates and stores x_forward and y_forward, then returns activation(y_forward)' \n",
        "        self.__validate_inputs(x=x, p=self.p)  \n",
        "        x = self.batch_norm(x, forward=True) ## TODO use fitting or not \n",
        "        self.x_forward = x\n",
        "        x = torch.cat((torch.tensor([[1.]]), x), dim=0) # intercept \n",
        "        self.y_forward = torch.matmul(self.betaT_forward_temp, x) # predict \n",
        "        self.y_forward = torch.clip(self.y_forward, -self.clip, self.clip)\n",
        "        return self.activation(self.y_forward) \n",
        "    def backward_temp(self, y): \n",
        "        'creates and stores x_backward and y_backward, then returns y_backward' \n",
        "        y = self.activation_inverse(y) \n",
        "        self.__validate_inputs(y=y, q=self.q) \n",
        "        y = self.batch_norm(y, forward=False) ## TODO use fitting or not\n",
        "        self.y_backward = y \n",
        "        y = torch.cat((torch.tensor([[1.]]), y), dim=0) \n",
        "        self.x_backward = torch.matmul(self.betaT_backward_temp, y) \n",
        "        self.x_backward = torch.clip(self.x_backward, -self.clip, self.clip)\n",
        "        return self.x_backward \n",
        "    def set_n_fits(self, n):\n",
        "        'resizes sufficient statistic matrices to sample size n'\n",
        "        if n < 1 or self.n_fits < 1:\n",
        "            return None \n",
        "        self.xTy *= n/self.n_fits \n",
        "        self.yTx *= n/self.n_fits \n",
        "        self.xTx_inv *= self.n_fits/n \n",
        "        self.yTy_inv *= self.n_fits/n \n",
        "        self.n_fits = n \n",
        "        pass\n",
        "    def batch_norm(self, x, forward, fitting=True):\n",
        "        '''\n",
        "        batch normalize tensor\n",
        "        inputs:\n",
        "        - x: (tensor) to be normalized \n",
        "        - forward: (boolean) indicates prediction is forward, instead of backward \n",
        "        - fitting: (boolean) if in model fitting, update values \n",
        "        '''\n",
        "        ## retrieve \n",
        "        if forward:\n",
        "            m = self.batch_norm_forward_mean \n",
        "            s = self.batch_norm_forward_std\n",
        "            n = self.batch_norm_forward_n \n",
        "        else: \n",
        "            m = self.batch_norm_backward_mean \n",
        "            s = self.batch_norm_backward_std\n",
        "            n = self.batch_norm_backward_n \n",
        "        ## caculate \n",
        "        if n == 0: \n",
        "            n = 1 \n",
        "            m = x.mean() \n",
        "            s = x.std() \n",
        "        else: \n",
        "            n += 1 \n",
        "            m = x.mean()/n + m*(n-1)/n \n",
        "            s = x.std()/n + s*(n-1)/n \n",
        "        ## store \n",
        "        if fitting:\n",
        "            if forward: \n",
        "                self.batch_norm_forward_mean = m \n",
        "                self.batch_norm_forward_std = s \n",
        "                self.batch_norm_forward_n = n \n",
        "            else: \n",
        "                self.batch_norm_backward_mean = m\n",
        "                self.batch_norm_backward_std = s \n",
        "                self.batch_norm_backward_n = n \n",
        "        ## no dividing by zero \n",
        "        if s < 1e-3:\n",
        "            s = 1e-3 \n",
        "        return (x - m)/s \n",
        "    def reregularize(self, dlamdn=None): \n",
        "        if dlamdn is None:\n",
        "            dlamdn = self.dlamdn \n",
        "        self.xTx_inv = self.online_regularizer(self.xTx_inv, dlamdn) \n",
        "        self.yTy_inv = self.online_regularizer(self.yTy_inv, dlamdn) \n",
        "        pass \n",
        "    @staticmethod\n",
        "    def online_regularizer(m_inv, dlam):\n",
        "        '''\n",
        "        Used to expand the regularization sphere as samples grow.\n",
        "        Applies modified Sherman Morrison formula for numerical efficiency. \n",
        "        inputs\n",
        "        - m_inv: inverse matrix of m \n",
        "        - dlam: regularizer to be added on the diagonal \n",
        "        returns\n",
        "         - (m + 1/dlam)^{-1} \n",
        "        '''\n",
        "        if dlam == 0. or dlam is None:\n",
        "            ## avoid degeneracy \n",
        "            return m_inv \n",
        "        if callable(dlam):\n",
        "            dlam = dlam(self.n_fits) \n",
        "        dlam_inv = 1/dlam \n",
        "        for i in range(m_inv.shape[0]): \n",
        "            m_inv -= dlam_inv * torch.matmul(m_inv[:,i].reshape((-1,1)), m_inv[i,:].reshape((1,-1))) / (1. + dlam_inv * m_inv[i,i]) \n",
        "        return m_inv  \n",
        "    @staticmethod \n",
        "    def sherman_morrison(inv_mat, vec1, vec2): \n",
        "        ''' \n",
        "        applies Sherman Morrison updates, (mat + vec1 vec2^T)^{-1} \n",
        "        inputs: \n",
        "        - inv_mat: an inverted matrix \n",
        "        - vec1: a column vector \n",
        "        - vec2: a column vector \n",
        "        returns: \n",
        "        - updated matrix \n",
        "        - the Sherman Morrison denominator, for tracking numerical stability \n",
        "        ''' \n",
        "        v2t = torch.transpose(vec2, 0, 1)\n",
        "        denominator = 1. + torch.matmul(torch.matmul(v2t, inv_mat), vec1) \n",
        "        numerator = torch.matmul(torch.matmul(inv_mat, vec1), torch.matmul(v2t, inv_mat)) \n",
        "        updated_inv_mat = inv_mat - numerator / denominator \n",
        "        return updated_inv_mat, float(denominator) \n",
        "    def __validate_inputs(self, p=None, q=None, lam=None, x=None, y=None, clip=None, dlamdn=None): \n",
        "        'raises value exceptions if provided parameters are invalid'\n",
        "        if q is not None:\n",
        "            if not isinstance(q, int):\n",
        "                raise ValueError('`q` must be int!')\n",
        "            if q <= 0:\n",
        "                raise ValueError('`q` must be greater than zero!')\n",
        "        if p is not None:\n",
        "            if not isinstance(p, int): \n",
        "                raise ValueError('`p` must be int!')\n",
        "            if p <= 0: \n",
        "                raise ValueError('`p` must be greater than zero!')\n",
        "        if lam is not None:\n",
        "            if not (isinstance(lam, float) or isinstance(lam, int)):\n",
        "                raise ValueError('`lam` must be float or int!')\n",
        "            if lam < 0:\n",
        "                raise ValueError('`lam` must be non-negative!')\n",
        "        if x is not None and p is not None: \n",
        "            if type(x) != TORCH_TENSOR_TYPE:\n",
        "                raise ValueError('`x` must be of type `torch.tensor`!') \n",
        "            if list(x.shape) != [p,1]: \n",
        "                raise ValueError('`x.shape` must be `[p,1]`!') \n",
        "            if torch.isnan(x).any():\n",
        "                raise ValueError('`x` contains `nan`!')\n",
        "            pass \n",
        "        if y is not None and q is not None: \n",
        "            if type(y) != TORCH_TENSOR_TYPE:\n",
        "                raise ValueError('`y` must be of type `torch.tensor`!') \n",
        "            if list(y.shape) != [q,1]: \n",
        "                raise ValueError('`y.shape` must be `[q,1]`') \n",
        "            if torch.isnan(y).any():\n",
        "                raise ValueError('`y` contains `nan`!')\n",
        "            pass  \n",
        "        if clip is not None: \n",
        "            if type(clip) != float:\n",
        "                raise ValueError('`clip` my be of type `float`!') \n",
        "            if clip <= 0.: \n",
        "                raise ValueError('`clip` must be positive!')\n",
        "            pass\n",
        "        if dlamdn is not None: \n",
        "            if type(dlamdn) not in [float, callable]: \n",
        "                raise ValueError('`dlamdn` my be of type `float` or `callable`!') \n",
        "            if type(dlamdn) == float:\n",
        "                if dlamdn < 0.: \n",
        "                    raise ValueError('`dlamdn` must be non-negative!') \n",
        "            pass\n",
        "        pass\n",
        "    pass\n",
        "\n",
        "class OnlineNet: \n",
        "    'online, sequential dense net' \n",
        "    def __init__(self, layer_list, dlamdn=0., reregularization_frequency=1000): \n",
        "        '''\n",
        "        initialize an online dense net\n",
        "        inputs:\n",
        "        - layer_list: list of OnlineDenseLayers \n",
        "        - dlamdn: (float >= 0) regularization rate per n. Disabled if zero \n",
        "        - reregularization_frequency: (int > 0) reregularize after fitting this number of samples, since reregularization is computationally expensive\n",
        "        '''\n",
        "        ## validate inputs \n",
        "        if type(layer_list) != list: \n",
        "            raise ValueError('`layer_list` must be of type list!') \n",
        "        for layer in layer_list: \n",
        "            if not issubclass(type(layer), OnlineDenseLayer):\n",
        "                raise ValueError('each item in `layer_list` must be an instance of a subclass of `OnlineDenseLayer`!') \n",
        "        if type(dlamdn) != float: \n",
        "            raise ValueError('`dlamdn` must of type `float`!') \n",
        "        if dlamdn < 0.: \n",
        "            raise ValueError('`dlamdn` must be non-negative!') \n",
        "        if type(reregularization_frequency) != int: \n",
        "            raise ValueError('`reregularization_frequency` must be of type `int`!') \n",
        "        if reregularization_frequency <= 0: \n",
        "            raise ValueError('`reregularization_frequency` must be postive!') \n",
        "        ## assign \n",
        "        self.layer_list = layer_list \n",
        "        self.fit_count = 0 \n",
        "        self.dlamdn = dlamdn \n",
        "        self.reregularization_frequency = reregularization_frequency \n",
        "        pass \n",
        "    def copy(self):\n",
        "        copied_layers = [] \n",
        "        for layer in self.layer_list:\n",
        "            copied_layers.append(layer.copy()) \n",
        "        copied_net = OnlineNet(copied_layers, \n",
        "                dlamdn=self.dlamdn, \n",
        "                reregularization_frequency=self.reregularization_frequency)\n",
        "        return copied_net \n",
        "    def forward(self, x): \n",
        "        'predict forward'\n",
        "        for layer in self.layer_list:\n",
        "            x = layer.forward(x) \n",
        "        return x \n",
        "    def backward(self, y):\n",
        "        'predict backward'\n",
        "        for layer in reversed(self.layer_list): \n",
        "            y = layer.backward(y) \n",
        "        return y \n",
        "    def forward_temp(self, x): \n",
        "        'predicts forward with temporary statistics, returns errors' \n",
        "        err = 0. \n",
        "        n_layers = len(self.layer_list) \n",
        "        for idx, layer in enumerate(self.layer_list):\n",
        "            x_old = layer.activation(layer.y_forward) \n",
        "            x = layer.forward_temp(x) \n",
        "            if idx + 1 < n_layers:\n",
        "                ## ignore observed variables \n",
        "                err += (x_old - x).abs().sum() \n",
        "        return err \n",
        "    def backward_temp(self, y):\n",
        "        'predicts backward with temporary statistics, returns errors' \n",
        "        err = 0.\n",
        "        n_layers = len(self.layer_list) \n",
        "        for idx, layer in enumerate(reversed(self.layer_list)):\n",
        "            y_old = layer.x_backward \n",
        "            y = layer.backward_temp(y)\n",
        "            if idx + 1 < n_layers: \n",
        "                ## ignore observed variables \n",
        "                err += (y_old - y).abs().sum() \n",
        "            #print(f'DEBUG 3: cumulative err: {err}')\n",
        "        return err \n",
        "    def set_n_fits(self, n):\n",
        "        'resizes sufficient statistic matrices to sample size n'\n",
        "        for layer in self.layer_list:\n",
        "            layer.set_n_fits(n)\n",
        "        pass \n",
        "    def fit(self, x, y, eps=.01):#1e-6): ## TODO get convergance guarantee, & remove cherry-picked eps\n",
        "        'integrates observation pair. Returns Sherman Morrison denominators per layer in (forward, backward) pairs in a list'\n",
        "        ## set intermediary predictions \n",
        "        self.set_ends(x,y)\n",
        "        self.forward(x) \n",
        "        self.backward(y) \n",
        "        ## infer intermediary vectors before keeping them \n",
        "        ## this'll keep matrix sizes aligned with sample sizes \n",
        "        err = 1. + eps  \n",
        "        idx = 0 \n",
        "        while err > eps: \n",
        "            idx += 1 \n",
        "            self.set_ends(x,y)\n",
        "            for layer in self.layer_list: \n",
        "                layer.forward_fit_temp() \n",
        "                layer.backward_fit_temp() \n",
        "            self.set_ends(x,y) \n",
        "            err_forward = self.forward_temp(x)\n",
        "            err_backward = self.backward_temp(y) \n",
        "            err = err_forward + err_backward \n",
        "            if idx % 1000 == 0:\n",
        "                print(f'DEBUG 1: err: {err}') \n",
        "                print(f'DEBUG 2: err_forward: {err_forward}, err_backward: {err_backward}') \n",
        "        ## iterate once more, but keep sufficient statistics \n",
        "        sherman_morrison_denominator_list = [] \n",
        "        for layer in self.layer_list: \n",
        "            forward_smd = layer.forward_fit() \n",
        "            backward_smd = layer.backward_fit() \n",
        "            sherman_morrison_denominator_list.append((forward_smd, backward_smd)) \n",
        "        return sherman_morrison_denominator_list \n",
        "    def reregularize(self, dlamdn=None): \n",
        "        for layer in self.layer_list: \n",
        "            layer.reregularize(dlamdn) \n",
        "            pass \n",
        "        pass \n",
        "    def set_ends(self, x, y):\n",
        "        'resets observations at network ends'\n",
        "        self.layer_list[0].x_forward = x \n",
        "        self.layer_list[0].x_backward = x \n",
        "        self.layer_list[-1].y_forward = y \n",
        "        self.layer_list[-1].y_backward = y \n",
        "        pass \n",
        "    def __reduce_sherman_morrison_denominator_list(self, smd_pair_list):\n",
        "        'returns the value closest to zero'\n",
        "        if type(smd_pair_list) != list: \n",
        "            raise ValueError('`smd_pair_list` must be of type `list`!')\n",
        "        if len(smd_pair_list) == 0:\n",
        "            return None \n",
        "        smallest_smd = None \n",
        "        for smd_pair in smd_pair_list:\n",
        "            if type(smd_pair) != tuple:\n",
        "                raise ValueError('`smd_pair_list` must be list of tuples!')\n",
        "            if smallest_smd is None: \n",
        "                smallest_smd = smd_pair[0] \n",
        "            if abs(smallest_smd) > abs(smd_pair[0]): \n",
        "                smallest_smd = smd_pair[0] \n",
        "            if abs(smallest_smd) > abs(smd_pair[1]):\n",
        "                smallest_smd = smd_pair[1] \n",
        "        return float(smallest_smd) \n",
        "    def __call__(self, x, y=None): \n",
        "        '''\n",
        "        If only x is given, a prediction is made and returned.\n",
        "        If x and y are given, then the model is updated, and returns\n",
        "        - the prediction\n",
        "        - the sherman morrison denominator closest to zero, for tracking numerical stability\n",
        "        '''\n",
        "        y_hat = self.forward(x) \n",
        "        if y is None: \n",
        "            return y_hat \n",
        "        self.backward(y) \n",
        "        smd_pair_list = self.fit(x,y) \n",
        "        smallest_smd = self.__reduce_sherman_morrison_denominator_list(smd_pair_list) \n",
        "        self.fit_count += 1 \n",
        "        if self.fit_count % self.reregularization_frequency == 0:\n",
        "            if self.dlamdn is not None: \n",
        "                ## dividing by self.reregularization_frequency ensures mathematical equivalency to reregularizing with every step \n",
        "                self.reregularize(self.dlamdn/self.reregularization_frequency) \n",
        "            else:\n",
        "                ## use per-layer dlamdn values \n",
        "                self.reregularize() \n",
        "        return y_hat, smallest_smd \n",
        "\n",
        "## tests \n",
        "\n",
        "## test 1: sherman morrison \n",
        "a = torch.tensor([[2., 1.], [1., 2.]]) \n",
        "b = torch.tensor([[.1],[.2]]) \n",
        "sm_inv, _ = OnlineDenseLayer.sherman_morrison(torch.inverse(a),b,b) \n",
        "num_inv = torch.inverse(a+torch.matmul(b, torch.transpose(b,0,1))) \n",
        "err = float(torch.abs(sm_inv - num_inv).sum()) \n",
        "assert(err < 1e-5) \n",
        "\n",
        "## test 2: online regularization sherman morrison \n",
        "a = torch.tensor([[2., 1.], [1., 2.]]) \n",
        "b = torch.tensor([[.1, 0.], [0., .1]])\n",
        "or_inv = OnlineDenseLayer.online_regularizer(torch.inverse(a), 10.) \n",
        "num_inv = torch.inverse(a+b) \n",
        "err = float(torch.abs(or_inv - num_inv).sum()) \n",
        "assert(err < 1e-5) "
      ],
      "outputs": [],
      "execution_count": 16,
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "gather": {
          "logged": 1644848011012
        }
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# first experiment: mnist classification"
      ],
      "metadata": {
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from tqdm import tqdm\r\n",
        "from torchvision import datasets, transforms\r\n",
        "\r\n",
        "transform=transforms.Compose([\r\n",
        "    transforms.ToTensor(),\r\n",
        "    transforms.Normalize((0.1307,), (0.3081,))\r\n",
        "    ])\r\n",
        "\r\n",
        "dataset1 = datasets.MNIST('../../data', train=True, download=True, transform=transform)\r\n",
        "dataset2 = datasets.MNIST('../../data', train=False, transform=transform)\r\n",
        "\r\n",
        "train_loader = torch.utils.data.DataLoader(dataset1)\r\n",
        "test_loader = torch.utils.data.DataLoader(dataset2)\r\n",
        "\r\n",
        "n_labels = 10 \r\n",
        "lam = 100. \r\n",
        "dlamdn = 10. \r\n",
        "reregularization_frequency = 1000 \r\n",
        "clip = 100. \r\n",
        "\r\n",
        "## activation functions \r\n",
        "## torch.sigmoid \r\n",
        "inv_sigmoid = lambda x: -torch.log((1/(x+1e-8))-1) \r\n",
        "leaky_relu_alpha = .1 \r\n",
        "leaky_relu = lambda x: (x > 0)*x + (x <= 0)*x*leaky_relu_alpha \r\n",
        "inv_leaky_relu = lambda x: (x > 0)*x + (x <= 0)*x/leaky_relu_alpha \r\n",
        "\r\n",
        "model = OnlineNet( \r\n",
        "    layer_list = [ \r\n",
        "        OnlineDenseLayer(p=1*1*28*28, q=100, activation=leaky_relu, activation_inverse=inv_leaky_relu, lam=lam, clip=clip), \r\n",
        "        OnlineDenseLayer(p=100, q=100, activation=leaky_relu, activation_inverse=inv_leaky_relu, lam=lam, clip=clip), \r\n",
        "        OnlineDenseLayer(p=100, q=100, activation=leaky_relu, activation_inverse=inv_leaky_relu, lam=lam, clip=clip), \r\n",
        "        OnlineDenseLayer(p=100, q=n_labels, activation=torch.sigmoid, activation_inverse=inv_sigmoid, lam=lam, clip=clip) \r\n",
        "    ], \r\n",
        "    reregularization_frequency = reregularization_frequency, \r\n",
        "    dlamdn = dlamdn \r\n",
        ") \r\n",
        "\r\n",
        "def build_data(image, label): \r\n",
        "    'format data from iterator for model' \r\n",
        "    y = torch.tensor([1. if int(label[0]) == idx else 0. for idx in range(n_labels)]) ## one-hot representation \r\n",
        "    x = image.reshape([-1]) ## flatten \r\n",
        "    ## shrink so sigmoid inverse is well-defined \r\n",
        "    y = y*.90 + .05 \r\n",
        "    ## reshape to column vectors \r\n",
        "    x = x.reshape([-1,1]) \r\n",
        "    y = y.reshape([-1,1]) \r\n",
        "    return x, y \r\n",
        "\r\n",
        "def match(y, y_hat):\r\n",
        "    y = y.reshape(-1)\r\n",
        "    y_hat = y_hat.reshape(-1)\r\n",
        "    if y.argmax() == y_hat.argmax():\r\n",
        "        return 1.\r\n",
        "    return 0. \r\n",
        "\r\n",
        "def run(data_iterable, fit=True, max_iters=None, model=model):\r\n",
        "    '''\r\n",
        "    fit or predict on dataset \r\n",
        "    inputs:\r\n",
        "    - data_iterable: an iterable of (image, label) pairs\r\n",
        "    - fit: (bool) are we integrating the (image, label) pair into the model or just predicting?\r\n",
        "    - max_iters: (int or None) if int then cap fit/predict iters at this amount, otherwise run the whole iterable \r\n",
        "    - model: (OnlineDenseNet) the model to update in-place \r\n",
        "    output: \r\n",
        "    - errs: a list of model errors \r\n",
        "    - stab: a list of numerical stability statistics \r\n",
        "    - y_std: a list of y_hat standard deviations \r\n",
        "    - acc: a list of running average accuracies \r\n",
        "    side-effects: \r\n",
        "    - model is updated in-place \r\n",
        "    '''\r\n",
        "    ## init stats \r\n",
        "    errs = [] \r\n",
        "    stab = [] \r\n",
        "    y_std = [] \r\n",
        "    acc = [0.] \r\n",
        "    ## get data \r\n",
        "    pbar = tqdm(data_iterable)\r\n",
        "    n_iters = 0 \r\n",
        "    for [image, label] in pbar: \r\n",
        "        n_iters += 1 \r\n",
        "        ## get a datum \r\n",
        "        x, y = build_data(image, label) \r\n",
        "        ## fit or predict \r\n",
        "        if fit: \r\n",
        "            y_hat, stability = model(x, y) \r\n",
        "        else:\r\n",
        "            y_hat = model(x) \r\n",
        "            stability = 1. \r\n",
        "        ## stats \r\n",
        "        err = float((y - y_hat).abs().sum()) \r\n",
        "        errs.append(err) \r\n",
        "        stab.append(stability) \r\n",
        "        std = float(y_hat.std()) \r\n",
        "        y_std.append(std) \r\n",
        "        acc_n = max(len(acc), 1000) \r\n",
        "        acc.append(match(y,y_hat)/acc_n + acc[-1]*(acc_n-1)/acc_n) \r\n",
        "        pbar.set_description(f'acc: {acc[-1]:.5f}, err: {err:.5f}, y_std: {std:.5f}, stab: {stability:.5f}') \r\n",
        "        if max_iters is not None: \r\n",
        "            if n_iters > max_iters:\r\n",
        "                return errs, stab, y_std, acc\r\n",
        "    return errs, stab, y_std, acc \r\n",
        "\r\n",
        "def test(data_iterable, model, max_iters=None): \r\n",
        "    'calculates accuracy correctly' \r\n",
        "    hits = 0 \r\n",
        "    n = 0 \r\n",
        "    n_iters = 0 \r\n",
        "    for image, label in tqdm(data_iterable):\r\n",
        "        x, y = build_data(image, label) \r\n",
        "        y_hat = model(x) \r\n",
        "        if match(y, y_hat) == 1:\r\n",
        "            hits += 1 \r\n",
        "        n += 1\r\n",
        "    return hits/n  \r\n",
        "\r\n",
        "errs, stab, y_std, acc = run(train_loader, fit=True, max_iters=10000) "
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": "acc: 0.80059, err: 3.16735, y_std: 0.18385, stab: 1.00088:  17%|█▋        | 10000/60000 [04:39<23:17, 35.78it/s]\n"
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": "DEBUG 1: err: 0.018810419365763664\nDEBUG 2: err_forward: 0.018764851614832878, err_backward: 4.556775093078613e-05\nDEBUG 1: err: 0.012334661558270454\nDEBUG 2: err_forward: 0.012017982080578804, err_backward: 0.0003166794776916504\nDEBUG 1: err: 0.010774933733046055\nDEBUG 2: err_forward: 0.010555082000792027, err_backward: 0.00021985173225402832\nDEBUG 1: err: 0.011564869433641434\nDEBUG 2: err_forward: 0.011507142335176468, err_backward: 5.772709846496582e-05\nDEBUG 1: err: 0.020877493545413017\nDEBUG 2: err_forward: 0.020823342725634575, err_backward: 5.415081977844238e-05\nDEBUG 1: err: 0.013910709880292416\nDEBUG 2: err_forward: 0.013853459618985653, err_backward: 5.7250261306762695e-05\nDEBUG 1: err: 0.015662536025047302\nDEBUG 2: err_forward: 0.015623465180397034, err_backward: 3.9070844650268555e-05\nDEBUG 1: err: 0.010816344991326332\nDEBUG 2: err_forward: 0.010599711909890175, err_backward: 0.00021663308143615723\nDEBUG 1: err: 0.012816378846764565\nDEBUG 2: err_forward: 0.012798318639397621, err_backward: 1.806020736694336e-05\nDEBUG 1: err: 0.011665374971926212\nDEBUG 2: err_forward: 0.011647314764559269, err_backward: 1.806020736694336e-05\nDEBUG 1: err: 0.01106985192745924\nDEBUG 2: err_forward: 0.011010128073394299, err_backward: 5.9723854064941406e-05\n"
        }
      ],
      "execution_count": 17,
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "gather": {
          "logged": 1644848293961
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as plt \r\n",
        "\r\n",
        "print('acc')\r\n",
        "plt.plot(acc[100:])\r\n",
        "plt.show()"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": "acc\n"
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": "<Figure size 432x288 with 1 Axes>",
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ],
      "execution_count": 18,
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "gather": {
          "logged": 1644848578804
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "print('errs')\r\n",
        "plt.plot(errs)\r\n",
        "plt.show()"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": "errs\n"
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": "<Figure size 432x288 with 1 Axes>",
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ],
      "execution_count": 19,
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "gather": {
          "logged": 1644848584231
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "print('y_std')\r\n",
        "plt.plot(y_std)\r\n",
        "plt.show()"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": "y_std\n"
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": "<Figure size 432x288 with 1 Axes>",
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ],
      "execution_count": 20,
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "gather": {
          "logged": 1644848586756
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "print('stab')\r\n",
        "plt.plot(stab)\r\n",
        "plt.show()"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": "stab\n"
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": "<Figure size 432x288 with 1 Axes>",
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ],
      "execution_count": 21,
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "gather": {
          "logged": 1644848588425
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "## test dataset \r\n",
        "errs, stab, y_std, acc = run(test_loader, fit=False, max_iters=10000) "
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": "acc: 0.82612, err: 3.17963, y_std: 0.18276, stab: 1.00000: 100%|██████████| 10000/10000 [00:25<00:00, 389.65it/s]\n"
        }
      ],
      "execution_count": 22,
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "gather": {
          "logged": 1644848615911
        }
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# hypothesis test 1: does this solve catestrophic forgetting? \r\n",
        "\r\n",
        "Least squares' sufficient statistics have finite dimension and closed-form online update equations which guarantee perfect transfer learning. \r\n",
        "Our use of one least squares estimator per deep net layer enjoys a series of such sufficient statistics, but is only heuristically simlar to the mathematical guarantees of least squares. \r\n",
        "Nevertheless, we have proceeded hypothesizing some degree of a transfer learning benefit. \r\n",
        "In this section, we test this hypothesis. \r\n",
        "\r\n",
        "To test our hypothesis, we will subsample MNIST into two parts: initial and expanded. \r\n",
        "The initial portion will include digits 0 through 7, and expanded will only include digits 8 and 9. \r\n",
        "We will first fit our model to the initial dataset and then _transfer learn_ by fitting to the expanded dataset. \r\n",
        "If our hypothesis is true, transfer learning should be maintained and thus catastrophic forgetting avoided, so we'd expect the updated model to retain the ability to predict on digits 0 through 7."
      ],
      "metadata": {
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "## build data \r\n",
        "min_train_samples = 10000 \r\n",
        "min_test_samples = 10000 \r\n",
        "\r\n",
        "def hypothesis_1_sampler(data_loader, min_samples):\r\n",
        "    '''\r\n",
        "    randomly samples data for hypothesis test 1\r\n",
        "    '''\r\n",
        "    ## init empty datasets \r\n",
        "    initial = [] \r\n",
        "    expanded = [] \r\n",
        "    for pair in tqdm(data_loader): \r\n",
        "        if pair[1] > 7: \r\n",
        "            expanded.append(pair) \r\n",
        "        else: \r\n",
        "            initial.append(pair) \r\n",
        "            pass \r\n",
        "        if len(expanded) > min_samples and len(initial) > min_samples: \r\n",
        "            return initial, expanded \r\n",
        "    return initial, expanded \r\n",
        "\r\n",
        "train_initial, train_expanded = hypothesis_1_sampler(train_loader, min_train_samples) \r\n",
        "test_initial, test_expanded = hypothesis_1_sampler(test_loader, min_test_samples) "
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": " 85%|████████▍ | 50798/60000 [00:11<00:02, 4473.55it/s]\n100%|██████████| 10000/10000 [00:02<00:00, 4357.07it/s]\n"
        }
      ],
      "execution_count": 23,
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "gather": {
          "logged": 1644848766151
        }
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Fitting on 0 through 7 "
      ],
      "metadata": {
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "## Get a fresh model \r\n",
        "hypothesis_1_model = OnlineNet( \r\n",
        "    layer_list = [ \r\n",
        "        OnlineDenseLayer(p=1*1*28*28, q=100, activation=leaky_relu, activation_inverse=inv_leaky_relu, lam=lam, clip=clip), \r\n",
        "        OnlineDenseLayer(p=100, q=100, activation=leaky_relu, activation_inverse=inv_leaky_relu, lam=lam, clip=clip), \r\n",
        "        OnlineDenseLayer(p=100, q=100, activation=leaky_relu, activation_inverse=inv_leaky_relu, lam=lam, clip=clip), \r\n",
        "        OnlineDenseLayer(p=100, q=n_labels, activation=torch.sigmoid, activation_inverse=inv_sigmoid, lam=lam, clip=clip) \r\n",
        "    ], \r\n",
        "    reregularization_frequency = reregularization_frequency, \r\n",
        "    dlamdn = dlamdn \r\n",
        ") \r\n",
        "\r\n",
        "print('fit on 0-7') \r\n",
        "_, _, _, acc_train_initial = run(train_initial, fit=True, max_iters=10000, model=hypothesis_1_model) "
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": "fit on 0-7\nDEBUG 1: err: 0.018810419365763664\nDEBUG 2: err_forward: 0.018764851614832878, err_backward: 4.556775093078613e-05\nDEBUG 1: err: 0.012334661558270454\nDEBUG 2: err_forward: 0.012017982080578804, err_backward: 0.0003166794776916504\nDEBUG 1: err: 0.010774933733046055\nDEBUG 2: err_forward: 0.010555082000792027, err_backward: 0.00021985173225402832\nDEBUG 1: err: 0.029264312237501144\nDEBUG 2: err_forward: 0.029200267046689987, err_backward: 6.404519081115723e-05\nDEBUG 1: err: 0.015712283551692963\nDEBUG 2: err_forward: 0.01565852016210556, err_backward: 5.3763389587402344e-05\nDEBUG 1: err: 0.01714036427438259\nDEBUG 2: err_forward: 0.01711917482316494, err_backward: 2.1189451217651367e-05\nDEBUG 1: err: 0.011734778992831707\nDEBUG 2: err_forward: 0.011674548499286175, err_backward: 6.0230493545532227e-05\nDEBUG 1: err: 0.014031924307346344\nDEBUG 2: err_forward: 0.01401788741350174, err_backward: 1.4036893844604492e-05\nDEBUG 1: err: 0.012005811557173729\nDEBUG 2: err_forward: 0.011991089209914207, err_backward: 1.4722347259521484e-05\nDEBUG 1: err: 0.01043570227921009\nDEBUG 2: err_forward: 0.010196806862950325, err_backward: 0.00023889541625976562\nDEBUG 1: err: 0.011887908913195133\nDEBUG 2: err_forward: 0.011803717352449894, err_backward: 8.419156074523926e-05\n"
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": "acc: 0.84571, err: 4.09494, y_std: 0.09185, stab: 1.00030:  25%|██▍       | 10000/40798 [04:23<13:32, 37.92it/s]\n"
        }
      ],
      "execution_count": 24,
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "gather": {
          "logged": 1644849045439
        }
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### test on 0 through 7 before transfer learning "
      ],
      "metadata": {
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "print('test on 0-7 before transfer learning') \r\n",
        "_, _, _, acc_test_initial_before = run(test_initial, fit=False, max_iters=10000, model=hypothesis_1_model) "
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": "acc: 0.85993, err: 3.19244, y_std: 0.18219, stab: 1.00000: 100%|██████████| 8017/8017 [00:20<00:00, 399.78it/s]\n"
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": "test on 0-7 before transfer learning\n"
        }
      ],
      "execution_count": 25,
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "gather": {
          "logged": 1644849065538
        }
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### fit on 8 and 9 "
      ],
      "metadata": {
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "print('fit on 8-9') \r\n",
        "hypothesis_1_model_copy = hypothesis_1_model.copy() \r\n",
        "## TODO\r\n",
        "hypothesis_1_model_copy.set_n_fits(1000)\r\n",
        "#hypothesis_1_model_copy.dlamdn = 10.\r\n",
        "_, _, _, acc_train_expanded = run(train_expanded, fit=True, max_iters=3000, model=hypothesis_1_model_copy) "
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": "fit on 8-9\nDEBUG 1: err: 12040.171875\nDEBUG 2: err_forward: 7995.6435546875, err_backward: 4044.528076171875\nDEBUG 1: err: 35393.76953125\nDEBUG 2: err_forward: 16693.0625, err_backward: 18700.70703125\nDEBUG 1: err: 33820.890625\nDEBUG 2: err_forward: 22028.609375, err_backward: 11792.28125\nDEBUG 1: err: 31575.140625\nDEBUG 2: err_forward: 11818.9541015625, err_backward: 19756.1875\nDEBUG 1: err: 30578.072265625\nDEBUG 2: err_forward: 22021.79296875, err_backward: 8556.279296875\nDEBUG 1: err: 17182.421875\nDEBUG 2: err_forward: 6306.50830078125, err_backward: 10875.9130859375\nDEBUG 1: err: 6467.94140625\nDEBUG 2: err_forward: 6081.689453125, err_backward: 386.251953125\nDEBUG 1: err: 7247.42578125\nDEBUG 2: err_forward: 7055.8681640625, err_backward: 191.55783081054688\nDEBUG 1: err: 11029.4453125\nDEBUG 2: err_forward: 11029.4453125, err_backward: 0.0\nDEBUG 1: err: 10026.453125\nDEBUG 2: err_forward: 10026.453125, err_backward: 0.0\nDEBUG 1: err: 6902.1533203125\nDEBUG 2: err_forward: 6902.1533203125, err_backward: 0.0\nDEBUG 1: err: 7233.58740234375\nDEBUG 2: err_forward: 7233.58740234375, err_backward: 0.0\nDEBUG 1: err: 11237.015625\nDEBUG 2: err_forward: 11237.015625, err_backward: 0.0\nDEBUG 1: err: 11115.052734375\nDEBUG 2: err_forward: 11115.052734375, err_backward: 0.0\nDEBUG 1: err: 36.096641540527344\nDEBUG 2: err_forward: 36.096641540527344, err_backward: 0.0\nDEBUG 1: err: 3230.71435546875\nDEBUG 2: err_forward: 3230.71435546875, err_backward: 0.0\nDEBUG 1: err: 13485.541015625\nDEBUG 2: err_forward: 13485.541015625, err_backward: 0.0\nDEBUG 1: err: 1310.1990966796875\nDEBUG 2: err_forward: 1310.1990966796875, err_backward: 0.0\nDEBUG 1: err: 4689.6708984375\nDEBUG 2: err_forward: 4689.6708984375, err_backward: 0.0\nDEBUG 1: err: 6383.1181640625\nDEBUG 2: err_forward: 6383.1181640625, err_backward: 0.0\nDEBUG 1: err: 1088.3160400390625\nDEBUG 2: err_forward: 1088.3160400390625, err_backward: 0.0\nDEBUG 1: err: 9137.8681640625\nDEBUG 2: err_forward: 9137.8681640625, err_backward: 0.0\nDEBUG 1: err: 7799.2978515625\nDEBUG 2: err_forward: 7799.2978515625, err_backward: 0.0\nDEBUG 1: err: 5987.63232421875\nDEBUG 2: err_forward: 5987.63232421875, err_backward: 0.0\nDEBUG 1: err: 7298.14013671875\nDEBUG 2: err_forward: 7298.14013671875, err_backward: 0.0\nDEBUG 1: err: 258.55584716796875\nDEBUG 2: err_forward: 258.55584716796875, err_backward: 0.0\nDEBUG 1: err: 3702.38916015625\nDEBUG 2: err_forward: 3702.38916015625, err_backward: 0.0\nDEBUG 1: err: 3238.482421875\nDEBUG 2: err_forward: 3238.482421875, err_backward: 0.0\nDEBUG 1: err: 7813.69677734375\nDEBUG 2: err_forward: 7813.69677734375, err_backward: 0.0\nDEBUG 1: err: 7737.44970703125\nDEBUG 2: err_forward: 7737.44970703125, err_backward: 0.0\nDEBUG 1: err: 8329.6357421875\nDEBUG 2: err_forward: 8329.6357421875, err_backward: 0.0\nDEBUG 1: err: 4516.73486328125\nDEBUG 2: err_forward: 4516.73486328125, err_backward: 0.0\nDEBUG 1: err: 9026.6728515625\nDEBUG 2: err_forward: 9026.6728515625, err_backward: 0.0\nDEBUG 1: err: 7679.30126953125\nDEBUG 2: err_forward: 7679.30126953125, err_backward: 0.0\nDEBUG 1: err: 554.1962280273438\nDEBUG 2: err_forward: 554.1962280273438, err_backward: 0.0\nDEBUG 1: err: 8965.58984375\nDEBUG 2: err_forward: 8965.58984375, err_backward: 0.0\nDEBUG 1: err: 2982.98681640625\nDEBUG 2: err_forward: 2982.98681640625, err_backward: 0.0\nDEBUG 1: err: 953.4069213867188\nDEBUG 2: err_forward: 953.4069213867188, err_backward: 0.0\nDEBUG 1: err: 5446.2138671875\nDEBUG 2: err_forward: 5446.2138671875, err_backward: 0.0\nDEBUG 1: err: 3533.94580078125\nDEBUG 2: err_forward: 3533.94580078125, err_backward: 0.0\nDEBUG 1: err: 3436.9736328125\nDEBUG 2: err_forward: 3436.9736328125, err_backward: 0.0\nDEBUG 1: err: 9025.34375\nDEBUG 2: err_forward: 9025.34375, err_backward: 0.0\nDEBUG 1: err: 3124.229736328125\nDEBUG 2: err_forward: 3124.229736328125, err_backward: 0.0\nDEBUG 1: err: 9023.533203125\nDEBUG 2: err_forward: 9023.533203125, err_backward: 0.0\nDEBUG 1: err: 3052.1943359375\nDEBUG 2: err_forward: 3052.1943359375, err_backward: 0.0\nDEBUG 1: err: 5432.0\nDEBUG 2: err_forward: 5432.0, err_backward: 0.0\nDEBUG 1: err: 3639.1474609375\nDEBUG 2: err_forward: 3639.1474609375, err_backward: 0.0\nDEBUG 1: err: 200.53504943847656\nDEBUG 2: err_forward: 200.53504943847656, err_backward: 0.0\nDEBUG 1: err: 2637.425048828125\nDEBUG 2: err_forward: 2637.425048828125, err_backward: 0.0\nDEBUG 1: err: 1221.067626953125\nDEBUG 2: err_forward: 1221.067626953125, err_backward: 0.0\nDEBUG 1: err: 571.3592529296875\nDEBUG 2: err_forward: 571.3592529296875, err_backward: 0.0\nDEBUG 1: err: 1522.19970703125\nDEBUG 2: err_forward: 1522.19970703125, err_backward: 0.0\nDEBUG 1: err: 342.65191650390625\nDEBUG 2: err_forward: 342.65191650390625, err_backward: 0.0\nDEBUG 1: err: 527.8450927734375\nDEBUG 2: err_forward: 527.8450927734375, err_backward: 0.0\nDEBUG 1: err: 1467.9786376953125\nDEBUG 2: err_forward: 1467.9786376953125, err_backward: 0.0\nDEBUG 1: err: 89.16314697265625\nDEBUG 2: err_forward: 89.16314697265625, err_backward: 0.0\nDEBUG 1: err: 420.4194641113281\nDEBUG 2: err_forward: 420.4194641113281, err_backward: 0.0\nDEBUG 1: err: 992.1025390625\nDEBUG 2: err_forward: 992.1025390625, err_backward: 0.0\nDEBUG 1: err: 3.9134292602539062\nDEBUG 2: err_forward: 3.9134292602539062, err_backward: 0.0\nDEBUG 1: err: 238.7408447265625\nDEBUG 2: err_forward: 238.7408447265625, err_backward: 0.0\nDEBUG 1: err: 1309.7779541015625\nDEBUG 2: err_forward: 1309.7779541015625, err_backward: 0.0\nDEBUG 1: err: 477.3546142578125\nDEBUG 2: err_forward: 477.3546142578125, err_backward: 0.0\nDEBUG 1: err: 0.0370941162109375\nDEBUG 2: err_forward: 0.0370941162109375, err_backward: 0.0\nDEBUG 1: err: 0.101806640625\nDEBUG 2: err_forward: 0.101806640625, err_backward: 0.0\nDEBUG 1: err: 0.257049560546875\nDEBUG 2: err_forward: 0.257049560546875, err_backward: 0.0\nDEBUG 1: err: 0.7593612670898438\nDEBUG 2: err_forward: 0.7593612670898438, err_backward: 0.0\nDEBUG 1: err: 0.80938720703125\nDEBUG 2: err_forward: 0.80938720703125, err_backward: 0.0\nDEBUG 1: err: 5965.07958984375\nDEBUG 2: err_forward: 5963.0595703125, err_backward: 2.0201339721679688\nDEBUG 1: err: 10277.482421875\nDEBUG 2: err_forward: 10276.0283203125, err_backward: 1.45367431640625\nDEBUG 1: err: 9057.150390625\nDEBUG 2: err_forward: 9055.0810546875, err_backward: 2.0693373680114746\nDEBUG 1: err: 8681.34765625\nDEBUG 2: err_forward: 8679.2978515625, err_backward: 2.0493526458740234\nDEBUG 1: err: 10592.5986328125\nDEBUG 2: err_forward: 10048.662109375, err_backward: 543.9364013671875\nDEBUG 1: err: 19.282724380493164\nDEBUG 2: err_forward: 18.50885772705078, err_backward: 0.7738666534423828\nDEBUG 1: err: 9036.3369140625\nDEBUG 2: err_forward: 9035.7587890625, err_backward: 0.5784263610839844\nDEBUG 1: err: 9030.9267578125\nDEBUG 2: err_forward: 9029.693359375, err_backward: 1.2332229614257812\nDEBUG 1: err: 19.573135375976562\nDEBUG 2: err_forward: 18.50641632080078, err_backward: 1.0667190551757812\nDEBUG 1: err: 9028.146484375\nDEBUG 2: err_forward: 9028.146484375, err_backward: 0.0\nDEBUG 1: err: 0.4453125\nDEBUG 2: err_forward: 0.4453125, err_backward: 0.0\nDEBUG 1: err: 0.44052886962890625\nDEBUG 2: err_forward: 0.44052886962890625, err_backward: 0.0\nDEBUG 1: err: 0.4852714538574219\nDEBUG 2: err_forward: 0.4852714538574219, err_backward: 0.0\nDEBUG 1: err: 0.4271354675292969\nDEBUG 2: err_forward: 0.4271354675292969, err_backward: 0.0\nDEBUG 1: err: 1.2516908645629883\nDEBUG 2: err_forward: 1.2516908645629883, err_backward: 0.0\nDEBUG 1: err: 3.1841602325439453\nDEBUG 2: err_forward: 3.1841602325439453, err_backward: 0.0\nDEBUG 1: err: 25.669254302978516\nDEBUG 2: err_forward: 25.669254302978516, err_backward: 0.0\nDEBUG 1: err: 11.836176872253418\nDEBUG 2: err_forward: 11.836176872253418, err_backward: 0.0\nDEBUG 1: err: 16.178680419921875\nDEBUG 2: err_forward: 16.178680419921875, err_backward: 0.0\nDEBUG 1: err: 60.93634796142578\nDEBUG 2: err_forward: 60.93634796142578, err_backward: 0.0\nDEBUG 1: err: 186.031005859375\nDEBUG 2: err_forward: 186.031005859375, err_backward: 0.0\nDEBUG 1: err: 679.9305419921875\nDEBUG 2: err_forward: 679.9305419921875, err_backward: 0.0\nDEBUG 1: err: 1219.4139404296875\nDEBUG 2: err_forward: 1219.4139404296875, err_backward: 0.0\nDEBUG 1: err: 45.15363311767578\nDEBUG 2: err_forward: 45.15363311767578, err_backward: 0.0\nDEBUG 1: err: 709.9014282226562\nDEBUG 2: err_forward: 709.9014282226562, err_backward: 0.0\nDEBUG 1: err: 52.01995849609375\nDEBUG 2: err_forward: 52.01995849609375, err_backward: 0.0\nDEBUG 1: err: 235.7676239013672\nDEBUG 2: err_forward: 235.7676239013672, err_backward: 0.0\nDEBUG 1: err: 27.49625015258789\nDEBUG 2: err_forward: 27.49625015258789, err_backward: 0.0\nDEBUG 1: err: 127.30668640136719\nDEBUG 2: err_forward: 127.30668640136719, err_backward: 0.0\nDEBUG 1: err: 218.3696746826172\nDEBUG 2: err_forward: 218.3696746826172, err_backward: 0.0\nDEBUG 1: err: 113.78779602050781\nDEBUG 2: err_forward: 113.78779602050781, err_backward: 0.0\nDEBUG 1: err: 56.14551544189453\nDEBUG 2: err_forward: 56.14551544189453, err_backward: 0.0\nDEBUG 1: err: 109.52203369140625\nDEBUG 2: err_forward: 109.52203369140625, err_backward: 0.0\nDEBUG 1: err: 165.1448211669922\nDEBUG 2: err_forward: 165.1448211669922, err_backward: 0.0\nDEBUG 1: err: 147.9021453857422\nDEBUG 2: err_forward: 147.9021453857422, err_backward: 0.0\nDEBUG 1: err: 135.24560546875\nDEBUG 2: err_forward: 135.24560546875, err_backward: 0.0\nDEBUG 1: err: 221.6277313232422\nDEBUG 2: err_forward: 221.6277313232422, err_backward: 0.0\nDEBUG 1: err: 63.92332077026367\nDEBUG 2: err_forward: 63.92332077026367, err_backward: 0.0\nDEBUG 1: err: 14.211989402770996\nDEBUG 2: err_forward: 14.211989402770996, err_backward: 0.0\nDEBUG 1: err: 22.54210662841797\nDEBUG 2: err_forward: 22.54210662841797, err_backward: 0.0\nDEBUG 1: err: 26.19989585876465\nDEBUG 2: err_forward: 26.19989585876465, err_backward: 0.0\nDEBUG 1: err: 3156.48046875\nDEBUG 2: err_forward: 3156.48046875, err_backward: 0.0\nDEBUG 1: err: 11.679766654968262\nDEBUG 2: err_forward: 11.679766654968262, err_backward: 0.0\nDEBUG 1: err: 52.79981994628906\nDEBUG 2: err_forward: 52.79981994628906, err_backward: 0.0\nDEBUG 1: err: 8.721248626708984\nDEBUG 2: err_forward: 8.721248626708984, err_backward: 0.0\nDEBUG 1: err: 17.57522964477539\nDEBUG 2: err_forward: 17.57522964477539, err_backward: 0.0\nDEBUG 1: err: 18.325075149536133\nDEBUG 2: err_forward: 18.325075149536133, err_backward: 0.0\nDEBUG 1: err: 5.131490707397461\nDEBUG 2: err_forward: 5.131490707397461, err_backward: 0.0\nDEBUG 1: err: 9.957419395446777\nDEBUG 2: err_forward: 9.957419395446777, err_backward: 0.0\nDEBUG 1: err: 6.715695381164551\nDEBUG 2: err_forward: 6.715695381164551, err_backward: 0.0\nDEBUG 1: err: 2.813955307006836\nDEBUG 2: err_forward: 2.813955307006836, err_backward: 0.0\nDEBUG 1: err: 8.412801742553711\nDEBUG 2: err_forward: 8.412801742553711, err_backward: 0.0\nDEBUG 1: err: 5.393712043762207\nDEBUG 2: err_forward: 5.393712043762207, err_backward: 0.0\nDEBUG 1: err: 4.195741653442383\nDEBUG 2: err_forward: 4.195741653442383, err_backward: 0.0\nDEBUG 1: err: 5.436861991882324\nDEBUG 2: err_forward: 5.436861991882324, err_backward: 0.0\nDEBUG 1: err: 6.638951301574707\nDEBUG 2: err_forward: 6.638951301574707, err_backward: 0.0\nDEBUG 1: err: 2.1092073917388916\nDEBUG 2: err_forward: 2.1092073917388916, err_backward: 0.0\nDEBUG 1: err: 1.6344361305236816\nDEBUG 2: err_forward: 1.6344361305236816, err_backward: 0.0\nDEBUG 1: err: 1.4664868116378784\nDEBUG 2: err_forward: 1.4664868116378784, err_backward: 0.0\nDEBUG 1: err: 3.2915797233581543\nDEBUG 2: err_forward: 3.2915797233581543, err_backward: 0.0\nDEBUG 1: err: 5.738664627075195\nDEBUG 2: err_forward: 5.738664627075195, err_backward: 0.0\nDEBUG 1: err: 3.0295357704162598\nDEBUG 2: err_forward: 3.0295357704162598, err_backward: 0.0\nDEBUG 1: err: 3.3153746128082275\nDEBUG 2: err_forward: 3.3153746128082275, err_backward: 0.0\nDEBUG 1: err: 2.0078680515289307\nDEBUG 2: err_forward: 2.0078680515289307, err_backward: 0.0\nDEBUG 1: err: 4.270741939544678\nDEBUG 2: err_forward: 4.270741939544678, err_backward: 0.0\nDEBUG 1: err: 1.0880682468414307\nDEBUG 2: err_forward: 1.0880682468414307, err_backward: 0.0\nDEBUG 1: err: 5.734207630157471\nDEBUG 2: err_forward: 5.734207630157471, err_backward: 0.0\nDEBUG 1: err: 3.4487247467041016\nDEBUG 2: err_forward: 3.4487247467041016, err_backward: 0.0\nDEBUG 1: err: 5.228797912597656\nDEBUG 2: err_forward: 5.228797912597656, err_backward: 0.0\nDEBUG 1: err: 4.772926330566406\nDEBUG 2: err_forward: 4.772926330566406, err_backward: 0.0\nDEBUG 1: err: 5.507938385009766\nDEBUG 2: err_forward: 5.507938385009766, err_backward: 0.0\nDEBUG 1: err: 6.911754608154297\nDEBUG 2: err_forward: 6.911754608154297, err_backward: 0.0\nDEBUG 1: err: 0.22753405570983887\nDEBUG 2: err_forward: 0.22753405570983887, err_backward: 0.0\nDEBUG 1: err: 3.019707679748535\nDEBUG 2: err_forward: 3.019707679748535, err_backward: 0.0\nDEBUG 1: err: 49.6074333190918\nDEBUG 2: err_forward: 49.6074333190918, err_backward: 0.0\nDEBUG 1: err: 34.089656829833984\nDEBUG 2: err_forward: 34.089656829833984, err_backward: 0.0\nDEBUG 1: err: 78.82142639160156\nDEBUG 2: err_forward: 78.82142639160156, err_backward: 0.0\nDEBUG 1: err: 42.59490203857422\nDEBUG 2: err_forward: 42.59490203857422, err_backward: 0.0\nDEBUG 1: err: 15.792096138000488\nDEBUG 2: err_forward: 15.792096138000488, err_backward: 0.0\nDEBUG 1: err: 69.90292358398438\nDEBUG 2: err_forward: 69.90292358398438, err_backward: 0.0\nDEBUG 1: err: 134.54248046875\nDEBUG 2: err_forward: 134.54248046875, err_backward: 0.0\nDEBUG 1: err: 118.6467056274414\nDEBUG 2: err_forward: 118.6467056274414, err_backward: 0.0\nDEBUG 1: err: 112.09576416015625\nDEBUG 2: err_forward: 112.09576416015625, err_backward: 0.0\nDEBUG 1: err: 90.7353744506836\nDEBUG 2: err_forward: 90.7353744506836, err_backward: 0.0\nDEBUG 1: err: 2.3421249389648438\nDEBUG 2: err_forward: 2.3421249389648438, err_backward: 0.0\nDEBUG 1: err: 1.902025818824768\nDEBUG 2: err_forward: 1.902025818824768, err_backward: 0.0\nDEBUG 1: err: 246.3031768798828\nDEBUG 2: err_forward: 246.3031768798828, err_backward: 0.0\nDEBUG 1: err: 132.02378845214844\nDEBUG 2: err_forward: 132.02378845214844, err_backward: 0.0\nDEBUG 1: err: 92.42578887939453\nDEBUG 2: err_forward: 92.42578887939453, err_backward: 0.0\nDEBUG 1: err: 79.09286499023438\nDEBUG 2: err_forward: 79.09286499023438, err_backward: 0.0\nDEBUG 1: err: 123.41471099853516\nDEBUG 2: err_forward: 123.41471099853516, err_backward: 0.0\nDEBUG 1: err: 39.2724494934082\nDEBUG 2: err_forward: 39.2724494934082, err_backward: 0.0\nDEBUG 1: err: 4.439103603363037\nDEBUG 2: err_forward: 4.439103603363037, err_backward: 0.0\nDEBUG 1: err: 0.16994190216064453\nDEBUG 2: err_forward: 0.16994190216064453, err_backward: 0.0\nDEBUG 1: err: 0.0874476432800293\nDEBUG 2: err_forward: 0.0874476432800293, err_backward: 0.0\nDEBUG 1: err: 0.1546158790588379\nDEBUG 2: err_forward: 0.1546158790588379, err_backward: 0.0\nDEBUG 1: err: 0.10425615310668945\nDEBUG 2: err_forward: 0.10425615310668945, err_backward: 0.0\nDEBUG 1: err: 0.09653854370117188\nDEBUG 2: err_forward: 0.09653854370117188, err_backward: 0.0\nDEBUG 1: err: 0.11388397216796875\nDEBUG 2: err_forward: 0.11388397216796875, err_backward: 0.0\nDEBUG 1: err: 0.1128227710723877\nDEBUG 2: err_forward: 0.1128227710723877, err_backward: 0.0\nDEBUG 1: err: 0.09194827079772949\nDEBUG 2: err_forward: 0.09194827079772949, err_backward: 0.0\nDEBUG 1: err: 0.15946459770202637\nDEBUG 2: err_forward: 0.15946459770202637, err_backward: 0.0\nDEBUG 1: err: 0.2549293041229248\nDEBUG 2: err_forward: 0.2549293041229248, err_backward: 0.0\nDEBUG 1: err: 0.21413731575012207\nDEBUG 2: err_forward: 0.21413731575012207, err_backward: 0.0\nDEBUG 1: err: 0.146223783493042\nDEBUG 2: err_forward: 0.146223783493042, err_backward: 0.0\nDEBUG 1: err: 0.10790753364562988\nDEBUG 2: err_forward: 0.10790753364562988, err_backward: 0.0\nDEBUG 1: err: 0.3763256072998047\nDEBUG 2: err_forward: 0.3763256072998047, err_backward: 0.0\nDEBUG 1: err: 0.10514187812805176\nDEBUG 2: err_forward: 0.10514187812805176, err_backward: 0.0\nDEBUG 1: err: 0.15902018547058105\nDEBUG 2: err_forward: 0.15902018547058105, err_backward: 0.0\nDEBUG 1: err: 0.10193276405334473\nDEBUG 2: err_forward: 0.10193276405334473, err_backward: 0.0\nDEBUG 1: err: 0.11417293548583984\nDEBUG 2: err_forward: 0.11417293548583984, err_backward: 0.0\nDEBUG 1: err: 0.07129859924316406\nDEBUG 2: err_forward: 0.07129859924316406, err_backward: 0.0\nDEBUG 1: err: 0.06353545188903809\nDEBUG 2: err_forward: 0.06353545188903809, err_backward: 0.0\nDEBUG 1: err: 0.18510866165161133\nDEBUG 2: err_forward: 0.18510866165161133, err_backward: 0.0\nDEBUG 1: err: 0.08118677139282227\nDEBUG 2: err_forward: 0.08118677139282227, err_backward: 0.0\nDEBUG 1: err: 0.08186197280883789\nDEBUG 2: err_forward: 0.08186197280883789, err_backward: 0.0\nDEBUG 1: err: 0.1664721965789795\nDEBUG 2: err_forward: 0.1664721965789795, err_backward: 0.0\nDEBUG 1: err: 0.08881199359893799\nDEBUG 2: err_forward: 0.08881199359893799, err_backward: 0.0\nDEBUG 1: err: 0.38447463512420654\nDEBUG 2: err_forward: 0.38447463512420654, err_backward: 0.0\nDEBUG 1: err: 0.08175718784332275\nDEBUG 2: err_forward: 0.08175718784332275, err_backward: 0.0\nDEBUG 1: err: 0.18280673027038574\nDEBUG 2: err_forward: 0.18280673027038574, err_backward: 0.0\nDEBUG 1: err: 0.1659221649169922\nDEBUG 2: err_forward: 0.1659221649169922, err_backward: 0.0\nDEBUG 1: err: 0.09750747680664062\nDEBUG 2: err_forward: 0.09750747680664062, err_backward: 0.0\nDEBUG 1: err: 0.07932674884796143\nDEBUG 2: err_forward: 0.07932674884796143, err_backward: 0.0\nDEBUG 1: err: 0.08234977722167969\nDEBUG 2: err_forward: 0.08234977722167969, err_backward: 0.0\nDEBUG 1: err: 0.05662393569946289\nDEBUG 2: err_forward: 0.05662393569946289, err_backward: 0.0\nDEBUG 1: err: 0.18912345170974731\nDEBUG 2: err_forward: 0.18912345170974731, err_backward: 0.0\nDEBUG 1: err: 0.09498298168182373\nDEBUG 2: err_forward: 0.09498298168182373, err_backward: 0.0\nDEBUG 1: err: 0.053673744201660156\nDEBUG 2: err_forward: 0.053673744201660156, err_backward: 0.0\nDEBUG 1: err: 0.10866332054138184\nDEBUG 2: err_forward: 0.10866332054138184, err_backward: 0.0\nDEBUG 1: err: 0.175154447555542\nDEBUG 2: err_forward: 0.175154447555542, err_backward: 0.0\nDEBUG 1: err: 0.08496880531311035\nDEBUG 2: err_forward: 0.08496880531311035, err_backward: 0.0\nDEBUG 1: err: 0.07992124557495117\nDEBUG 2: err_forward: 0.07992124557495117, err_backward: 0.0\nDEBUG 1: err: 0.02827279269695282\nDEBUG 2: err_forward: 0.02827279269695282, err_backward: 0.0\nDEBUG 1: err: 0.03652685135602951\nDEBUG 2: err_forward: 0.03652685135602951, err_backward: 0.0\nDEBUG 1: err: 0.11133359372615814\nDEBUG 2: err_forward: 0.11133359372615814, err_backward: 0.0\nDEBUG 1: err: 0.06390780210494995\nDEBUG 2: err_forward: 0.06390780210494995, err_backward: 0.0\nDEBUG 1: err: 0.09030270576477051\nDEBUG 2: err_forward: 0.09030270576477051, err_backward: 0.0\nDEBUG 1: err: 0.15106797218322754\nDEBUG 2: err_forward: 0.15106797218322754, err_backward: 0.0\nDEBUG 1: err: 0.20532119274139404\nDEBUG 2: err_forward: 0.20532119274139404, err_backward: 0.0\nDEBUG 1: err: 0.1586136817932129\nDEBUG 2: err_forward: 0.1586136817932129, err_backward: 0.0\nDEBUG 1: err: 0.13940298557281494\nDEBUG 2: err_forward: 0.13940298557281494, err_backward: 0.0\nDEBUG 1: err: 0.05841207504272461\nDEBUG 2: err_forward: 0.05841207504272461, err_backward: 0.0\nDEBUG 1: err: 0.16499412059783936\nDEBUG 2: err_forward: 0.16499412059783936, err_backward: 0.0\nDEBUG 1: err: 0.1987842321395874\nDEBUG 2: err_forward: 0.1987842321395874, err_backward: 0.0\nDEBUG 1: err: 0.13211578130722046\nDEBUG 2: err_forward: 0.13211578130722046, err_backward: 0.0\nDEBUG 1: err: 0.20963811874389648\nDEBUG 2: err_forward: 0.20963811874389648, err_backward: 0.0\nDEBUG 1: err: 0.06257933378219604\nDEBUG 2: err_forward: 0.06257933378219604, err_backward: 0.0\nDEBUG 1: err: 0.06259530782699585\nDEBUG 2: err_forward: 0.06259530782699585, err_backward: 0.0\nDEBUG 1: err: 0.10025304555892944\nDEBUG 2: err_forward: 0.10025304555892944, err_backward: 0.0\nDEBUG 1: err: 0.32362401485443115\nDEBUG 2: err_forward: 0.32362401485443115, err_backward: 0.0\nDEBUG 1: err: 0.0879228413105011\nDEBUG 2: err_forward: 0.0879228413105011, err_backward: 0.0\nDEBUG 1: err: 0.20652185380458832\nDEBUG 2: err_forward: 0.20652185380458832, err_backward: 0.0\nDEBUG 1: err: 0.23684030771255493\nDEBUG 2: err_forward: 0.23684030771255493, err_backward: 0.0\nDEBUG 1: err: 0.11191892623901367\nDEBUG 2: err_forward: 0.11191892623901367, err_backward: 0.0\nDEBUG 1: err: 0.16228115558624268\nDEBUG 2: err_forward: 0.16228115558624268, err_backward: 0.0\nDEBUG 1: err: 0.4496748447418213\nDEBUG 2: err_forward: 0.4496748447418213, err_backward: 0.0\nDEBUG 1: err: 0.1354891061782837\nDEBUG 2: err_forward: 0.1354891061782837, err_backward: 0.0\nDEBUG 1: err: 0.27930402755737305\nDEBUG 2: err_forward: 0.27930402755737305, err_backward: 0.0\nDEBUG 1: err: 0.15176427364349365\nDEBUG 2: err_forward: 0.15176427364349365, err_backward: 0.0\nDEBUG 1: err: 0.07397091388702393\nDEBUG 2: err_forward: 0.07397091388702393, err_backward: 0.0\nDEBUG 1: err: 0.1666945219039917\nDEBUG 2: err_forward: 0.1666945219039917, err_backward: 0.0\nDEBUG 1: err: 0.12877702713012695\nDEBUG 2: err_forward: 0.12877702713012695, err_backward: 0.0\nDEBUG 1: err: 0.14075279235839844\nDEBUG 2: err_forward: 0.14075279235839844, err_backward: 0.0\nDEBUG 1: err: 0.0852041244506836\nDEBUG 2: err_forward: 0.0852041244506836, err_backward: 0.0\nDEBUG 1: err: 0.11407995223999023\nDEBUG 2: err_forward: 0.11407995223999023, err_backward: 0.0\nDEBUG 1: err: 0.04946780204772949\nDEBUG 2: err_forward: 0.04946780204772949, err_backward: 0.0\nDEBUG 1: err: 0.21480047702789307\nDEBUG 2: err_forward: 0.21480047702789307, err_backward: 0.0\nDEBUG 1: err: 0.0873556137084961\nDEBUG 2: err_forward: 0.0873556137084961, err_backward: 0.0\nDEBUG 1: err: 0.18662595748901367\nDEBUG 2: err_forward: 0.18662595748901367, err_backward: 0.0\nDEBUG 1: err: 0.058963894844055176\nDEBUG 2: err_forward: 0.058963894844055176, err_backward: 0.0\nDEBUG 1: err: 0.1259082555770874\nDEBUG 2: err_forward: 0.1259082555770874, err_backward: 0.0\nDEBUG 1: err: 0.11138266324996948\nDEBUG 2: err_forward: 0.11138266324996948, err_backward: 0.0\nDEBUG 1: err: 0.07955533266067505\nDEBUG 2: err_forward: 0.07955533266067505, err_backward: 0.0\nDEBUG 1: err: 0.1127249002456665\nDEBUG 2: err_forward: 0.1127249002456665, err_backward: 0.0\nDEBUG 1: err: 0.05692988634109497\nDEBUG 2: err_forward: 0.05692988634109497, err_backward: 0.0\nDEBUG 1: err: 0.0912896990776062\nDEBUG 2: err_forward: 0.0912896990776062, err_backward: 0.0\nDEBUG 1: err: 0.12348812818527222\nDEBUG 2: err_forward: 0.12348812818527222, err_backward: 0.0\nDEBUG 1: err: 0.2352394461631775\nDEBUG 2: err_forward: 0.2352394461631775, err_backward: 0.0\nDEBUG 1: err: 0.06317520141601562\nDEBUG 2: err_forward: 0.06317520141601562, err_backward: 0.0\nDEBUG 1: err: 0.08036726713180542\nDEBUG 2: err_forward: 0.08036726713180542, err_backward: 0.0\nDEBUG 1: err: 0.10302934050559998\nDEBUG 2: err_forward: 0.10302934050559998, err_backward: 0.0\nDEBUG 1: err: 0.10285675525665283\nDEBUG 2: err_forward: 0.10285675525665283, err_backward: 0.0\nDEBUG 1: err: 0.056200265884399414\nDEBUG 2: err_forward: 0.056200265884399414, err_backward: 0.0\nDEBUG 1: err: 0.0675663948059082\nDEBUG 2: err_forward: 0.0675663948059082, err_backward: 0.0\nDEBUG 1: err: 0.15755045413970947\nDEBUG 2: err_forward: 0.15755045413970947, err_backward: 0.0\nDEBUG 1: err: 0.0967058539390564\nDEBUG 2: err_forward: 0.0967058539390564, err_backward: 0.0\nDEBUG 1: err: 0.08710114657878876\nDEBUG 2: err_forward: 0.08710114657878876, err_backward: 0.0\nDEBUG 1: err: 0.24370631575584412\nDEBUG 2: err_forward: 0.24370631575584412, err_backward: 0.0\nDEBUG 1: err: 0.15578846633434296\nDEBUG 2: err_forward: 0.15578846633434296, err_backward: 0.0\nDEBUG 1: err: 0.18991073966026306\nDEBUG 2: err_forward: 0.18991073966026306, err_backward: 0.0\nDEBUG 1: err: 0.09733051061630249\nDEBUG 2: err_forward: 0.09733051061630249, err_backward: 0.0\nDEBUG 1: err: 0.09847712516784668\nDEBUG 2: err_forward: 0.09847712516784668, err_backward: 0.0\nDEBUG 1: err: 0.07929778099060059\nDEBUG 2: err_forward: 0.07929778099060059, err_backward: 0.0\nDEBUG 1: err: 0.13439452648162842\nDEBUG 2: err_forward: 0.13439452648162842, err_backward: 0.0\nDEBUG 1: err: 0.5156290531158447\nDEBUG 2: err_forward: 0.5156290531158447, err_backward: 0.0\nDEBUG 1: err: 0.058370113372802734\nDEBUG 2: err_forward: 0.058370113372802734, err_backward: 0.0\nDEBUG 1: err: 0.14823627471923828\nDEBUG 2: err_forward: 0.14823627471923828, err_backward: 0.0\nDEBUG 1: err: 8.716846466064453\nDEBUG 2: err_forward: 8.716846466064453, err_backward: 0.0\nDEBUG 1: err: 0.2234940528869629\nDEBUG 2: err_forward: 0.2234940528869629, err_backward: 0.0\n"
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": "acc: 0.00000, err: 5.90000, y_std: 0.52705, stab: 1.99661:   0%|          | 2/10001 [19:46<1647:03:50, 593.00s/it]\n"
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-26-8a754f87e6b3>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0mhypothesis_1_model_copy\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhypothesis_1_model\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcopy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mhypothesis_1_model_copy\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdlamdn\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m10.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m \u001b[0m_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0macc_train_expanded\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mrun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_expanded\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfit\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmax_iters\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m3000\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mhypothesis_1_model_copy\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m<ipython-input-17-da5cacace19a>\u001b[0m in \u001b[0;36mrun\u001b[0;34m(data_iterable, fit, max_iters, model)\u001b[0m\n\u001b[1;32m     85\u001b[0m         \u001b[0;31m## fit or predict\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     86\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mfit\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 87\u001b[0;31m             \u001b[0my_hat\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstability\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     88\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     89\u001b[0m             \u001b[0my_hat\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-16-10170651d546>\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, x, y)\u001b[0m\n\u001b[1;32m    449\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0my_hat\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    450\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 451\u001b[0;31m         \u001b[0msmd_pair_list\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    452\u001b[0m         \u001b[0msmallest_smd\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__reduce_sherman_morrison_denominator_list\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msmd_pair_list\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    453\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit_count\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-16-10170651d546>\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, eps)\u001b[0m\n\u001b[1;32m    393\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mset_ends\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    394\u001b[0m             \u001b[0;32mfor\u001b[0m \u001b[0mlayer\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlayer_list\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 395\u001b[0;31m                 \u001b[0mlayer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward_fit_temp\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    396\u001b[0m                 \u001b[0mlayer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward_fit_temp\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    397\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mset_ends\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-16-10170651d546>\u001b[0m in \u001b[0;36mforward_fit_temp\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    141\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mxTx_inv_temp\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msm_denom\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msherman_morrison\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mxTx_inv\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    142\u001b[0m             \u001b[0;31m##self.xTx_inv = self.reregularizer(self.xTx_inv, self.dlamdn) ## real online regularization too slow\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 143\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mxTy_temp\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mxTy\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmatmul\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtranspose\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0my_backward\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    144\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbetaT_forward_temp\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmatmul\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mxTx_inv_temp\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mxTy_temp\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    145\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbetaT_forward_temp\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtranspose\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbetaT_forward_temp\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ],
      "execution_count": 26,
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "gather": {
          "logged": 1640725684605
        }
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### test on 0 through 7 after transfer learning"
      ],
      "metadata": {
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "print('test on 0-7 after transfer learning') \r\n",
        "_, _, _, acc_train_initial_after = run(test_initial, fit=False, max_iters=10000, model=hypothesis_1_model_copy) "
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "gather": {
          "logged": 1640725705692
        }
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### test on 8 and 9 after transfer learning "
      ],
      "metadata": {
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "print('test on 8-9 after transfer learning') \r\n",
        "_, _, _, acc_test_expanded = run(test_expanded, fit=False, max_iters=10000, model=hypothesis_1_model_copy) "
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "gather": {
          "logged": 1640725710810
        }
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# scratch space\r\n",
        "\r\n",
        "ideas\r\n",
        "- to improve accuracies:\r\n",
        "  - larger models, likely needs GPUs \r\n",
        "  - hyperparamter tuning: try different paths for $\\frac{\\partial \\lambda}{\\partial n}(n)$\r\n",
        "- to explore strength of transfer learning result\r\n",
        "  - compare against a good competing method \r\n",
        "  - ... $\\leftarrow$ really need more here"
      ],
      "metadata": {
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "## trying to improve accuracy: using a dense net architecture found online \r\n",
        "## this is turning-out to be difficult... \r\n",
        "\r\n",
        "lam = 100. \r\n",
        "dlamdn = 10. \r\n",
        "reregularization_frequency = 1000 \r\n",
        "clip = 100. \r\n",
        "\r\n",
        "model_3 = OnlineNet( \r\n",
        "    layer_list = [ \r\n",
        "        OnlineDenseLayer(p=1*1*28*28, q=512, activation=leaky_relu, activation_inverse=inv_leaky_relu, lam=lam, clip=clip), \r\n",
        "        OnlineDenseLayer(p=512, q=n_labels, activation=torch.sigmoid, activation_inverse=inv_sigmoid, lam=lam, clip=clip) \r\n",
        "    ], \r\n",
        "    reregularization_frequency = reregularization_frequency, \r\n",
        "    dlamdn = dlamdn \r\n",
        ") \r\n",
        "\r\n",
        "print('fit on train data') \r\n",
        "_, _, _, acc_3 = run(train_loader, fit=True, max_iters=10000, model=model_3)"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": "acc: 0.76777, err: 4.23754, y_std: 0.09292, stab: 1.00047:  17%|█▋        | 10000/60000 [01:54<09:32, 87.30it/s]\n"
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": "fit on train data\n"
        }
      ],
      "execution_count": 14,
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "gather": {
          "logged": 1640725825410
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model_3_1 = model_3.copy() \r\n",
        "model_3_1.dlamdn = 100000 \r\n",
        "\r\n",
        "_, _, _, acc_3_1 = run(train_loader, fit=True, max_iters=3000, model=model_3_1)"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": "acc: 0.13335, err: 5.78938, y_std: 0.10098, stab: 1.00166:   5%|▌         | 3000/60000 [00:35<11:07, 85.40it/s]\n"
        }
      ],
      "execution_count": 15,
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "gather": {
          "logged": 1640725860508
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "## inspect \r\n",
        "p = train_initial[0]\r\n",
        "x, y = build_data(p[0], p[1]) \r\n",
        "y_hat = model_3_1(x) \r\n",
        "torch.cat((y, y_hat), dim=1) "
      ],
      "outputs": [
        {
          "output_type": "execute_result",
          "execution_count": 16,
          "data": {
            "text/plain": "tensor([[0.0500, 0.7424],\n        [0.0500, 0.8904],\n        [0.0500, 0.8776],\n        [0.0500, 0.8693],\n        [0.0500, 0.7748],\n        [0.9500, 0.7470],\n        [0.0500, 0.8215],\n        [0.0500, 0.8227],\n        [0.0500, 0.7933],\n        [0.0500, 0.7836]])"
          },
          "metadata": {}
        }
      ],
      "execution_count": 16,
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "gather": {
          "logged": 1640725860632
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "## hypothesis 2: transfer learning is robust \r\n",
        "## fit on 8-9, then 0-7 \r\n",
        "\r\n",
        "lam = 100. \r\n",
        "dlamdn = 10. \r\n",
        "reregularization_frequency = 1000 \r\n",
        "clip = 100. \r\n",
        "\r\n",
        "model_4 = OnlineNet( \r\n",
        "    layer_list = [ \r\n",
        "        OnlineDenseLayer(p=1*1*28*28, q=100, activation=leaky_relu, activation_inverse=inv_leaky_relu, lam=lam, clip=clip), \r\n",
        "        OnlineDenseLayer(p=100, q=100, activation=leaky_relu, activation_inverse=inv_leaky_relu, lam=lam, clip=clip), \r\n",
        "        OnlineDenseLayer(p=100, q=100, activation=leaky_relu, activation_inverse=inv_leaky_relu, lam=lam, clip=clip), \r\n",
        "        OnlineDenseLayer(p=100, q=n_labels, activation=torch.sigmoid, activation_inverse=inv_sigmoid, lam=lam, clip=clip) \r\n",
        "    ], \r\n",
        "    reregularization_frequency = reregularization_frequency, \r\n",
        "    dlamdn = dlamdn \r\n",
        ") \r\n",
        "\r\n",
        "print('fit on 8-9') \r\n",
        "_, _, _, _ = run(train_expanded, fit=True, max_iters=10000, model=model_4) \r\n",
        "\r\n",
        "print('test on 8-9') \r\n",
        "_, _, _, _ = run(test_expanded, fit=False, max_iters=10000, model=model_4) \r\n",
        "\r\n",
        "print('fit on 0-7') \r\n",
        "_, _, _, _ = run(train_initial, fit=True, max_iters=10000, model=model_4) \r\n",
        "\r\n",
        "print('test on 0-7') \r\n",
        "_, _, _, _ = run(test_initial, fit=False, max_iters=10000, model=model_4) \r\n",
        "\r\n",
        "print('test on 8-9') \r\n",
        "_, _, _, _ = run(test_expanded, fit=False, max_iters=10000, model=model_4) "
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": "acc: 0.80397, err: 4.42073, y_std: 0.06614, stab: 1.00017: 100%|█████████▉| 10000/10001 [01:10<00:00, 142.04it/s]\nacc: 0.76474, err: 4.31255, y_std: 0.07799, stab: 1.00000: 100%|██████████| 1983/1983 [00:05<00:00, 386.35it/s]\nacc: 0.00920, err: 4.74959, y_std: 0.01047, stab: 1.00009:  25%|██▍       | 10000/40798 [01:10<03:36, 142.38it/s]\nacc: 0.01686, err: 4.69201, y_std: 0.03374, stab: 1.00000: 100%|██████████| 8017/8017 [00:20<00:00, 385.09it/s]\nacc: 0.25299, err: 4.63899, y_std: 0.03366, stab: 1.00000: 100%|██████████| 1983/1983 [00:05<00:00, 392.06it/s]\n"
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": "fit on 8-9\ntest on 8-9\nfit on 0-7\ntest on 0-7\ntest on 8-9\n"
        }
      ],
      "execution_count": 17,
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "gather": {
          "logged": 1640726032270
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "## Does freezing lower layers help transfer learning? \r\n",
        "\r\n",
        "lam = 100. \r\n",
        "dlamdn = 10. \r\n",
        "reregularization_frequency = 1000 \r\n",
        "clip = 100. \r\n",
        "\r\n",
        "model_5 = OnlineNet( \r\n",
        "    layer_list = [ \r\n",
        "        OnlineDenseLayer(p=1*1*28*28, q=100, activation=leaky_relu, activation_inverse=inv_leaky_relu, lam=lam, clip=clip), \r\n",
        "        OnlineDenseLayer(p=100, q=100, activation=leaky_relu, activation_inverse=inv_leaky_relu, lam=lam, clip=clip), \r\n",
        "        OnlineDenseLayer(p=100, q=100, activation=leaky_relu, activation_inverse=inv_leaky_relu, lam=lam, clip=clip), \r\n",
        "        OnlineDenseLayer(p=100, q=n_labels, activation=torch.sigmoid, activation_inverse=inv_sigmoid, lam=lam, clip=clip) \r\n",
        "    ], \r\n",
        "    reregularization_frequency = reregularization_frequency, \r\n",
        "    dlamdn = dlamdn \r\n",
        ") \r\n",
        "\r\n",
        "#print('fit on 0-7') \r\n",
        "_, _, _, _ = run(train_initial, fit=True, max_iters=10000, model=model_5) \r\n",
        "\r\n",
        "#print('test on 0-7') \r\n",
        "_, _, _, _ = run(test_initial, fit=False, max_iters=10000, model=model_5) \r\n",
        "\r\n",
        "model_5.layer_list[0].trainable = False \r\n",
        "model_5.layer_list[1].trainable = False \r\n",
        "model_5.layer_list[2].trainable = False \r\n",
        "\r\n",
        "#print('fit on 8-9') \r\n",
        "_, _, _, _ = run(train_expanded, fit=True, max_iters=10000, model=model_5) \r\n",
        "\r\n",
        "#print('test on 8-9') \r\n",
        "_, _, _, _ = run(test_expanded, fit=False, max_iters=10000, model=model_5) \r\n",
        "#print('test on 0-7') \r\n",
        "_, _, _, _ = run(test_initial, fit=False, max_iters=10000, model=model_5) "
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": "acc: 0.66772, err: 4.67209, y_std: 0.02354, stab: 5.00000:  25%|██▍       | 10000/40798 [01:05<03:23, 151.59it/s]\nacc: 0.68942, err: 4.20784, y_std: 0.09580, stab: 1.00000: 100%|██████████| 8017/8017 [00:21<00:00, 381.67it/s]\nacc: 0.57032, err: 4.62903, y_std: 0.03707, stab: 5.00000: 100%|█████████▉| 10000/10001 [00:40<00:00, 245.54it/s]\nacc: 0.58905, err: 4.67013, y_std: 0.03525, stab: 1.00000: 100%|██████████| 1983/1983 [00:05<00:00, 371.48it/s]\nacc: 0.39470, err: 4.24401, y_std: 0.09614, stab: 1.00000: 100%|██████████| 8017/8017 [00:21<00:00, 380.89it/s]\n"
        }
      ],
      "execution_count": 24,
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "gather": {
          "logged": 1640727298020
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "## Does freezing lower layers help transfer learning? This time, without reregularization. \r\n",
        "\r\n",
        "lam = 100. \r\n",
        "dlamdn = 10. \r\n",
        "reregularization_frequency = 1000 \r\n",
        "clip = 100. \r\n",
        "\r\n",
        "model_6 = OnlineNet( \r\n",
        "    layer_list = [ \r\n",
        "        OnlineDenseLayer(p=1*1*28*28, q=100, activation=leaky_relu, activation_inverse=inv_leaky_relu, lam=lam, clip=clip), \r\n",
        "        OnlineDenseLayer(p=100, q=100, activation=leaky_relu, activation_inverse=inv_leaky_relu, lam=lam, clip=clip), \r\n",
        "        OnlineDenseLayer(p=100, q=100, activation=leaky_relu, activation_inverse=inv_leaky_relu, lam=lam, clip=clip), \r\n",
        "        OnlineDenseLayer(p=100, q=n_labels, activation=torch.sigmoid, activation_inverse=inv_sigmoid, lam=lam, clip=clip) \r\n",
        "    ], \r\n",
        "    reregularization_frequency = reregularization_frequency, \r\n",
        "    dlamdn = dlamdn \r\n",
        ") \r\n",
        "\r\n",
        "#print('fit on 0-7') \r\n",
        "_, _, _, _ = run(train_initial, fit=True, max_iters=10000, model=model_6) \r\n",
        "\r\n",
        "#print('test on 0-7') \r\n",
        "_, _, _, _ = run(test_initial, fit=False, max_iters=10000, model=model_6) \r\n",
        "\r\n",
        "model_6.dlamdn = None \r\n",
        "model_6.layer_list[0].trainable = False \r\n",
        "model_6.layer_list[1].trainable = False \r\n",
        "model_6.layer_list[2].trainable = False \r\n",
        "model_6.layer_list[3].dlamdn = None \r\n",
        "\r\n",
        "#print('fit on 8-9') \r\n",
        "_, _, _, _ = run(train_expanded, fit=True, max_iters=10000, model=model_6) \r\n",
        "\r\n",
        "#print('test on 8-9') \r\n",
        "_, _, _, _ = run(test_expanded, fit=False, max_iters=10000, model=model_6) \r\n",
        "#print('test on 0-7') \r\n",
        "_, _, _, _ = run(test_initial, fit=False, max_iters=10000, model=model_6) "
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": "acc: 0.66772, err: 4.67209, y_std: 0.02354, stab: 5.00000:  25%|██▍       | 10000/40798 [01:08<03:30, 146.21it/s]\nacc: 0.68942, err: 4.20784, y_std: 0.09580, stab: 1.00000: 100%|██████████| 8017/8017 [00:21<00:00, 378.78it/s]\nacc: 0.57082, err: 4.62437, y_std: 0.03780, stab: 5.00000: 100%|█████████▉| 10000/10001 [00:36<00:00, 275.91it/s]\nacc: 0.59003, err: 4.65936, y_std: 0.03680, stab: 1.00000: 100%|██████████| 1983/1983 [00:05<00:00, 376.05it/s]\nacc: 0.39056, err: 4.23951, y_std: 0.09700, stab: 1.00000: 100%|██████████| 8017/8017 [00:21<00:00, 381.20it/s]\n"
        }
      ],
      "execution_count": 25,
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "gather": {
          "logged": 1640727762587
        }
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Conclusion\r\n",
        "\r\n",
        "In theory, a least squares model should be capable of perfect transfer learning. That's not showing-up here. There's a little potential shown in "
      ],
      "metadata": {
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# scatch space \r\n",
        "\r\n",
        "$\\hat \\theta_{MLE} := \\text{arg max}_\\theta f_X(X; \\theta) = \\text{arg max}_\\theta n^{-1} f_X(X; \\theta) \\to \\text{arg max}_\\theta \\mathbb{E} f_X(X; \\theta) \\text{ as } {n \\to \\infty} $\r\n",
        "\r\n",
        "$\\hat \\beta := \\text{arg min}_\\beta \\|y - x \\beta \\|^2 + \\lambda(n) \\| \\beta \\|^2 = \\left( x^Tx + \\lambda(n) \\right)^{-1} x^Ty = \\left(X_{n-1}^TX_{n-1} + x_n^T x_n + \\lambda(n) \\right)^{-1} \\left(X_{n-1}^TY_{n-1} + x_n^T y_n \\right) $\r\n",
        "\r\n",
        "$ = \\frac{n}{n} \\left( x^Tx + \\lambda(n) \\right)^{-1} x^Ty $\r\n",
        "\r\n",
        "$ = \\left( \\frac{x^Tx}{n} + \\frac{\\lambda(n)}{n} \\right)^{-1} \\frac{x^Ty}{n} $\r\n",
        "\r\n",
        "Apply the SLLN $\\left( n^{-1}\\sum_{i=1}^n X_i \\to \\mathbb{E}X_1 \\text{ a.s. if } X_i \\text{ iid} \\right)$.\r\n",
        "\r\n",
        "$ = \\left( \\mathbb{E}X^TX + \\frac{\\lambda(n)}{n} \\right)^{-1} \\mathbb{E}X^TY $"
      ],
      "metadata": {
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      }
    }
  ],
  "metadata": {
    "kernelspec": {
      "name": "python3-azureml",
      "language": "python",
      "display_name": "Python 3.6 - AzureML"
    },
    "language_info": {
      "name": "python",
      "version": "3.6.9",
      "mimetype": "text/x-python",
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "pygments_lexer": "ipython3",
      "nbconvert_exporter": "python",
      "file_extension": ".py"
    },
    "kernel_info": {
      "name": "python3-azureml"
    },
    "nteract": {
      "version": "nteract-front-end@1.0.0"
    },
    "microsoft": {
      "host": {
        "AzureML": {
          "notebookHasBeenCompleted": true
        }
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 2
}