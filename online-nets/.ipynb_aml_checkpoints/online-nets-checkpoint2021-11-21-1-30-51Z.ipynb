{
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# online nets\r\n",
        "\r\n",
        "Deep learning is powerful but computationally expensive, frequently requiring massive compute budgets. In persuit of cost-effective-yet-powerful AI, this work explores and evaluates a heuristic which should lend to more-efficient use of data through online learning.\r\n",
        "\r\n",
        "Goal: evaluate a deep learning alternative capable of true online learning. Solution requirements:\r\n",
        "\r\n",
        "1. catastrophic forgetting should be impossible;\r\n",
        "2. all data is integrated into sufficient statistics of fixed dimension;\r\n",
        "3. and our solution should have predictive power comparable to deep learning.\r\n",
        "\r\n",
        "## modeling strategy\r\n",
        "\r\n",
        "We will not attempt to derive sufficient statistics for an entire deep net, but instead leverage well-known sufficient statistics for least squares models, \r\n",
        "so will have sufficient statistics per deep net layer. If this can be empirically shown effective, we'll build-out the theory afterwards. \r\n",
        "\r\n",
        "Recognizing a deep net as a series of compositions, as follows.\r\n",
        "\r\n",
        "$ Y + \\varepsilon \\approx \\mathbb{E}Y = \\sigma_3 \\circ \\beta_3^T \\circ \\sigma_2 \\circ \\beta_2^T \\circ \\sigma_1 \\circ \\beta_1^T X $\r\n",
        "\r\n",
        "So, we can isolate invidivdual $\\beta_j$ matrices using (psuedo-)inverses $\\beta_j^{-1}$ like so.\r\n",
        "\r\n",
        "$ \\sigma_2^{-1} \\circ \\beta_3^{-1} \\circ \\sigma_3^{-1} (Y) \\approx  \\beta_2^T \\circ \\sigma_1 \\circ \\beta_1^T X $\r\n",
        "\r\n",
        "In this example, if we freeze all $\\beta_j$'s except $\\beta_2$, we are free to update $\\hat \\beta_2$ using $\\tilde Y = \\sigma_2^{-1} \\circ \\beta_3^{-1} \\circ \\sigma_3^{-1} (Y) $\r\n",
        "and $\\tilde X = \\sigma_1 \\circ \\beta_1^T X $.\r\n",
        "\r\n",
        "Using a least squares formulation for fitting to $\\left( \\tilde X, \\tilde Y \\right)$, we get sufficient statistics per layer."
      ],
      "metadata": {
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# model code definitions"
      ],
      "metadata": {
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "\n",
        "TORCH_TENSOR_TYPE = type(torch.tensor(1)) \n",
        "\n",
        "def padded_diagonal(diag_value, n_rows, n_cols):\n",
        "    ## construct diagonal matrix \n",
        "    n_diag = min(n_rows, n_cols)\n",
        "    diag = torch.diag(torch.tensor([diag_value]*n_diag))\n",
        "    if n_rows > n_cols: \n",
        "        ## pad rows \n",
        "        pad = n_rows - n_cols \n",
        "        return torch.cat([diag, torch.zeros((pad, n_cols))], 0)\n",
        "    if n_cols > n_rows:\n",
        "        ## pad cols \n",
        "        pad = n_cols - n_rows \n",
        "        return torch.cat([diag, torch.zeros((n_rows, pad))], 1)\n",
        "    ## no padding \n",
        "    return diag \n",
        "\n",
        "class OnlineDenseLayer:\n",
        "    '''\n",
        "    A single dense net, formulated as a least squares model. \n",
        "    '''\n",
        "    def __init__(self, p, q, activation=lambda x:x, activation_inverse=lambda x:x, lam=1.): \n",
        "        '''\n",
        "        inputs:\n",
        "        - p: input dimension\n",
        "        - q: output dimension\n",
        "        - activation: non-linear function, from R^p to R^q. Default is identity\n",
        "        - activation_inverse: inverse of the activation function. Default is identity. \n",
        "        - lam: regularization term \n",
        "        '''\n",
        "        self.__validate_inputs(p=p, q=q, lam=lam) \n",
        "        self.p = p \n",
        "        self.q = q \n",
        "        self.activation = activation \n",
        "        self.activation_inverse = activation_inverse \n",
        "        self.lam = lam \n",
        "        self.xTy = padded_diagonal(lam, p+1,q) # +1 for intercept \n",
        "        self.yTx = padded_diagonal(lam, q+1,p) \n",
        "        self.xTx_inv = torch.diag(torch.tensor([1./lam]*(p+1))) \n",
        "        self.yTy_inv = torch.diag(torch.tensor([1./lam]*(q+1))) \n",
        "        self.betaT_forward = torch.matmul(self.xTx_inv, self.xTy) \n",
        "        self.betaT_forward = torch.transpose(self.betaT_forward, 0, 1) \n",
        "        self.betaT_backward = torch.matmul(self.yTy_inv, self.yTx) \n",
        "        self.betaT_backward = torch.transpose(self.betaT_backward, 0, 1) \n",
        "        self.x_forward = None \n",
        "        self.y_forward = None \n",
        "        self.x_backward = None \n",
        "        self.y_backward = None \n",
        "        pass \n",
        "    def forward(self, x): \n",
        "        'creates and stores x_forward and y_forward, then returns activation(y_forward)' \n",
        "        self.__validate_inputs(x=x, p=self.p) \n",
        "        self.x_forward = x \n",
        "        x = torch.cat((torch.tensor([[1.]]), x), dim=0) # intercept \n",
        "        self.y_forward = torch.matmul(self.betaT_forward, x) # predict \n",
        "        return self.activation(self.y_forward) \n",
        "    def backward(self, y): \n",
        "        'creates and stores x_backward and y_backward, then returns y_backward'\n",
        "        y = self.activation_inverse(y) \n",
        "        self.__validate_inputs(y=y, q=self.q) \n",
        "        self.y_backward = y \n",
        "        y = torch.cat((torch.tensor([[1.]]), y), dim=0) \n",
        "        self.x_backward = torch.matmul(self.betaT_backward, y) \n",
        "        return self.x_backward \n",
        "    def forward_fit(self): \n",
        "        'uses x_forward and y_backward to update forward model, then returns Sherman Morrison denominator' \n",
        "        self.__validate_inputs(x=self.x_forward, y=self.y_backward, p=self.p, q=self.q) \n",
        "        x = torch.cat((torch.tensor([[1.]]), self.x_forward), dim=0) \n",
        "        self.xTx_inv, sm_denom = self.sherman_morrison(self.xTx_inv, x, x) \n",
        "        self.xTy += torch.matmul(x, torch.transpose(self.y_backward, 0, 1)) \n",
        "        self.betaT_forward = torch.matmul(self.xTx_inv, self.xTy) \n",
        "        self.betaT_forward = torch.transpose(self.betaT_forward, 0, 1) \n",
        "        return sm_denom \n",
        "    def backward_fit(self):\n",
        "        'uses x_backward and y_forward to update backward model, then returns Sherman Morrison denominator'\n",
        "        self.__validate_inputs(x=self.x_forward, y=self.y_backward, p=self.p, q=self.q) \n",
        "        y = torch.cat((torch.tensor([[1.]]), self.y_backward), dim=0) \n",
        "        self.yTy_inv, sm_denom = self.sherman_morrison(self.yTy_inv, y, y) \n",
        "        self.yTx += torch.matmul(y, torch.transpose(self.x_backward, 0, 1)) \n",
        "        self.betaT_backward = torch.matmul(self.yTy_inv, self.yTx) \n",
        "        self.betaT_backward = torch.transpose(self.betaT_backward, 0, 1) \n",
        "        return sm_denom \n",
        "    @staticmethod\n",
        "    def sherman_morrison(inv_mat, vec1, vec2):\n",
        "        '''\n",
        "        applies Sherman Morrison updates, (mat + vec1 vec2^T)^{-1}\n",
        "        inputs:\n",
        "        - inv_mat: an inverted matrix \n",
        "        - vec1: a column vector \n",
        "        - vec2: a column vector \n",
        "        returns:\n",
        "        - updated matrix\n",
        "        - the Sherman Morrison denominator, for tracking numerical stability \n",
        "        '''\n",
        "        v2t = torch.transpose(vec2, 0, 1)\n",
        "        denominator = 1. + torch.matmul(torch.matmul(v2t, inv_mat), vec1) \n",
        "        numerator = torch.matmul(torch.matmul(inv_mat, vec1), torch.matmul(v2t, inv_mat)) \n",
        "        updated_inv_mat = inv_mat - numerator / denominator \n",
        "        return updated_inv_mat, float(denominator) \n",
        "    def __validate_inputs(self, p=None, q=None, lam=None, x=None, y=None): \n",
        "        'raises value exceptions if provided parameters are invalid'\n",
        "        if q is not None:\n",
        "            if not isinstance(q, int):\n",
        "                raise ValueError('`q` must be int!')\n",
        "            if q <= 0:\n",
        "                raise ValueError('`q` must be greater than zero!')\n",
        "        if p is not None:\n",
        "            if not isinstance(p, int): \n",
        "                raise ValueError('`p` must be int!')\n",
        "            if p <= 0: \n",
        "                raise ValueError('`p` must be greater than zero!')\n",
        "        if lam is not None:\n",
        "            if not (isinstance(lam, float) or isinstance(lam, int)):\n",
        "                raise ValueError('`lam` must be float or int!')\n",
        "            if lam < 0:\n",
        "                raise ValueError('`lam` must be non-negative!')\n",
        "        if x is not None and p is not None: \n",
        "            if type(x) != TORCH_TENSOR_TYPE:\n",
        "                raise ValueError('`x` must be of type `torch.tensor`!') \n",
        "            if list(x.shape) != [p,1]: \n",
        "                raise ValueError('`x.shape` must be `[p,1]`!') \n",
        "            if torch.isnan(x).any():\n",
        "                raise ValueError('`x` contains `nan`!')\n",
        "            pass \n",
        "        if y is not None and q is not None: \n",
        "            if type(y) != TORCH_TENSOR_TYPE:\n",
        "                raise ValueError('`y` must be of type `torch.tensor`!') \n",
        "            if list(y.shape) != [q,1]: \n",
        "                raise ValueError('`y.shape` must be `[q,1]`') \n",
        "            if torch.isnan(y).any():\n",
        "                raise ValueError('`y` contains `nan`!')\n",
        "            pass \n",
        "        pass \n",
        "    pass\n",
        "\n",
        "class OnlineNet: \n",
        "    'online, sequential dense net' \n",
        "    def __init__(self, layer_list): \n",
        "        ## validate inputs \n",
        "        if type(layer_list) != list: \n",
        "            raise ValueError('`layer_list` must be of type list!') \n",
        "        for layer in layer_list: \n",
        "            if not issubclass(type(layer), OnlineDenseLayer):\n",
        "                raise ValueError('each item in `layer_list` must be an instance of a subclass of `OnlineDenseLayer`!') \n",
        "        ## assign \n",
        "        self.layer_list = layer_list \n",
        "        pass \n",
        "    def forward(self, x): \n",
        "        'predict forward'\n",
        "        for layer in self.layer_list:\n",
        "            x = layer.forward(x) \n",
        "        return x \n",
        "    def backward(self, y):\n",
        "        'predict backward'\n",
        "        for layer in reversed(self.layer_list): \n",
        "            y = layer.backward(y) \n",
        "        return y \n",
        "    def fit(self): \n",
        "        'assumes layers x & y targets have already been set. Returns Sherman Morrison denominators per layer in (forward, backward) pairs in a list'\n",
        "        sherman_morrison_denominator_list = [] \n",
        "        for layer in self.layer_list:\n",
        "            forward_smd = layer.forward_fit() \n",
        "            backward_smd = layer.backward_fit() \n",
        "            sherman_morrison_denominator_list.append((forward_smd, backward_smd))\n",
        "        return sherman_morrison_denominator_list \n",
        "    def __reduce_sherman_morrison_denominator_list(self, smd_pair_list):\n",
        "        'returns the value closest to zero'\n",
        "        if type(smd_pair_list) != list: \n",
        "            raise ValueError('`smd_pair_list` must be of type `list`!')\n",
        "        if len(smd_pair_list) == 0:\n",
        "            return None \n",
        "        smallest_smd = None \n",
        "        for smd_pair in smd_pair_list:\n",
        "            if type(smd_pair) != tuple:\n",
        "                raise ValueError('`smd_pair_list` must be list of tuples!')\n",
        "            if smallest_smd is None: \n",
        "                smallest_smd = smd_pair[0] \n",
        "            if abs(smallest_smd) > abs(smd_pair[0]): \n",
        "                smallest_smd = smd_pair[0] \n",
        "            if abs(smallest_smd) > abs(smd_pair[1]):\n",
        "                smallest_smd = smd_pair[1] \n",
        "        return float(smallest_smd) \n",
        "    def __call__(self, x, y=None): \n",
        "        '''\n",
        "        If only x is given, a prediction is made and returned.\n",
        "        If x and y are given, then the model is updated, and returns\n",
        "        - the prediction\n",
        "        - the sherman morrison denominator closest to zero, for tracking numerical stability\n",
        "        '''\n",
        "        y_hat = self.forward(x) \n",
        "        if y is None: \n",
        "            return y_hat \n",
        "        self.backward(y) \n",
        "        self.layer_list[0].x_forward = x \n",
        "        self.layer_list[0].x_backward = x \n",
        "        self.layer_list[-1].y_forward = y \n",
        "        self.layer_list[-1].y_backward = y \n",
        "        smd_pair_list = self.fit() \n",
        "        smallest_smd = self.__reduce_sherman_morrison_denominator_list(smd_pair_list) \n",
        "        return y_hat, smallest_smd \n",
        "\n",
        "## tests \n",
        "\n",
        "## test 1: sherman morrison \n",
        "a = torch.tensor([[2., 1.], [1., 2.]]) \n",
        "b = torch.tensor([[.1],[.2]]) \n",
        "sm_inv, _ = OnlineDenseLayer.sherman_morrison(torch.inverse(a),b,b) \n",
        "num_inv = torch.inverse(a+torch.matmul(b, torch.transpose(b,0,1))) \n",
        "err = float(torch.abs(sm_inv - num_inv).sum()) \n",
        "assert(err < 1e-5) "
      ],
      "outputs": [],
      "execution_count": 36,
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "gather": {
          "logged": 1640050187099
        }
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# first experiment: mnist classification"
      ],
      "metadata": {
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from tqdm import tqdm\r\n",
        "from torchvision import datasets, transforms\r\n",
        "\r\n",
        "transform=transforms.Compose([\r\n",
        "    transforms.ToTensor(),\r\n",
        "    transforms.Normalize((0.1307,), (0.3081,))\r\n",
        "    ])\r\n",
        "\r\n",
        "dataset1 = datasets.MNIST('../../data', train=True, download=True, transform=transform)\r\n",
        "dataset2 = datasets.MNIST('../../data', train=False, transform=transform)\r\n",
        "\r\n",
        "train_loader = torch.utils.data.DataLoader(dataset1)\r\n",
        "test_loader = torch.utils.data.DataLoader(dataset2)\r\n",
        "\r\n",
        "n_labels = 10 \r\n",
        "\r\n",
        "## activation functions \r\n",
        "## torch.sigmoid \r\n",
        "inv_sigmoid = lambda x: -torch.log((1/(x+1e-8))-1) \r\n",
        "leaky_relu_alpha = .1 \r\n",
        "leaky_relu = lambda x: (x > 0)*x + (x <= 0)*x*leaky_relu_alpha \r\n",
        "inv_leaky_relu = lambda x: (x > 0)*x + (x <= 0)*x/leaky_relu_alpha \r\n",
        "\r\n",
        "model = OnlineNet(\r\n",
        "    [\r\n",
        "        #OnlineDenseLayer(p=1*1*28*28, q=1000, activation=torch.sigmoid, activation_inverse=inv_sigmoid),  \r\n",
        "        #OnlineDenseLayer(p=1000, q=5000, activation=torch.sigmoid, activation_inverse=inv_sigmoid), \r\n",
        "        #OnlineDenseLayer(p=5000, q=100, activation=torch.sigmoid, activation_inverse=inv_sigmoid), \r\n",
        "        #OnlineDenseLayer(p=100, q=n_labels, activation=torch.sigmoid, activation_inverse=inv_sigmoid)\r\n",
        "        OnlineDenseLayer(p=3, q=2, activation=leaky_relu, activation_inverse=inv_leaky_relu),\r\n",
        "        OnlineDenseLayer(p=2, q=1)\r\n",
        "    ] \r\n",
        ")\r\n",
        "\r\n",
        "def build_data(image, label): \r\n",
        "    'format data from iterator for model' \r\n",
        "    y = torch.tensor([1. if int(label[0]) == idx else 0. for idx in range(n_labels)]) ## one-hot representation \r\n",
        "    x = image.reshape([-1]) ## flatten \r\n",
        "    ## shrink so sigmoid inverse is well-defined \r\n",
        "    y = y*.90 + .05 \r\n",
        "    ## reshape to column vectors \r\n",
        "    x = x.reshape([-1,1]) \r\n",
        "    y = y.reshape([-1,1]) \r\n",
        "    return x, y \r\n",
        "\r\n",
        "def build_test_data():\r\n",
        "    x = torch.normal(mean=torch.zeros([3,1]))\r\n",
        "    y = torch.sigmoid(3. + 5.*x[0] - 10.*x[1])\r\n",
        "    y = y + 3*x[2]\r\n",
        "    y = y.reshape([-1,1])\r\n",
        "    return x, y\r\n",
        "\r\n",
        "errs = [] \r\n",
        "stab = [] \r\n",
        "pbar = tqdm(train_loader) \r\n",
        "for [image, label] in pbar: \r\n",
        "    #x, y = build_data(image, label) \r\n",
        "    x, y = build_test_data() \r\n",
        "    ## fit \r\n",
        "    y_hat, stability = model(x, y) \r\n",
        "    err = float((y - y_hat).abs().sum()) \r\n",
        "    errs.append(err) \r\n",
        "    stab.append(stability)\r\n",
        "    pbar.set_description(f'err: {err}, stab: {stability}') \r\n",
        "    ## train error \r\n",
        "    ## TODO "
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": "err: 4.8085551261901855, stab: 1.0005404949188232:   6%|▌         | 3586/60000 [00:07<01:50, 509.72it/s]   \n"
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-37-c63cced567fe>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     62\u001b[0m     \u001b[0merrs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0merr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     63\u001b[0m     \u001b[0mstab\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstability\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 64\u001b[0;31m     \u001b[0mpbar\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mset_description\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf'err: {err}, stab: {stability}'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     65\u001b[0m     \u001b[0;31m## train error\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     66\u001b[0m     \u001b[0;31m## TODO\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/anaconda/envs/azureml_py36/lib/python3.6/site-packages/tqdm/std.py\u001b[0m in \u001b[0;36mset_description\u001b[0;34m(self, desc, refresh)\u001b[0m\n\u001b[1;32m   1396\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdesc\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdesc\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m': '\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mdesc\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0;34m''\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1397\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mrefresh\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1398\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrefresh\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1399\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1400\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mset_description_str\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdesc\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrefresh\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/anaconda/envs/azureml_py36/lib/python3.6/site-packages/tqdm/std.py\u001b[0m in \u001b[0;36mrefresh\u001b[0;34m(self, nolock, lock_args)\u001b[0m\n\u001b[1;32m   1349\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1350\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_lock\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0macquire\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1351\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdisplay\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1352\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mnolock\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1353\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_lock\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrelease\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/anaconda/envs/azureml_py36/lib/python3.6/site-packages/tqdm/std.py\u001b[0m in \u001b[0;36mdisplay\u001b[0;34m(self, msg, pos)\u001b[0m\n\u001b[1;32m   1497\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mpos\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1498\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmoveto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpos\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1499\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msp\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__str__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mmsg\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0mmsg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1500\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mpos\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1501\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmoveto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0mpos\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/anaconda/envs/azureml_py36/lib/python3.6/site-packages/tqdm/std.py\u001b[0m in \u001b[0;36mprint_status\u001b[0;34m(s)\u001b[0m\n\u001b[1;32m    349\u001b[0m         \u001b[0;32mdef\u001b[0m \u001b[0mprint_status\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ms\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    350\u001b[0m             \u001b[0mlen_s\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdisp_len\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ms\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 351\u001b[0;31m             \u001b[0mfp_write\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'\\r'\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0ms\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;34m' '\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mmax\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlast_len\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mlen_s\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    352\u001b[0m             \u001b[0mlast_len\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlen_s\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    353\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/anaconda/envs/azureml_py36/lib/python3.6/site-packages/tqdm/std.py\u001b[0m in \u001b[0;36mfp_write\u001b[0;34m(s)\u001b[0m\n\u001b[1;32m    343\u001b[0m         \u001b[0;32mdef\u001b[0m \u001b[0mfp_write\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ms\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    344\u001b[0m             \u001b[0mfp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwrite\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_unicode\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ms\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 345\u001b[0;31m             \u001b[0mfp_flush\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    346\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    347\u001b[0m         \u001b[0mlast_len\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/anaconda/envs/azureml_py36/lib/python3.6/site-packages/tqdm/utils.py\u001b[0m in \u001b[0;36minner\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    140\u001b[0m         \u001b[0;32mdef\u001b[0m \u001b[0minner\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    141\u001b[0m             \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 142\u001b[0;31m                 \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    143\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mOSError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    144\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0merrno\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0;36m5\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/anaconda/envs/azureml_py36/lib/python3.6/site-packages/ipykernel/iostream.py\u001b[0m in \u001b[0;36mflush\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    340\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpub_thread\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpub_thread\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mthread\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpub_thread\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mthread\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mis_alive\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    341\u001b[0m             \u001b[0;31m# request flush on the background thread\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 342\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpub_thread\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mschedule\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_flush\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    343\u001b[0m             \u001b[0;31m# wait for flush to actually get through, if we can.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    344\u001b[0m             \u001b[0;31m# waiting across threads during import can cause deadlocks\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/anaconda/envs/azureml_py36/lib/python3.6/site-packages/ipykernel/iostream.py\u001b[0m in \u001b[0;36mschedule\u001b[0;34m(self, f)\u001b[0m\n\u001b[1;32m    201\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_events\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    202\u001b[0m             \u001b[0;31m# wake event thread (message content is ignored)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 203\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_event_pipe\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mb''\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    204\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    205\u001b[0m             \u001b[0mf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/anaconda/envs/azureml_py36/lib/python3.6/site-packages/zmq/sugar/socket.py\u001b[0m in \u001b[0;36msend\u001b[0;34m(self, data, flags, copy, track, routing_id, group)\u001b[0m\n\u001b[1;32m    503\u001b[0m                 )\n\u001b[1;32m    504\u001b[0m             \u001b[0mdata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgroup\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgroup\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 505\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0msuper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mSocket\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mflags\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mflags\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcopy\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcopy\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrack\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtrack\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    506\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    507\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0msend_multipart\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmsg_parts\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mflags\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcopy\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrack\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32mzmq/backend/cython/socket.pyx\u001b[0m in \u001b[0;36mzmq.backend.cython.socket.Socket.send\u001b[0;34m()\u001b[0m\n",
            "\u001b[0;32mzmq/backend/cython/socket.pyx\u001b[0m in \u001b[0;36mzmq.backend.cython.socket.Socket.send\u001b[0;34m()\u001b[0m\n",
            "\u001b[0;32mzmq/backend/cython/socket.pyx\u001b[0m in \u001b[0;36mzmq.backend.cython.socket._send_copy\u001b[0;34m()\u001b[0m\n",
            "\u001b[0;32m/anaconda/envs/azureml_py36/lib/python3.6/site-packages/zmq/backend/cython/checkrc.pxd\u001b[0m in \u001b[0;36mzmq.backend.cython.checkrc._check_rc\u001b[0;34m()\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ],
      "execution_count": 37,
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "### DELETE ME \r\n",
        "y1 = model.layer_list[0].forward(x)\r\n",
        "print(x)\r\n",
        "print(y1)\r\n",
        "\r\n",
        "x2 = model.layer_list[1].backward(y)\r\n",
        "print(x2)\r\n",
        "\r\n",
        "print(x)"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": "tensor([[-1.5899],\n        [-1.2096],\n        [-1.4435]])\ntensor([[0.],\n        [0.]])\ntensor([[0.],\n        [0.]])\ntensor([[-1.5899],\n        [-1.2096],\n        [-1.4435]])\n"
        }
      ],
      "execution_count": 29,
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "gather": {
          "logged": 1640048933463
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "### DELETE ME \r\n",
        "m2 = OnlineNet(\r\n",
        "    [\r\n",
        "        #OnlineDenseLayer(p=1*1*28*28, q=1000, activation=torch.sigmoid, activation_inverse=inv_sigmoid),  \r\n",
        "        #OnlineDenseLayer(p=1000, q=5000, activation=torch.sigmoid, activation_inverse=inv_sigmoid), \r\n",
        "        #OnlineDenseLayer(p=5000, q=100, activation=torch.sigmoid, activation_inverse=inv_sigmoid), \r\n",
        "        #OnlineDenseLayer(p=100, q=n_labels, activation=torch.sigmoid, activation_inverse=inv_sigmoid)\r\n",
        "        OnlineDenseLayer(p=3, q=2, activation=leaky_relu, activation_inverse=inv_leaky_relu),\r\n",
        "        OnlineDenseLayer(p=2, q=1)\r\n",
        "    ] \r\n",
        ")\r\n",
        "\r\n",
        "m2.layer_list[0].forward(x)"
      ],
      "outputs": [
        {
          "output_type": "execute_result",
          "execution_count": 30,
          "data": {
            "text/plain": "tensor([[0.],\n        [0.]])"
          },
          "metadata": {}
        }
      ],
      "execution_count": 30,
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "gather": {
          "logged": 1640048979659
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as plt \r\n",
        "\r\n",
        "cs = torch.cumsum(torch.tensor(errs), dim=0)\r\n",
        "ma = (cs[100:] - cs[:-100])/100.\r\n",
        "#list(ma)\r\n",
        "plt.plot(errs)\r\n",
        "#plt.plot(stab)\r\n",
        "plt.show()"
      ],
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": "<Figure size 432x288 with 1 Axes>",
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ],
      "execution_count": 38,
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "gather": {
          "logged": 1640050226285
        }
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## scratch space\r\n",
        "\r\n",
        "$x_1, X_2, X_3, \\ldots, X_{p-1}, x_p = y$\r\n",
        "\r\n",
        "$\\beta_1^F, \\beta_1^B, \\beta_2^F, \\beta_2^B, \\ldots, \\beta_{p-1}^F, \\beta_{p-1}^B$\r\n",
        "\r\n",
        "$\\hat x_{j+1} = \\sigma \\left( \\beta_j^{FT} x_j \\right)$\r\n",
        "\r\n",
        "forward series: $x_1, \\hat x_2, \\hat x_3, \\ldots, \\hat x_{p-1}, x_p = y$\r\n",
        "\r\n",
        "$ \\hat \\beta_{p-1}^{FT} = \\text{argmin}_\\beta \\| x_p - \\beta^{T} \\hat x_{p-1} \\|^2 $\r\n",
        "\r\n",
        "$ \\hat \\beta_{p-2}^{FT} = \\text{argmin}_\\beta \\| \\hat x_{p-1} - \\beta^{T} \\hat x_{p-2} \\|^2 $ We won't do this. \r\n",
        "\r\n",
        "$ \\tilde x_{j-1} = \\sigma^{-1}\\left( \\beta_j^{BT} x_j \\right)$\r\n",
        "\r\n",
        "backward series: $x_1, \\tilde x_2, \\tilde x_3, \\ldots, \\tilde x_{p-1}, x_p = y$\r\n",
        "\r\n",
        "$ \\hat \\beta_{p-2}^{F} = \\text{argmin}_\\beta \\| \\tilde x_{p-1} - \\beta^{T} \\hat x_{p-2} \\|^2 $\r\n",
        "\r\n",
        "$ \\hat \\beta_{p-2}^{B} = \\text{argmin}_\\beta \\| \\hat x_{p-2} - \\beta^{T} \\tilde x_{p-1} \\|^2 $"
      ],
      "metadata": {
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "$ \\hat x_3 = \\sigma \\left( \\beta_2^{FT} \\hat x_2 \\right) $\r\n",
        "\r\n",
        "$ \\hat \\beta_2^F = \\text{argmin}_\\beta \\| \\sigma^{-1}\\left( \\hat x_3 \\right) - \\beta^T \\hat x_2 \\|^2 $ Useless without $\\tilde x$\r\n",
        "\r\n",
        "$ \\tilde x_2 = \\sigma^{-1}\\left( \\beta_3^{BT} \\tilde x_3 \\right) $\r\n",
        "\r\n",
        "$ \\hat \\beta_2^B = \\text{argmin}_\\beta \\| \\sigma\\left( \\hat x_2 \\right) - \\beta^T \\hat x_3 \\|^2 $ Useless without $\\hat x$\r\n",
        "\r\n",
        "So, use these estimates instead.\r\n",
        "\r\n",
        "$ \\hat \\beta_2^F = \\text{argmin}_\\beta \\| \\sigma^{-1}\\left( \\tilde x_3 \\right) - \\beta^T \\hat x_2 \\|^2 $\r\n",
        "\r\n",
        "$ \\hat \\beta_2^B = \\text{argmin}_\\beta \\| \\sigma\\left( \\hat x_2 \\right) - \\beta^T \\tilde x_3 \\|^2 $"
      ],
      "metadata": {
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "$\\mathbb{E} l(X;\\theta) \\approx l(X;\\theta_0) + \\left( \\theta - \\theta_0 \\right)^T \\mathbb{E} \\nabla_\\theta l(X;\\theta_0) + \\left( \\theta - \\theta_0 \\right)^T \\mathbb{E} \\nabla^2_\\theta l(X;\\theta_0) \\left( \\theta - \\theta_0 \\right)/2 $\r\n",
        "\r\n",
        "$ = \\mathbb{E}l(X;\\theta_0) + 0 - \\left( \\theta - \\theta_0 \\right)^T \\mathcal{I}_{\\theta_0} \\left( \\theta - \\theta_0 \\right)/2 $\r\n"
      ],
      "metadata": {
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "$ X_{j+1} = \\beta^T X_j + \\sigma \\varepsilon, \\; \\varepsilon \\sim N(0, \\mathcal{I}) $\r\n",
        "\r\n",
        "$ X_{j+k} = \\beta^{kT} X_j \\Rightarrow \\mathbb{E}[X_j|X_0] = \\mathbb{E}[\\beta^{jT} X_0|X_0] = \\beta^{jT} X_0 $\r\n",
        "\r\n",
        "$ \\mathbb{E}\\left[ f(X_0) \\; | \\; X_0 \\right] = f(X_0) $"
      ],
      "metadata": {
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      }
    }
  ],
  "metadata": {
    "kernelspec": {
      "name": "python3-azureml",
      "language": "python",
      "display_name": "Python 3.6 - AzureML"
    },
    "language_info": {
      "name": "python",
      "version": "3.6.9",
      "mimetype": "text/x-python",
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "pygments_lexer": "ipython3",
      "nbconvert_exporter": "python",
      "file_extension": ".py"
    },
    "kernel_info": {
      "name": "python3-azureml"
    },
    "nteract": {
      "version": "nteract-front-end@1.0.0"
    },
    "microsoft": {
      "host": {
        "AzureML": {
          "notebookHasBeenCompleted": true
        }
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 2
}