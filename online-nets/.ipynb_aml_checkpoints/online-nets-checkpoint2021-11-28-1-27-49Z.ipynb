{
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# online nets\r\n",
        "\r\n",
        "Deep learning is powerful but computationally expensive, frequently requiring massive compute budgets. In persuit of cost-effective-yet-powerful AI, this work explores and evaluates a heuristic which should lend to more-efficient use of data through online learning.\r\n",
        "\r\n",
        "Goal: evaluate a deep learning alternative capable of true online learning. Solution requirements:\r\n",
        "\r\n",
        "1. catastrophic forgetting should be impossible;\r\n",
        "2. all data is integrated into sufficient statistics of fixed dimension;\r\n",
        "3. and our solution should have predictive power comparable to deep learning.\r\n",
        "\r\n",
        "## modeling strategy\r\n",
        "\r\n",
        "We will not attempt to derive sufficient statistics for an entire deep net, but instead leverage well-known sufficient statistics for least squares models, \r\n",
        "so will have sufficient statistics per deep net layer. If this can be empirically shown effective, we'll build-out the theory afterwards. \r\n",
        "\r\n",
        "Recognizing a deep net as a series of compositions, as follows.\r\n",
        "\r\n",
        "$ Y + \\varepsilon \\approx \\mathbb{E}Y = \\sigma_3 \\circ \\beta_3^T \\circ \\sigma_2 \\circ \\beta_2^T \\circ \\sigma_1 \\circ \\beta_1^T X $\r\n",
        "\r\n",
        "So, we can isolate invidivdual $\\beta_j$ matrices using (psuedo-)inverses $\\beta_j^{-1}$ like so.\r\n",
        "\r\n",
        "$ \\sigma_2^{-1} \\circ \\beta_3^{-1} \\circ \\sigma_3^{-1} (Y) \\approx  \\beta_2^T \\circ \\sigma_1 \\circ \\beta_1^T X $\r\n",
        "\r\n",
        "In this example, if we freeze all $\\beta_j$'s except $\\beta_2$, we are free to update $\\hat \\beta_2$ using $\\tilde Y = \\sigma_2^{-1} \\circ \\beta_3^{-1} \\circ \\sigma_3^{-1} (Y) $\r\n",
        "and $\\tilde X = \\sigma_1 \\circ \\beta_1^T X $.\r\n",
        "\r\n",
        "Using a least squares formulation for fitting to $\\left( \\tilde X, \\tilde Y \\right)$, we get sufficient statistics per layer."
      ],
      "metadata": {
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# model code definitions"
      ],
      "metadata": {
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "\n",
        "TORCH_TENSOR_TYPE = type(torch.tensor(1)) \n",
        "\n",
        "def iterated_diagonals(diag_value, n_rows, n_cols): \n",
        "    ## construct diagonal matrix \n",
        "    n_diag = min(n_rows, n_cols)\n",
        "    diag = torch.diag(torch.tensor([diag_value]*n_diag))\n",
        "    if n_rows > n_cols: \n",
        "        ## pad rows \n",
        "        pad = n_rows//n_cols + 1\n",
        "        return torch.cat([diag]*pad, 0)[:n_rows, :n_cols] \n",
        "    if n_cols > n_rows: \n",
        "        ## pad cols \n",
        "        pad = n_cols//n_rows + 1 \n",
        "        return torch.cat([diag]*pad, 1)[:n_rows, :n_cols] \n",
        "    ## no padding \n",
        "    return diag \n",
        "\n",
        "class OnlineDenseLayer: \n",
        "    ''' \n",
        "    A single dense net, formulated as a least squares model. \n",
        "    ''' \n",
        "    def __init__(self, p, q, activation=lambda x:x, activation_inverse=lambda x:x, lam=1., clip=10000., dlamdn=0.): \n",
        "        ''' \n",
        "        inputs: \n",
        "        - p: input dimension \n",
        "        - q: output dimension \n",
        "        - activation: non-linear function, from R^p to R^q. Default is identity. \n",
        "        - activation_inverse: inverse of the activation function. Default is identity. \n",
        "        - lam: regularization term \n",
        "        - clip: predicted value clipping limit \n",
        "        - dlamdn: rate of lambda growth relative to n for online regularization \n",
        "        ''' \n",
        "        lam = float(lam) \n",
        "        clip = float(clip) \n",
        "        if dlamdn is not None: \n",
        "            dlamdn = float(dlamdn)\n",
        "        self.__validate_inputs(p=p, q=q, lam=lam, clip=clip, dlamdn=dlamdn) \n",
        "        self.p = p \n",
        "        self.q = q \n",
        "        self.clip = clip \n",
        "        self.activation = activation \n",
        "        self.activation_inverse = activation_inverse \n",
        "        self.batch_norm_forward_mean = None \n",
        "        self.batch_norm_forward_std = None \n",
        "        self.batch_norm_forward_n = 0 \n",
        "        self.batch_norm_backward_mean = None \n",
        "        self.batch_norm_backward_std = None \n",
        "        self.batch_norm_backward_n = 0 \n",
        "        self.lam = lam \n",
        "        self.dlamdn = dlamdn \n",
        "        self.xTy = iterated_diagonals(lam, p+1,q) # +1 for intercept \n",
        "        self.yTx = iterated_diagonals(lam, q+1,p) \n",
        "        self.xTx_inv = torch.diag(torch.tensor([1./lam]*(p+1))) \n",
        "        self.yTy_inv = torch.diag(torch.tensor([1./lam]*(q+1))) \n",
        "        self.betaT_forward = torch.matmul(self.xTx_inv, self.xTy) \n",
        "        self.betaT_forward = torch.transpose(self.betaT_forward, 0, 1) \n",
        "        self.betaT_backward = torch.matmul(self.yTy_inv, self.yTx) \n",
        "        self.betaT_backward = torch.transpose(self.betaT_backward, 0, 1) \n",
        "        self.x_forward = None \n",
        "        self.y_forward = None \n",
        "        self.x_backward = None \n",
        "        self.y_backward = None \n",
        "        pass \n",
        "    def copy(self): \n",
        "        copied_layer = OnlineDenseLayer(self.p, self.q)\n",
        "        copied_layer.p = self.p \n",
        "        copied_layer.q = self.q \n",
        "        copied_layer.clip = self.clip \n",
        "        copied_layer.activation = self.activation \n",
        "        copied_layer.activation_inverse = self.activation_inverse \n",
        "        copied_layer.batch_norm_forward_mean = self.batch_norm_forward_mean \n",
        "        copied_layer.batch_norm_forward_std = self.batch_norm_forward_std \n",
        "        copied_layer.batch_norm_forward_n = self.batch_norm_forward_n \n",
        "        copied_layer.batch_norm_backward_mean = self.batch_norm_backward_mean \n",
        "        copied_layer.batch_norm_backward_std = self.batch_norm_backward_std \n",
        "        copied_layer.batch_norm_backward_n = self.batch_norm_backward_n \n",
        "        copied_layer.lam = self.lam \n",
        "        copied_layer.dlamdn = self.dlamdn \n",
        "        copied_layer.xTy = self.xTy.clone() \n",
        "        copied_layer.yTx = self.yTx.clone()\n",
        "        copied_layer.betaT_forward = self.betaT_forward.clone()\n",
        "        copied_layer.betaT_backward = self.betaT_backward.clone()\n",
        "        self.x_forward = None \n",
        "        self.y_forward = None \n",
        "        self.x_backward = None \n",
        "        self.y_backward = None\n",
        "        return copied_layer \n",
        "    def forward(self, x): \n",
        "        'creates and stores x_forward and y_forward, then returns activation(y_forward)' \n",
        "        self.__validate_inputs(x=x, p=self.p)  \n",
        "        x = self.batch_norm(x, forward=True) ## TODO use fitting or not \n",
        "        self.x_forward = x\n",
        "        x = torch.cat((torch.tensor([[1.]]), x), dim=0) # intercept \n",
        "        self.y_forward = torch.matmul(self.betaT_forward, x) # predict \n",
        "        self.y_forward = torch.clip(self.y_forward, -self.clip, self.clip)\n",
        "        return self.activation(self.y_forward) \n",
        "    def backward(self, y): \n",
        "        'creates and stores x_backward and y_backward, then returns y_backward' \n",
        "        y = self.activation_inverse(y) \n",
        "        self.__validate_inputs(y=y, q=self.q) \n",
        "        y = self.batch_norm(y, forward=False) ## TODO use fitting or not\n",
        "        self.y_backward = y \n",
        "        y = torch.cat((torch.tensor([[1.]]), y), dim=0) \n",
        "        self.x_backward = torch.matmul(self.betaT_backward, y) \n",
        "        self.x_backward = torch.clip(self.x_backward, -self.clip, self.clip)\n",
        "        return self.x_backward \n",
        "    def forward_fit(self): \n",
        "        'uses x_forward and y_backward to update forward model, then returns Sherman Morrison denominator' \n",
        "        self.__validate_inputs(x=self.x_forward, y=self.y_backward, p=self.p, q=self.q) \n",
        "        x = torch.cat((torch.tensor([[1.]]), self.x_forward), dim=0) \n",
        "        self.xTx_inv, sm_denom = self.sherman_morrison(self.xTx_inv, x, x) \n",
        "        ##self.xTx_inv = self.reregularizer(self.xTx_inv, self.dlamdn) ## real online regularization too slow \n",
        "        self.xTy += torch.matmul(x, torch.transpose(self.y_backward, 0, 1)) \n",
        "        self.betaT_forward = torch.matmul(self.xTx_inv, self.xTy) \n",
        "        self.betaT_forward = torch.transpose(self.betaT_forward, 0, 1) \n",
        "        return sm_denom \n",
        "    def backward_fit(self):\n",
        "        'uses x_backward and y_forward to update backward model, then returns Sherman Morrison denominator' \n",
        "        self.__validate_inputs(x=self.x_forward, y=self.y_backward, p=self.p, q=self.q) \n",
        "        y = torch.cat((torch.tensor([[1.]]), self.y_backward), dim=0) \n",
        "        self.yTy_inv, sm_denom = self.sherman_morrison(self.yTy_inv, y, y) \n",
        "        ##self.yTy_inv = self.reregularizer(self.yTy_inv, self.dlamdn) \n",
        "        self.yTx += torch.matmul(y, torch.transpose(self.x_backward, 0, 1)) \n",
        "        self.betaT_backward = torch.matmul(self.yTy_inv, self.yTx) \n",
        "        self.betaT_backward = torch.transpose(self.betaT_backward, 0, 1) \n",
        "        return sm_denom \n",
        "    def batch_norm(self, x, forward, fitting=True):\n",
        "        '''\n",
        "        batch normalize tensor\n",
        "        inputs:\n",
        "        - x: (tensor) to be normalized \n",
        "        - forward: (boolean) indicates prediction is forward, instead of backward \n",
        "        - fitting: (boolean) if in model fitting, update values \n",
        "        '''\n",
        "        ## retrieve \n",
        "        if forward:\n",
        "            m = self.batch_norm_forward_mean \n",
        "            s = self.batch_norm_forward_std\n",
        "            n = self.batch_norm_forward_n \n",
        "        else: \n",
        "            m = self.batch_norm_backward_mean \n",
        "            s = self.batch_norm_backward_std\n",
        "            n = self.batch_norm_backward_n \n",
        "        ## caculate \n",
        "        if n == 0: \n",
        "            n = 1 \n",
        "            m = x.mean() \n",
        "            s = x.std() \n",
        "        else: \n",
        "            n += 1 \n",
        "            m = x.mean()/n + m*(n-1)/n \n",
        "            s = x.std()/n + s*(n-1)/n \n",
        "        ## store \n",
        "        if fitting:\n",
        "            if forward: \n",
        "                self.batch_norm_forward_mean = m \n",
        "                self.batch_norm_forward_std = s \n",
        "                self.batch_norm_forward_n = n \n",
        "            else: \n",
        "                self.batch_norm_backward_mean = m\n",
        "                self.batch_norm_backward_std = s \n",
        "                self.batch_norm_backward_n = n \n",
        "        ## no dividing by zero \n",
        "        if s < 1e-3:\n",
        "            s = 1e-3 \n",
        "        return (x - m)/s \n",
        "    def reregularize(self, dlamdn=None): \n",
        "        if dlamdn is None:\n",
        "            dlamdn = self.dlamdn \n",
        "        self.xTx_inv = self.online_regularizer(self.xTx_inv, dlamdn) \n",
        "        self.yTy_inv = self.online_regularizer(self.yTy_inv, dlamdn) \n",
        "        pass \n",
        "    @staticmethod\n",
        "    def online_regularizer(m_inv, dlam):\n",
        "        '''\n",
        "        Used to expand the regularization sphere as samples grow.\n",
        "        Applies modified Sherman Morrison formula for numerical efficiency. \n",
        "        inputs\n",
        "        - m_inv: inverse matrix of m \n",
        "        - dlam: regularizer to be added on the diagonal \n",
        "        returns\n",
        "         - (m + 1/dlam)^{-1} \n",
        "        '''\n",
        "        if dlam == 0.:\n",
        "            ## avoid degeneracy \n",
        "            return m_inv \n",
        "        dlam_inv = 1/dlam \n",
        "        for i in range(m_inv.shape[0]): \n",
        "            m_inv -= dlam_inv * torch.matmul(m_inv[:,i].reshape((-1,1)), m_inv[i,:].reshape((1,-1))) / (1. + dlam_inv * m_inv[i,i]) \n",
        "        return m_inv  \n",
        "    @staticmethod \n",
        "    def sherman_morrison(inv_mat, vec1, vec2): \n",
        "        ''' \n",
        "        applies Sherman Morrison updates, (mat + vec1 vec2^T)^{-1} \n",
        "        inputs: \n",
        "        - inv_mat: an inverted matrix \n",
        "        - vec1: a column vector \n",
        "        - vec2: a column vector \n",
        "        returns: \n",
        "        - updated matrix \n",
        "        - the Sherman Morrison denominator, for tracking numerical stability \n",
        "        ''' \n",
        "        v2t = torch.transpose(vec2, 0, 1)\n",
        "        denominator = 1. + torch.matmul(torch.matmul(v2t, inv_mat), vec1) \n",
        "        numerator = torch.matmul(torch.matmul(inv_mat, vec1), torch.matmul(v2t, inv_mat)) \n",
        "        updated_inv_mat = inv_mat - numerator / denominator \n",
        "        return updated_inv_mat, float(denominator) \n",
        "    def __validate_inputs(self, p=None, q=None, lam=None, x=None, y=None, clip=None, dlamdn=None): \n",
        "        'raises value exceptions if provided parameters are invalid'\n",
        "        if q is not None:\n",
        "            if not isinstance(q, int):\n",
        "                raise ValueError('`q` must be int!')\n",
        "            if q <= 0:\n",
        "                raise ValueError('`q` must be greater than zero!')\n",
        "        if p is not None:\n",
        "            if not isinstance(p, int): \n",
        "                raise ValueError('`p` must be int!')\n",
        "            if p <= 0: \n",
        "                raise ValueError('`p` must be greater than zero!')\n",
        "        if lam is not None:\n",
        "            if not (isinstance(lam, float) or isinstance(lam, int)):\n",
        "                raise ValueError('`lam` must be float or int!')\n",
        "            if lam < 0:\n",
        "                raise ValueError('`lam` must be non-negative!')\n",
        "        if x is not None and p is not None: \n",
        "            if type(x) != TORCH_TENSOR_TYPE:\n",
        "                raise ValueError('`x` must be of type `torch.tensor`!') \n",
        "            if list(x.shape) != [p,1]: \n",
        "                raise ValueError('`x.shape` must be `[p,1]`!') \n",
        "            if torch.isnan(x).any():\n",
        "                raise ValueError('`x` contains `nan`!')\n",
        "            pass \n",
        "        if y is not None and q is not None: \n",
        "            if type(y) != TORCH_TENSOR_TYPE:\n",
        "                raise ValueError('`y` must be of type `torch.tensor`!') \n",
        "            if list(y.shape) != [q,1]: \n",
        "                raise ValueError('`y.shape` must be `[q,1]`') \n",
        "            if torch.isnan(y).any():\n",
        "                raise ValueError('`y` contains `nan`!')\n",
        "            pass  \n",
        "        if clip is not None: \n",
        "            if type(clip) != float:\n",
        "                raise ValueError('`clip` my be of type `float`!') \n",
        "            if clip <= 0.: \n",
        "                raise ValueError('`clip` must be positive!')\n",
        "            pass\n",
        "        if dlamdn is not None: \n",
        "            if type(dlamdn) != float: \n",
        "                raise ValueError('`dlamdn` my be of type `float`!') \n",
        "            if dlamdn < 0.: \n",
        "                raise ValueError('`dlamdn` must be non-negative!') \n",
        "            pass\n",
        "        pass\n",
        "    pass\n",
        "\n",
        "class OnlineNet: \n",
        "    'online, sequential dense net' \n",
        "    def __init__(self, layer_list, dlamdn=0., reregularization_frequency=1000): \n",
        "        '''\n",
        "        initialize an online dense net\n",
        "        inputs:\n",
        "        - layer_list: list of OnlineDenseLayers \n",
        "        - dlamdn: (float >= 0) regularization rate per n. Disabled if zero \n",
        "        - reregularization_frequency: (int > 0) reregularize after fitting this number of samples, since reregularization is computationally expensive\n",
        "        '''\n",
        "        ## validate inputs \n",
        "        if type(layer_list) != list: \n",
        "            raise ValueError('`layer_list` must be of type list!') \n",
        "        for layer in layer_list: \n",
        "            if not issubclass(type(layer), OnlineDenseLayer):\n",
        "                raise ValueError('each item in `layer_list` must be an instance of a subclass of `OnlineDenseLayer`!') \n",
        "        if type(dlamdn) != float:\n",
        "            raise ValueError('`dlamdn` must of type `float`!') \n",
        "        if dlamdn < 0.:\n",
        "            raise ValueError('`dlamdn` must be non-negative!') \n",
        "        if type(reregularization_frequency) != int:\n",
        "            raise ValueError('`reregularization_frequency` must be of type `int`!') \n",
        "        if reregularization_frequency <= 0:\n",
        "            raise ValueError('`reregularization_frequency` must be postive!') \n",
        "        ## assign \n",
        "        self.layer_list = layer_list \n",
        "        self.fit_count = 0 \n",
        "        self.dlamdn = dlamdn \n",
        "        self.reregularization_frequency = reregularization_frequency \n",
        "        pass \n",
        "    def copy(self):\n",
        "        copied_layers = [] \n",
        "        for layer in self.layer_list:\n",
        "            copied_layers.append(layer.copy()) \n",
        "        copied_net = OnlineNet(copied_layers, \n",
        "                dlamdn=self.dlamdn, \n",
        "                reregularization_frequency=self.reregularization_frequency)\n",
        "        return copied_net \n",
        "    def forward(self, x): \n",
        "        'predict forward'\n",
        "        for layer in self.layer_list:\n",
        "            x = layer.forward(x) \n",
        "        return x \n",
        "    def backward(self, y):\n",
        "        'predict backward'\n",
        "        for layer in reversed(self.layer_list): \n",
        "            y = layer.backward(y) \n",
        "        return y \n",
        "    def fit(self): \n",
        "        'assumes layers x & y targets have already been set. Returns Sherman Morrison denominators per layer in (forward, backward) pairs in a list'\n",
        "        sherman_morrison_denominator_list = [] \n",
        "        for layer in self.layer_list:\n",
        "            forward_smd = layer.forward_fit() \n",
        "            backward_smd = layer.backward_fit() \n",
        "            sherman_morrison_denominator_list.append((forward_smd, backward_smd))\n",
        "        return sherman_morrison_denominator_list \n",
        "    def reregularize(self, dlamdn=None): \n",
        "        for layer in self.layer_list:\n",
        "            layer.reregularize(dlamdn)\n",
        "            pass \n",
        "        pass \n",
        "    def __reduce_sherman_morrison_denominator_list(self, smd_pair_list):\n",
        "        'returns the value closest to zero'\n",
        "        if type(smd_pair_list) != list: \n",
        "            raise ValueError('`smd_pair_list` must be of type `list`!')\n",
        "        if len(smd_pair_list) == 0:\n",
        "            return None \n",
        "        smallest_smd = None \n",
        "        for smd_pair in smd_pair_list:\n",
        "            if type(smd_pair) != tuple:\n",
        "                raise ValueError('`smd_pair_list` must be list of tuples!')\n",
        "            if smallest_smd is None: \n",
        "                smallest_smd = smd_pair[0] \n",
        "            if abs(smallest_smd) > abs(smd_pair[0]): \n",
        "                smallest_smd = smd_pair[0] \n",
        "            if abs(smallest_smd) > abs(smd_pair[1]):\n",
        "                smallest_smd = smd_pair[1] \n",
        "        return float(smallest_smd) \n",
        "    def __call__(self, x, y=None): \n",
        "        '''\n",
        "        If only x is given, a prediction is made and returned.\n",
        "        If x and y are given, then the model is updated, and returns\n",
        "        - the prediction\n",
        "        - the sherman morrison denominator closest to zero, for tracking numerical stability\n",
        "        '''\n",
        "        y_hat = self.forward(x) \n",
        "        if y is None: \n",
        "            return y_hat \n",
        "        self.backward(y) \n",
        "        self.layer_list[0].x_forward = x \n",
        "        self.layer_list[0].x_backward = x \n",
        "        self.layer_list[-1].y_forward = y \n",
        "        self.layer_list[-1].y_backward = y \n",
        "        smd_pair_list = self.fit() \n",
        "        smallest_smd = self.__reduce_sherman_morrison_denominator_list(smd_pair_list) \n",
        "        self.fit_count += 1 \n",
        "        if self.dlamdn is not None and self.fit_count % self.reregularization_frequency == 0:\n",
        "            ## dividing by self.reregularization_frequency ensures mathematical equivalency to reregularizing with every step \n",
        "            self.reregularize(self.dlamdn/self.reregularization_frequency) \n",
        "        return y_hat, smallest_smd \n",
        "\n",
        "## tests \n",
        "\n",
        "## test 1: sherman morrison \n",
        "a = torch.tensor([[2., 1.], [1., 2.]]) \n",
        "b = torch.tensor([[.1],[.2]]) \n",
        "sm_inv, _ = OnlineDenseLayer.sherman_morrison(torch.inverse(a),b,b) \n",
        "num_inv = torch.inverse(a+torch.matmul(b, torch.transpose(b,0,1))) \n",
        "err = float(torch.abs(sm_inv - num_inv).sum()) \n",
        "assert(err < 1e-5) \n",
        "\n",
        "## test 2: online regularization sherman morrison \n",
        "a = torch.tensor([[2., 1.], [1., 2.]]) \n",
        "b = torch.tensor([[.1, 0.], [0., .1]])\n",
        "or_inv = OnlineDenseLayer.online_regularizer(torch.inverse(a), 10.) \n",
        "num_inv = torch.inverse(a+b) \n",
        "err = float(torch.abs(or_inv - num_inv).sum()) \n",
        "assert(err < 1e-5) "
      ],
      "outputs": [],
      "execution_count": 1,
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "gather": {
          "logged": 1640536685384
        }
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# first experiment: mnist classification"
      ],
      "metadata": {
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from tqdm import tqdm\r\n",
        "from torchvision import datasets, transforms\r\n",
        "\r\n",
        "transform=transforms.Compose([\r\n",
        "    transforms.ToTensor(),\r\n",
        "    transforms.Normalize((0.1307,), (0.3081,))\r\n",
        "    ])\r\n",
        "\r\n",
        "dataset1 = datasets.MNIST('../../data', train=True, download=True, transform=transform)\r\n",
        "dataset2 = datasets.MNIST('../../data', train=False, transform=transform)\r\n",
        "\r\n",
        "train_loader = torch.utils.data.DataLoader(dataset1)\r\n",
        "test_loader = torch.utils.data.DataLoader(dataset2)\r\n",
        "\r\n",
        "n_labels = 10 \r\n",
        "lam = 100. \r\n",
        "dlamdn = 10. \r\n",
        "reregularization_frequency = 1000 \r\n",
        "clip = 100. \r\n",
        "\r\n",
        "## activation functions \r\n",
        "## torch.sigmoid \r\n",
        "inv_sigmoid = lambda x: -torch.log((1/(x+1e-8))-1) \r\n",
        "leaky_relu_alpha = .1 \r\n",
        "leaky_relu = lambda x: (x > 0)*x + (x <= 0)*x*leaky_relu_alpha \r\n",
        "inv_leaky_relu = lambda x: (x > 0)*x + (x <= 0)*x/leaky_relu_alpha \r\n",
        "\r\n",
        "model = OnlineNet( \r\n",
        "    layer_list = [ \r\n",
        "        OnlineDenseLayer(p=1*1*28*28, q=100, activation=leaky_relu, activation_inverse=inv_leaky_relu, lam=lam, clip=clip), \r\n",
        "        OnlineDenseLayer(p=100, q=100, activation=leaky_relu, activation_inverse=inv_leaky_relu, lam=lam, clip=clip), \r\n",
        "        OnlineDenseLayer(p=100, q=100, activation=leaky_relu, activation_inverse=inv_leaky_relu, lam=lam, clip=clip), \r\n",
        "        OnlineDenseLayer(p=100, q=n_labels, activation=torch.sigmoid, activation_inverse=inv_sigmoid, lam=lam, clip=clip) \r\n",
        "    ], \r\n",
        "    reregularization_frequency = reregularization_frequency, \r\n",
        "    dlamdn = dlamdn \r\n",
        ") \r\n",
        "\r\n",
        "def build_data(image, label): \r\n",
        "    'format data from iterator for model' \r\n",
        "    y = torch.tensor([1. if int(label[0]) == idx else 0. for idx in range(n_labels)]) ## one-hot representation \r\n",
        "    x = image.reshape([-1]) ## flatten \r\n",
        "    ## shrink so sigmoid inverse is well-defined \r\n",
        "    y = y*.90 + .05 \r\n",
        "    ## reshape to column vectors \r\n",
        "    x = x.reshape([-1,1]) \r\n",
        "    y = y.reshape([-1,1]) \r\n",
        "    return x, y \r\n",
        "\r\n",
        "def match(y, y_hat):\r\n",
        "    y = y.reshape(-1)\r\n",
        "    y_hat = y_hat.reshape(-1)\r\n",
        "    if y.argmax() == y_hat.argmax():\r\n",
        "        return 1.\r\n",
        "    return 0. \r\n",
        "\r\n",
        "def run(data_iterable, fit=True, max_iters=None, model=model):\r\n",
        "    '''\r\n",
        "    fit or predict on dataset \r\n",
        "    inputs:\r\n",
        "    - data_iterable: an iterable of (image, label) pairs\r\n",
        "    - fit: (bool) are we integrating the (image, label) pair into the model or just predicting?\r\n",
        "    - max_iters: (int or None) if int then cap fit/predict iters at this amount, otherwise run the whole iterable \r\n",
        "    - model: (OnlineDenseNet) the model to update in-place \r\n",
        "    output: \r\n",
        "    - errs: a list of model errors \r\n",
        "    - stab: a list of numerical stability statistics \r\n",
        "    - y_std: a list of y_hat standard deviations \r\n",
        "    - acc: a list of running average accuracies \r\n",
        "    side-effects: \r\n",
        "    - model is updated in-place \r\n",
        "    '''\r\n",
        "    ## init stats \r\n",
        "    errs = [] \r\n",
        "    stab = [] \r\n",
        "    y_std = [] \r\n",
        "    acc = [0.] \r\n",
        "    ## get data \r\n",
        "    pbar = tqdm(data_iterable)\r\n",
        "    n_iters = 0 \r\n",
        "    for [image, label] in pbar: \r\n",
        "        n_iters += 1 \r\n",
        "        ## get a datum \r\n",
        "        x, y = build_data(image, label) \r\n",
        "        ## fit or predict \r\n",
        "        if fit: \r\n",
        "            y_hat, stability = model(x, y) \r\n",
        "        else:\r\n",
        "            y_hat = model(x) \r\n",
        "            stability = 1. \r\n",
        "        ## stats \r\n",
        "        err = float((y - y_hat).abs().sum()) \r\n",
        "        errs.append(err) \r\n",
        "        stab.append(stability) \r\n",
        "        std = float(y_hat.std()) \r\n",
        "        y_std.append(std) \r\n",
        "        acc_n = max(len(acc), 1000) \r\n",
        "        acc.append(match(y,y_hat)/acc_n + acc[-1]*(acc_n-1)/acc_n) \r\n",
        "        pbar.set_description(f'acc: {acc[-1]:.5f}, err: {err:.5f}, y_std: {std:.5f}, stab: {stability:.5f}') \r\n",
        "        if max_iters is not None: \r\n",
        "            if n_iters > max_iters:\r\n",
        "                return errs, stab, y_std, acc\r\n",
        "    return errs, stab, y_std, acc \r\n",
        "\r\n",
        "def test(data_iterable, model, max_iters=None): \r\n",
        "    'calculates accuracy correctly' \r\n",
        "    hits = [] \r\n",
        "    n_iters = 0 \r\n",
        "\r\n",
        "    return None \r\n",
        "\r\n",
        "errs, stab, y_std, acc = run(train_loader, fit=True, max_iters=10000) "
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": "acc: 0.68195, err: 4.25238, y_std: 0.08848, stab: 1.00047:  17%|█▋        | 10000/60000 [01:16<06:24, 129.97it/s]\n"
        }
      ],
      "execution_count": 2,
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "gather": {
          "logged": 1640536763333
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as plt \r\n",
        "\r\n",
        "print('acc')\r\n",
        "plt.plot(acc[100:])\r\n",
        "plt.show()"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": "acc\n"
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": "<Figure size 432x288 with 1 Axes>",
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ],
      "execution_count": 3,
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "gather": {
          "logged": 1640536763681
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "print('errs')\r\n",
        "plt.plot(errs)\r\n",
        "plt.show()"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": "errs\n"
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": "<Figure size 432x288 with 1 Axes>",
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ],
      "execution_count": 4,
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "gather": {
          "logged": 1640536763830
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "print('y_std')\r\n",
        "plt.plot(y_std)\r\n",
        "plt.show()"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": "y_std\n"
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": "<Figure size 432x288 with 1 Axes>",
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ],
      "execution_count": 5,
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "gather": {
          "logged": 1640536764073
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "print('stab')\r\n",
        "plt.plot(stab)\r\n",
        "plt.show()"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": "stab\n"
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": "<Figure size 432x288 with 1 Axes>",
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ],
      "execution_count": 6,
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "gather": {
          "logged": 1640536764355
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "## test dataset \r\n",
        "errs, stab, y_std, acc = run(test_loader, fit=False, max_iters=10000) "
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": "acc: 0.68048, err: 4.20706, y_std: 0.09620, stab: 1.00000: 100%|██████████| 10000/10000 [00:27<00:00, 366.48it/s]\n"
        }
      ],
      "execution_count": 7,
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "gather": {
          "logged": 1640536791602
        }
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# hypothesis test 1: does this solve catestrophic forgetting? \r\n",
        "\r\n",
        "Least squares' sufficient statistics have finite dimension and closed-form online update equations which guarantee perfect transfer learning. \r\n",
        "Our use of one least squares estimator per deep net layer enjoys a series of such sufficient statistics, but is only heuristically simlar to the mathematical guarantees of least squares. \r\n",
        "Nevertheless, we have proceeded hypothesizing some degree of a transfer learning benefit. \r\n",
        "In this section, we test this hypothesis. \r\n",
        "\r\n",
        "To test our hypothesis, we will subsample MNIST into two parts: initial and expanded. \r\n",
        "The initial portion will include digits 0 through 7, and expanded will only include digits 8 and 9. \r\n",
        "We will first fit our model to the initial dataset and then _transfer learn_ by fitting to the expanded dataset. \r\n",
        "If our hypothesis is true, transfer learning should be maintained and thus catastrophic forgetting avoided, so we'd expect the updated model to retain the ability to predict on digits 0 through 7."
      ],
      "metadata": {
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "## build data \r\n",
        "min_train_samples = 10000 \r\n",
        "min_test_samples = 10000 \r\n",
        "\r\n",
        "def hypothesis_1_sampler(data_loader, min_samples):\r\n",
        "    '''\r\n",
        "    randomly samples data for hypothesis test 1\r\n",
        "    '''\r\n",
        "    ## init empty datasets \r\n",
        "    initial = [] \r\n",
        "    expanded = [] \r\n",
        "    for pair in tqdm(data_loader): \r\n",
        "        if pair[1] > 7: \r\n",
        "            expanded.append(pair) \r\n",
        "        else: \r\n",
        "            initial.append(pair) \r\n",
        "            pass \r\n",
        "        if len(expanded) > min_samples and len(initial) > min_samples: \r\n",
        "            return initial, expanded \r\n",
        "    return initial, expanded \r\n",
        "\r\n",
        "train_initial, train_expanded = hypothesis_1_sampler(train_loader, min_train_samples) \r\n",
        "test_initial, test_expanded = hypothesis_1_sampler(test_loader, min_test_samples) "
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": " 85%|████████▍ | 50798/60000 [00:11<00:02, 4297.69it/s]\n100%|██████████| 10000/10000 [00:02<00:00, 4071.36it/s]\n"
        }
      ],
      "execution_count": 8,
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "gather": {
          "logged": 1640536805841
        }
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Fitting on 0 through 7 "
      ],
      "metadata": {
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "## Get a fresh model \r\n",
        "hypothesis_1_model = OnlineNet( \r\n",
        "    layer_list = [ \r\n",
        "        OnlineDenseLayer(p=1*1*28*28, q=100, activation=leaky_relu, activation_inverse=inv_leaky_relu, lam=lam, clip=clip), \r\n",
        "        OnlineDenseLayer(p=100, q=100, activation=leaky_relu, activation_inverse=inv_leaky_relu, lam=lam, clip=clip), \r\n",
        "        OnlineDenseLayer(p=100, q=100, activation=leaky_relu, activation_inverse=inv_leaky_relu, lam=lam, clip=clip), \r\n",
        "        OnlineDenseLayer(p=100, q=n_labels, activation=torch.sigmoid, activation_inverse=inv_sigmoid, lam=lam, clip=clip) \r\n",
        "    ], \r\n",
        "    reregularization_frequency = reregularization_frequency, \r\n",
        "    dlamdn = dlamdn \r\n",
        ") \r\n",
        "\r\n",
        "print('fit on 0-7') \r\n",
        "_, _, _, acc_train_initial = run(train_initial, fit=True, max_iters=10000, model=hypothesis_1_model) "
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": "acc: 0.66772, err: 4.67209, y_std: 0.02354, stab: 1.00034:  25%|██▍       | 10000/40798 [01:18<04:02, 126.88it/s]\n"
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": "fit on 0-7\n"
        }
      ],
      "execution_count": 18,
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "gather": {
          "logged": 1640537599696
        }
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### test on 0 through 7 before transfer learning "
      ],
      "metadata": {
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "print('test on 0-7 before transfer learning') \r\n",
        "_, _, _, acc_test_initial_before = run(test_initial, fit=False, max_iters=10000, model=hypothesis_1_model) "
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": "acc: 0.68942, err: 4.20784, y_std: 0.09580, stab: 1.00000: 100%|██████████| 8017/8017 [00:23<00:00, 345.51it/s]\n"
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": "test on 0-7 before transfer learning\n"
        }
      ],
      "execution_count": 19,
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "gather": {
          "logged": 1640537641597
        }
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### fit on 8 and 9 "
      ],
      "metadata": {
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "print('fit on 8-9') \r\n",
        "hypothesis_1_model_copy = hypothesis_1_model.copy() \r\n",
        "hypothesis_1_model_copy.dlamdn = 10.\r\n",
        "_, _, _, acc_train_expanded = run(train_expanded, fit=True, max_iters=3000, model=hypothesis_1_model_copy) "
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": "acc: 0.00156, err: 5.77426, y_std: 0.00709, stab: 1.00038:  30%|██▉       | 3000/10001 [00:21<00:49, 140.46it/s] \n"
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": "fit on 8-9\n"
        }
      ],
      "execution_count": 22,
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "gather": {
          "logged": 1640537743759
        }
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### test on 0 through 7 after transfer learning"
      ],
      "metadata": {
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "print('test on 0-7 after transfer learning') \r\n",
        "_, _, _, acc_train_initial_after = run(test_initial, fit=False, max_iters=10000, model=hypothesis_1_model_copy) "
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": "acc: 0.63295, err: 4.23241, y_std: 0.09413, stab: 1.00000: 100%|██████████| 8017/8017 [00:21<00:00, 376.95it/s]\n"
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": "test on 0-7 after transfer learning\n"
        }
      ],
      "execution_count": 12,
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "gather": {
          "logged": 1640536947904
        }
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### test on 8 and 9 after transfer learning "
      ],
      "metadata": {
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "print('test on 8-9 after transfer learning') \r\n",
        "_, _, _, acc_test_expanded = run(test_expanded, fit=False, max_iters=10000, model=hypothesis_1_model_copy) "
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": "acc: 0.25017, err: 4.65969, y_std: 0.04816, stab: 1.00000: 100%|██████████| 1983/1983 [00:05<00:00, 378.06it/s]\n"
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": "test on 8-9 after transfer learning\n"
        }
      ],
      "execution_count": 13,
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "gather": {
          "logged": 1640536953160
        }
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# scratch space\r\n",
        "\r\n",
        "ideas\r\n",
        "- to improve accuracies:\r\n",
        "  - larger models, likely needs GPUs \r\n",
        "  - hyperparamter tuning: try different paths for $\\frac{\\partial \\lambda}{\\partial n}(n)$\r\n",
        "- to explore strength of transfer learning result\r\n",
        "  - compare against a good competing method \r\n",
        "  - ... $\\leftarrow$ really need more here"
      ],
      "metadata": {
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "## trying to improve accuracy: using a dense net architecture found online \r\n",
        "## this is turning-out to be difficult... \r\n",
        "\r\n",
        "lam = 100. \r\n",
        "dlamdn = 10. \r\n",
        "reregularization_frequency = 1000 \r\n",
        "clip = 100. \r\n",
        "\r\n",
        "model_3 = OnlineNet( \r\n",
        "    layer_list = [ \r\n",
        "        OnlineDenseLayer(p=1*1*28*28, q=512, activation=leaky_relu, activation_inverse=inv_leaky_relu, lam=lam, clip=clip), \r\n",
        "        OnlineDenseLayer(p=512, q=n_labels, activation=torch.sigmoid, activation_inverse=inv_sigmoid, lam=lam, clip=clip) \r\n",
        "    ], \r\n",
        "    reregularization_frequency = reregularization_frequency, \r\n",
        "    dlamdn = dlamdn \r\n",
        ") \r\n",
        "\r\n",
        "print('fit on train data') \r\n",
        "_, _, _, acc_3 = run(train_loader, fit=True, max_iters=10000, model=model_3)"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": "acc: 0.76777, err: 4.23754, y_std: 0.09292, stab: 1.00047:  17%|█▋        | 10000/60000 [02:02<10:13, 81.44it/s]\n"
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": "fit on train data\n"
        }
      ],
      "execution_count": 14,
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "gather": {
          "logged": 1640537075947
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model_3_1 = model_3.copy() \r\n",
        "model_3_1.dlamdn = 100000 \r\n",
        "\r\n",
        "_, _, _, acc_3_1 = run(train_loader, fit=True, max_iters=3000, model=model_3_1)"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": "acc: 0.13335, err: 5.78938, y_std: 0.10098, stab: 1.00166:   5%|▌         | 3000/60000 [00:36<11:39, 81.54it/s]\n"
        }
      ],
      "execution_count": 15,
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "gather": {
          "logged": 1640537112751
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "## inspect \r\n",
        "p = train_initial[0]\r\n",
        "x, y = build_data(p[0], p[1]) \r\n",
        "y_hat = model_3_1(x) \r\n",
        "torch.cat((y, y_hat), dim=1) "
      ],
      "outputs": [
        {
          "output_type": "execute_result",
          "execution_count": 16,
          "data": {
            "text/plain": "tensor([[0.0500, 0.7424],\n        [0.0500, 0.8904],\n        [0.0500, 0.8776],\n        [0.0500, 0.8693],\n        [0.0500, 0.7748],\n        [0.9500, 0.7470],\n        [0.0500, 0.8215],\n        [0.0500, 0.8227],\n        [0.0500, 0.7933],\n        [0.0500, 0.7836]])"
          },
          "metadata": {}
        }
      ],
      "execution_count": 16,
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "gather": {
          "logged": 1640537112848
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "## hypothesis 2: transfer learning is robust \r\n",
        "## fit on 8-9, then 0-7 \r\n",
        "\r\n",
        "lam = 100. \r\n",
        "dlamdn = 10. \r\n",
        "reregularization_frequency = 1000 \r\n",
        "clip = 100. \r\n",
        "\r\n",
        "model_4 = OnlineNet( \r\n",
        "    layer_list = [ \r\n",
        "        OnlineDenseLayer(p=1*1*28*28, q=100, activation=leaky_relu, activation_inverse=inv_leaky_relu, lam=lam, clip=clip), \r\n",
        "        OnlineDenseLayer(p=100, q=100, activation=leaky_relu, activation_inverse=inv_leaky_relu, lam=lam, clip=clip), \r\n",
        "        OnlineDenseLayer(p=100, q=100, activation=leaky_relu, activation_inverse=inv_leaky_relu, lam=lam, clip=clip), \r\n",
        "        OnlineDenseLayer(p=100, q=n_labels, activation=torch.sigmoid, activation_inverse=inv_sigmoid, lam=lam, clip=clip) \r\n",
        "    ], \r\n",
        "    reregularization_frequency = reregularization_frequency, \r\n",
        "    dlamdn = dlamdn \r\n",
        ") \r\n",
        "\r\n",
        "print('fit on 8-9') \r\n",
        "_, _, _, _ = run(train_expanded, fit=True, max_iters=10000, model=model_4) \r\n",
        "\r\n",
        "print('test on 8-9') \r\n",
        "_, _, _, _ = run(test_expanded, fit=False, max_iters=10000, model=model_4) \r\n",
        "\r\n",
        "print('fit on 0-7') \r\n",
        "_, _, _, _ = run(train_initial, fit=True, max_iters=10000, model=model_4) \r\n",
        "\r\n",
        "print('test on 0-7') \r\n",
        "_, _, _, _ = run(test_initial, fit=False, max_iters=10000, model=model_4) \r\n",
        "\r\n",
        "print('test on 8-9') \r\n",
        "_, _, _, _ = run(test_expanded, fit=False, max_iters=10000, model=model_4) "
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": "acc: 0.80397, err: 4.42073, y_std: 0.06614, stab: 1.00017: 100%|█████████▉| 10000/10001 [01:15<00:00, 132.63it/s]\nacc: 0.76474, err: 4.31255, y_std: 0.07799, stab: 1.00000: 100%|██████████| 1983/1983 [00:05<00:00, 372.93it/s]\nacc: 0.00920, err: 4.74959, y_std: 0.01047, stab: 1.00009:  25%|██▍       | 10000/40798 [01:15<03:52, 132.25it/s]\nacc: 0.01686, err: 4.69201, y_std: 0.03374, stab: 1.00000: 100%|██████████| 8017/8017 [00:21<00:00, 378.41it/s]\nacc: 0.25299, err: 4.63899, y_std: 0.03366, stab: 1.00000: 100%|██████████| 1983/1983 [00:05<00:00, 362.08it/s]\n"
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": "fit on 8-9\ntest on 8-9\nfit on 0-7\ntest on 0-7\ntest on 8-9\n"
        }
      ],
      "execution_count": 17,
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "gather": {
          "logged": 1640537295830
        }
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Conclusion\r\n",
        "\r\n",
        "We've observed that online nets do indeed retain their accuracy on old data after being updated with new data. \r\n",
        "So, we have a potential resolution to catastrophic forgetting. \r\n",
        "However, it's unclear how to best fit these models, so accuracies remain low. \r\n",
        "Also, it's not entirely clear how this method competes with existing \r\n",
        "Thus, to make a strong argument, our next steps should involve\r\n",
        "- getting these accuracies up, proving these models are worthwhile in application;\r\n",
        "- and comparing these models against competing resolutions to catastrophic forgetting.\r\n",
        "\r\n",
        "So, we have a good lead and it should be pursued. \r\n",
        "It is important because resolving catastrophic forgetting has at least these following implications.\r\n",
        "- Model distribution becomes more useful. Currently, a distributed model has narrow scope of application and cannot be expanded into new applications. Online nets may resolve this.\r\n",
        "- Artificial general intelligence (AGI) has made important improvements via solving video games. However, reality has a smaller dataset. Better transfer learning may mean AGI can be bootstrapped into reality.\r\n"
      ],
      "metadata": {
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      }
    }
  ],
  "metadata": {
    "kernelspec": {
      "name": "python3-azureml",
      "language": "python",
      "display_name": "Python 3.6 - AzureML"
    },
    "language_info": {
      "name": "python",
      "version": "3.6.9",
      "mimetype": "text/x-python",
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "pygments_lexer": "ipython3",
      "nbconvert_exporter": "python",
      "file_extension": ".py"
    },
    "kernel_info": {
      "name": "python3-azureml"
    },
    "nteract": {
      "version": "nteract-front-end@1.0.0"
    },
    "microsoft": {
      "host": {
        "AzureML": {
          "notebookHasBeenCompleted": true
        }
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 2
}