{
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# online nets\r\n",
        "\r\n",
        "Deep learning is powerful but computationally expensive, frequently requiring massive compute budgets. In persuit of cost-effective-yet-powerful AI, this work explores and evaluates a heuristic which should lend to more-efficient use of data through online learning.\r\n",
        "\r\n",
        "Goal: evaluate a deep learning alternative capable of true online learning. Solution requirements:\r\n",
        "\r\n",
        "1. catastrophic forgetting should be impossible;\r\n",
        "2. all data is integrated into sufficient statistics of fixed dimension;\r\n",
        "3. and our solution should have predictive power comparable to deep learning.\r\n",
        "\r\n",
        "## modeling strategy\r\n",
        "\r\n",
        "We will not attempt to derive sufficient statistics for an entire deep net, but instead leverage well-known sufficient statistics for least squares models, \r\n",
        "so will have sufficient statistics per deep net layer. If this can be empirically shown effective, we'll build-out the theory afterwards. \r\n"
      ],
      "metadata": {
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# model code definitions"
      ],
      "metadata": {
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "\n",
        "TORCH_TENSOR_TYPE = type(torch.tensor(1)) \n",
        "\n",
        "class OnlineDenseLayer:\n",
        "    '''\n",
        "    A single dense net, formulated as a least squares model. \n",
        "    '''\n",
        "    def __init__(self, p, q, activation=lambda x:x, activation_inverse=lambda x:x, lam=1.): \n",
        "        '''\n",
        "        inputs:\n",
        "        - p: input dimension\n",
        "        - q: output dimension\n",
        "        - activation: non-linear function, from R^p to R^q. Default is identity\n",
        "        - activation_inverse: inverse of the activation function. Default is identity. \n",
        "        - lam: regularization term \n",
        "        '''\n",
        "        self.__validate_inputs(p=p, q=q, lam=lam) \n",
        "        self.p = p\n",
        "        self.q = q\n",
        "        self.activation = activation \n",
        "        self.activation_inverse = activation_inverse \n",
        "        self.lam = lam \n",
        "        self.xTy = torch.zeros(p+1,q) # +1 for intercept \n",
        "        self.yTx = torch.zeros(q+1,p) \n",
        "        self.xTx_inv = torch.diag(torch.tensor([lam]*(p+1))) \n",
        "        self.yTy_inv = torch.diag(torch.tensor([lam]*(q+1))) \n",
        "        self.betaT_forward = torch.matmul(self.xTx_inv, self.xTy) \n",
        "        self.betaT_forward = torch.transpose(self.betaT_forward, 0, 1) \n",
        "        self.betaT_backward = torch.matmul(self.yTy_inv, self.yTx) \n",
        "        self.betaT_backward = torch.transpose(self.betaT_backward, 0, 1) \n",
        "        self.x_forward = None \n",
        "        self.y_forward = None \n",
        "        self.x_backward = None \n",
        "        self.y_backward = None \n",
        "        pass \n",
        "    def forward(self, x): \n",
        "        'creates and stores x_forward and y_forward, then returns activation(y_forward)' \n",
        "        self.__validate_inputs(x=x, p=self.p) \n",
        "        self.x_forward = x \n",
        "        x = torch.cat((torch.tensor([[1.]]), x), dim=0) # intercept \n",
        "        self.y_forward = torch.matmul(self.betaT_forward, x) # predict \n",
        "        return self.activation(self.y_forward) \n",
        "    def backward(self, y): \n",
        "        'creates and stores x_backward and y_backward, then returns y_backward'\n",
        "        y = self.activation_inverse(y) \n",
        "        self.__validate_inputs(y=y, q=self.q)\n",
        "        self.y_backward = y \n",
        "        y = torch.cat((torch.tensor([[1.]]), y), dim=0) \n",
        "        self.x_backward = torch.matmul(self.betaT_backward, y) \n",
        "        return self.x_backward \n",
        "    def forward_fit(self): \n",
        "        'uses x_forward and y_backward to update forward model, then returns Sherman Morrison denominator' \n",
        "        self.__validate_inputs(x=self.x_forward, y=self.y_backward, p=self.p, q=self.q) \n",
        "        x = torch.cat((torch.tensor([[1.]]), self.x_forward), dim=0) \n",
        "        self.xTx_inv, sm_denom = self.__sherman_morrison(self.xTx_inv, x, x) \n",
        "        self.xTy += torch.matmul(x, torch.transpose(self.y_backward, 0, 1)) \n",
        "        self.betaT_forward = torch.matmul(self.xTx_inv, self.xTy) \n",
        "        self.betaT_forward = torch.transpose(self.betaT_forward, 0, 1) \n",
        "        return sm_denom \n",
        "    def backward_fit(self):\n",
        "        'uses x_backward and y_forward to update backward model, then returns Sherman Morrison denominator'\n",
        "        self.__validate_inputs(x=self.x_forward, y=self.y_backward, p=self.p, q=self.q) \n",
        "        y = torch.cat((torch.tensor([[1.]]), self.y_backward), dim=0)\n",
        "        self.yTy_inv, sm_denom = self.__sherman_morrison(self.yTy_inv, y, y) \n",
        "        self.yTx += torch.matmul(y, torch.transpose(self.x_backward, 0, 1)) \n",
        "        self.betaT_backward = torch.matmul(self.yTy_inv, self.yTx)\n",
        "        self.betaT_backward = torch.transpose(self.betaT_backward, 0, 1) \n",
        "        return sm_denom \n",
        "    def __sherman_morrison(self, inv_mat, vec1, vec2):\n",
        "        '''\n",
        "        applies Sherman Morrison updates, (mat + vec1 vec2^T)^{-1}\n",
        "        inputs:\n",
        "        - inv_mat: an inverted matrix \n",
        "        - vec1: a column vector \n",
        "        - vec2: a column vector \n",
        "        returns:\n",
        "        - updated matrix\n",
        "        - the Sherman Morrison denominator, for tracking numerical stability \n",
        "        '''\n",
        "        v2t = torch.transpose(vec2, 0, 1)\n",
        "        denominator = 1. + torch.matmul(torch.matmul(v2t, inv_mat), vec1) \n",
        "        numerator = torch.matmul(torch.matmul(inv_mat, vec1), torch.matmul(v2t, inv_mat)) \n",
        "        updated_inv_mat = inv_mat - numerator / denominator \n",
        "        return updated_inv_mat, float(denominator) \n",
        "    def __validate_inputs(self, p=None, q=None, lam=None, x=None, y=None): \n",
        "        'raises value exceptions if provided parameters are invalid'\n",
        "        if q is not None:\n",
        "            if not isinstance(q, int):\n",
        "                raise ValueError('`q` must be int!')\n",
        "            if q <= 0:\n",
        "                raise ValueError('`q` must be greater than zero!')\n",
        "        if p is not None:\n",
        "            if not isinstance(p, int): \n",
        "                raise ValueError('`p` must be int!')\n",
        "            if p <= 0: \n",
        "                raise ValueError('`p` must be greater than zero!')\n",
        "        if lam is not None:\n",
        "            if not (isinstance(lam, float) or isinstance(lam, int)):\n",
        "                raise ValueError('`lam` must be float or int!')\n",
        "            if lam < 0:\n",
        "                raise ValueError('`lam` must be non-negative!')\n",
        "        if x is not None and p is not None: \n",
        "            if type(x) != TORCH_TENSOR_TYPE:\n",
        "                raise ValueError('`x` must be of type `torch.tensor`!') \n",
        "            if list(x.shape) != [p,1]: \n",
        "                raise ValueError('`x.shape` must be `[p,1]`') \n",
        "            pass \n",
        "        if y is not None and q is not None: \n",
        "            if type(y) != TORCH_TENSOR_TYPE:\n",
        "                raise ValueError('`y` must be of type `torch.tensor`!') \n",
        "            if list(y.shape) != [q,1]: \n",
        "                raise ValueError('`y.shape` must be `[q,1]`') \n",
        "            pass \n",
        "        pass \n",
        "    pass\n",
        "\n",
        "class OnlineNet: \n",
        "    'online, sequential dense net' \n",
        "    def __init__(self, layer_list): \n",
        "        ## validate inputs \n",
        "        if type(layer_list) != list: \n",
        "            raise ValueError('`layer_list` must be of type list!') \n",
        "        for layer in layer_list: \n",
        "            if not issubclass(type(layer), OnlineDenseLayer):\n",
        "                raise ValueError('each item in `layer_list` must be an instance of a subclass of `OnlineDenseLayer`!') \n",
        "        ## assign \n",
        "        self.layer_list = layer_list \n",
        "        pass \n",
        "    def forward(self, x): \n",
        "        'predict forward'\n",
        "        for layer in self.layer_list:\n",
        "            x = layer.forward(x) \n",
        "        return x \n",
        "    def backward(self, y):\n",
        "        'predict backward'\n",
        "        for layer in reversed(self.layer_list): \n",
        "            y = layer.backward(y) \n",
        "        return y \n",
        "    def fit(self): \n",
        "        'assumes layers x & y targets have already been set. Returns Sherman Morrison denominators per layer in (forward, backward) pairs in a list'\n",
        "        sherman_morrison_denominator_list = [] \n",
        "        for layer in self.layer_list:\n",
        "            forward_smd = layer.forward_fit() \n",
        "            backward_smd = layer.backward_fit() \n",
        "            sherman_morrison_denominator_list.append((forward_smd, backward_smd))\n",
        "        return sherman_morrison_denominator_list \n",
        "    def __reduce_sherman_morrison_denominator_list(self, smd_pair_list):\n",
        "        'returns the value closest to zero'\n",
        "        if type(smd_pair_list) != list: \n",
        "            raise ValueError('`smd_pair_list` must be of type `list`!')\n",
        "        if len(smd_pair_list) == 0:\n",
        "            return None \n",
        "        smallest_smd = None \n",
        "        for smd_pair in smd_pair_list:\n",
        "            if type(smd_pair) != tuple:\n",
        "                raise ValueError('`smd_pair_list` must be list of tuples!')\n",
        "            if smallest_smd is None: \n",
        "                smallest_smd = smd_pair[0] \n",
        "            if abs(smallest_smd) > abs(smd_pair[0]): \n",
        "                smallest_smd = smd_pair[0] \n",
        "            if abs(smallest_smd) > abs(smd_pair[1]):\n",
        "                smallest_smd = smd_pair[1] \n",
        "        return float(smallest_smd) \n",
        "    def __call__(self, x, y=None): \n",
        "        '''\n",
        "        If only x is given, a prediction is made and returned.\n",
        "        If x and y are given, then the model is updated, and returns\n",
        "        - the prediction\n",
        "        - the sherman morrison denominator closest to zero, for tracking numerical stability\n",
        "        '''\n",
        "        y_hat = self.forward(x) \n",
        "        if y is None: \n",
        "            return y_hat \n",
        "        self.backward(y) \n",
        "        self.layer_list[0].x_forward = x \n",
        "        self.layer_list[0].x_backward = x \n",
        "        self.layer_list[-1].y_forward = y \n",
        "        self.layer_list[-1].y_backward = y \n",
        "        smd_pair_list = self.fit() \n",
        "        smallest_smd = self.__reduce_sherman_morrison_denominator_list(smd_pair_list) \n",
        "        return y_hat, smallest_smd "
      ],
      "outputs": [],
      "execution_count": 110,
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "gather": {
          "logged": 1637885755411
        }
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# first experiment: mnist classification"
      ],
      "metadata": {
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from tqdm import tqdm\r\n",
        "from torchvision import datasets, transforms\r\n",
        "\r\n",
        "transform=transforms.Compose([\r\n",
        "    transforms.ToTensor(),\r\n",
        "    transforms.Normalize((0.1307,), (0.3081,))\r\n",
        "    ])\r\n",
        "\r\n",
        "dataset1 = datasets.MNIST('../../data', train=True, download=True, transform=transform)\r\n",
        "dataset2 = datasets.MNIST('../../data', train=False, transform=transform)\r\n",
        "\r\n",
        "train_loader = torch.utils.data.DataLoader(dataset1)\r\n",
        "test_loader = torch.utils.data.DataLoader(dataset2)\r\n",
        "\r\n",
        "n_labels = 10 \r\n",
        "\r\n",
        "inv_sigmoid = lambda x: -torch.log((1/(x+1e-8))-1)\r\n",
        "\r\n",
        "model = OnlineNet(\r\n",
        "    [\r\n",
        "        OnlineDenseLayer(p=1*1*28*28, q=1000, activation=torch.sigmoid, activation_inverse=inv_sigmoid),  \r\n",
        "        OnlineDenseLayer(p=1000, q=5000, activation=torch.sigmoid, activation_inverse=inv_sigmoid), \r\n",
        "        OnlineDenseLayer(p=5000, q=100, activation=torch.sigmoid, activation_inverse=inv_sigmoid), \r\n",
        "        OnlineDenseLayer(p=100, q=n_labels, activation=torch.sigmoid, activation_inverse=inv_sigmoid)\r\n",
        "    ] \r\n",
        ")\r\n",
        "\r\n",
        "def build_data(image, label): \r\n",
        "    'format data from iterator for model' \r\n",
        "    y = torch.tensor([1. if int(label[0]) == idx else 0. for idx in range(n_labels)]) ## one-hot representation \r\n",
        "    x = image.reshape([-1]) ## flatten \r\n",
        "    ## shrink so sigmoid inverse is well-defined \r\n",
        "    y = y*.90 + .05 \r\n",
        "    ## reshape to column vectors \r\n",
        "    x = x.reshape([-1,1])\r\n",
        "    y = y.reshape([-1,1])\r\n",
        "    return x, y \r\n",
        "\r\n",
        "errors = [] \r\n",
        "lat_sums = [] \r\n",
        "pbar = tqdm(train_loader) \r\n",
        "for [image, label] in pbar: \r\n",
        "    x, y = build_data(image, label) \r\n",
        "    ## fit \r\n",
        "    y_hat, stability = model(x, y) \r\n",
        "    err = float((y - y_hat).abs().sum()) \r\n",
        "    pbar.set_description(f'err: {err}, stab: {stability}') \r\n",
        "    ## train error \r\n",
        "    ## TODO "
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": "err: 4.775514602661133, stab: 1.0003235340118408:   5%|â–Œ         | 3092/60000 [19:04<5:51:01,  2.70it/s] \n"
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-111-ea8c4dd98ef3>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     43\u001b[0m     \u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbuild_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimage\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabel\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     44\u001b[0m     \u001b[0;31m## fit\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 45\u001b[0;31m     \u001b[0my_hat\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstability\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     46\u001b[0m     \u001b[0merr\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfloat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0my_hat\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mabs\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msum\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     47\u001b[0m     \u001b[0mpbar\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mset_description\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf'err: {err}, stab: {stability}'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-110-069876059071>\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, x, y)\u001b[0m\n\u001b[1;32m    178\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlayer_list\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0my_forward\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    179\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlayer_list\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0my_backward\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 180\u001b[0;31m         \u001b[0msmd_pair_list\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    181\u001b[0m         \u001b[0msmallest_smd\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__reduce_sherman_morrison_denominator_list\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msmd_pair_list\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    182\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0my_hat\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msmallest_smd\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-110-069876059071>\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    143\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mlayer\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlayer_list\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    144\u001b[0m             \u001b[0mforward_smd\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlayer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward_fit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 145\u001b[0;31m             \u001b[0mbackward_smd\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlayer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward_fit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    146\u001b[0m             \u001b[0msherman_morrison_denominator_list\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mforward_smd\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbackward_smd\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    147\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0msherman_morrison_denominator_list\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-110-069876059071>\u001b[0m in \u001b[0;36mbackward_fit\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m     63\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__validate_inputs\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mx_forward\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0my_backward\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mp\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mp\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mq\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mq\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     64\u001b[0m         \u001b[0my\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1.\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0my_backward\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdim\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 65\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0myTy_inv\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msm_denom\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__sherman_morrison\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0myTy_inv\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     66\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0myTx\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmatmul\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtranspose\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mx_backward\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     67\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbetaT_backward\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmatmul\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0myTy_inv\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0myTx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-110-069876059071>\u001b[0m in \u001b[0;36m__sherman_morrison\u001b[0;34m(self, inv_mat, vec1, vec2)\u001b[0m\n\u001b[1;32m     81\u001b[0m         \u001b[0mv2t\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtranspose\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvec2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     82\u001b[0m         \u001b[0mdenominator\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m1.\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmatmul\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmatmul\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mv2t\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minv_mat\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvec1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 83\u001b[0;31m         \u001b[0mnumerator\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmatmul\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmatmul\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minv_mat\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvec1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmatmul\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mv2t\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minv_mat\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     84\u001b[0m         \u001b[0mupdated_inv_mat\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0minv_mat\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mnumerator\u001b[0m \u001b[0;34m/\u001b[0m \u001b[0mdenominator\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     85\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mupdated_inv_mat\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfloat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdenominator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ],
      "execution_count": 111,
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## scratch space\r\n",
        "\r\n",
        "$x_1, X_2, X_3, \\ldots, X_{p-1}, x_p = y$\r\n",
        "\r\n",
        "$\\beta_1^F, \\beta_1^B, \\beta_2^F, \\beta_2^B, \\ldots, \\beta_{p-1}^F, \\beta_{p-1}^B$\r\n",
        "\r\n",
        "$\\hat x_{j+1} = \\sigma \\left( \\beta_j^{FT} x_j \\right)$\r\n",
        "\r\n",
        "forward series: $x_1, \\hat x_2, \\hat x_3, \\ldots, \\hat x_{p-1}, x_p = y$\r\n",
        "\r\n",
        "$ \\hat \\beta_{p-1}^{FT} = \\text{argmin}_\\beta \\| x_p - \\beta^{T} \\hat x_{p-1} \\|^2 $\r\n",
        "\r\n",
        "$ \\hat \\beta_{p-2}^{FT} = \\text{argmin}_\\beta \\| \\hat x_{p-1} - \\beta^{T} \\hat x_{p-2} \\|^2 $ We won't do this. \r\n",
        "\r\n",
        "$ \\tilde x_{j-1} = \\sigma^{-1}\\left( \\beta_j^{BT} x_j \\right)$\r\n",
        "\r\n",
        "backward series: $x_1, \\tilde x_2, \\tilde x_3, \\ldots, \\tilde x_{p-1}, x_p = y$\r\n",
        "\r\n",
        "$ \\hat \\beta_{p-2}^{F} = \\text{argmin}_\\beta \\| \\tilde x_{p-1} - \\beta^{T} \\hat x_{p-2} \\|^2 $\r\n",
        "\r\n",
        "$ \\hat \\beta_{p-2}^{B} = \\text{argmin}_\\beta \\| \\hat x_{p-2} - \\beta^{T} \\tilde x_{p-1} \\|^2 $"
      ],
      "metadata": {
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "$ \\hat x_3 = \\sigma \\left( \\beta_2^{FT} \\hat x_2 \\right) $\r\n",
        "\r\n",
        "$ \\hat \\beta_2^F = \\text{argmin}_\\beta \\| \\sigma^{-1}\\left( \\hat x_3 \\right) - \\beta^T \\hat x_2 \\|^2 $ Useless without $\\tilde x$\r\n",
        "\r\n",
        "$ \\tilde x_2 = \\sigma^{-1}\\left( \\beta_3^{BT} \\tilde x_3 \\right) $\r\n",
        "\r\n",
        "$ \\hat \\beta_2^B = \\text{argmin}_\\beta \\| \\sigma\\left( \\hat x_2 \\right) - \\beta^T \\hat x_3 \\|^2 $ Useless without $\\hat x$\r\n",
        "\r\n",
        "So, use these estimates instead.\r\n",
        "\r\n",
        "$ \\hat \\beta_2^F = \\text{argmin}_\\beta \\| \\sigma^{-1}\\left( \\tilde x_3 \\right) - \\beta^T \\hat x_2 \\|^2 $\r\n",
        "\r\n",
        "$ \\hat \\beta_2^B = \\text{argmin}_\\beta \\| \\sigma\\left( \\hat x_2 \\right) - \\beta^T \\tilde x_3 \\|^2 $"
      ],
      "metadata": {
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "$\\pi$"
      ],
      "metadata": {
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      }
    }
  ],
  "metadata": {
    "kernelspec": {
      "name": "python3-azureml",
      "language": "python",
      "display_name": "Python 3.6 - AzureML"
    },
    "language_info": {
      "name": "python",
      "version": "3.6.9",
      "mimetype": "text/x-python",
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "pygments_lexer": "ipython3",
      "nbconvert_exporter": "python",
      "file_extension": ".py"
    },
    "kernel_info": {
      "name": "python3-azureml"
    },
    "nteract": {
      "version": "nteract-front-end@1.0.0"
    },
    "microsoft": {
      "host": {
        "AzureML": {
          "notebookHasBeenCompleted": true
        }
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 2
}