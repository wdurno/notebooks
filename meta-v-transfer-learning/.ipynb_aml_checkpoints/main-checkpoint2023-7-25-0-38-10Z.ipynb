{
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# Transfer learning compared to meta learning \n",
        "\n",
        "Meta learning prepares a model to interpolate generally over a submanifold in the parameter space, \n",
        "but the submanifold dimension is practically small relative the parameter space dimension, \n",
        "because each one must be engineered. \n",
        "Alternatively, transfer learning effectively contributes significant samples sizes to some dimensions \n",
        "and usually arrives with a little bias. \n",
        "Here, we show (HYPOTHESIZE) that meta learning is competitive near its submanifold, \n",
        "but sufficiently-abstracted transfer learning ultimately produces greater generality beyond the submanifold, \n",
        "at least when bias is sufficiently low. \n",
        "Ultimately, it's a trade-off between meta learning's effective submanifold, \n",
        "and the relevance of a data abstraction produced by transfer learning. \n",
        "If the abstraction is coherent and small, it should be more general. \n",
        "When done correctly, packing greater volumes of data into smaller dimensional spaces lends to greater generality."
      ],
      "metadata": {
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torch.nn as nn \n",
        "\n",
        "MNIST_DIM = 28 \n",
        "LEARNING_RATE = 1e-3 \n",
        "EMBEDDING_DIM = 20 \n",
        "\n",
        "class BaseLayer(nn.Module): \n",
        "    def __init__(self,\n",
        "            abstraction_dimension=20):\n",
        "        self.abstraction_dimension = abstraction_dimension \n",
        "        self.fc1 = nn.Linear(MNIST_DIM*MNIST_DIM, self.abstraction_dimension) \n",
        "        self.relu1 = nn.LeakyReLU() \n",
        "        self.fc2 = nn.Linear(self.abstraction_dimension, EMBEDDING_DIM) \n",
        "        pass \n",
        "    def forward(self, \n",
        "            x): \n",
        "        x = self.fc1(x) \n",
        "        x = self.relu1(x) \n",
        "        x = self.fc2(x) \n",
        "        return x \n",
        "    pass \n",
        "\n",
        "class AutoEncoder(nn.Module): \n",
        "    def __init__(self,\n",
        "            abstraction_dimension=20): \n",
        "        self.abstraction_dimension = abstraction_dimension \n",
        "        self.base_layer = BaseLayer(abstraction_dimension=self.abstraction_dimension) \n",
        "        self.relu1 = nn.LeakyReLU()\n",
        "        self.fc1 = nn.Linear(EMBEDDING_DIM, self.abstraction_dimension) \n",
        "        self.relu2 = nn.LeakyReLU() \n",
        "        self.fc2 = nn.Linear(self.abstraction_dimension, MNIST_DIM*MNIST_DIM) \n",
        "        self.optimizer = torch.optim.Adam(self.parameters(), lr=LEARNING_RATE) \n",
        "        pass \n",
        "        def forward(self,\n",
        "                x):\n",
        "            x = self.base_layer(x) \n",
        "            x = self.relu1(x) \n",
        "            x = self.fc1(x) \n",
        "            x = self.relu2(x) \n",
        "            x = self.fc2(x) \n",
        "            x = torch.sigmoid(x) \n",
        "            return x \n",
        "    pass \n",
        "\n",
        "    class Classifier(nn.Module): \n",
        "        def __init__(self,\n",
        "                abstraction_dimension=20, \n",
        "                base_layer_transfer=None, \n",
        "                n_labels=10): \n",
        "            self.abstraction_dimension = abstraction_dimension \n",
        "            self.n_labels=10 \n",
        "            self.base_layer = BaseLayer(abstraction_dimension=self.abstraction_dimension) \n",
        "            self.relu1 = nn.LeakyReLU() \n",
        "            self.fc1 = nn.Linear(EMBEDDING_DIM, self.n_labels) \n",
        "            if base_layer_transfer is not None: \n",
        "                ## TODO copy params \n",
        "                pass \n",
        "            pass \n",
        "        def forward(self, \n",
        "                x): \n",
        "            x = self.base_layer(x) \n",
        "            x = self.relu1(x) \n",
        "            x = self.fc1(x) \n",
        "            x = torch.softmax(x) \n",
        "            return x \n",
        "        pass \n",
        "\n",
        "## TODO experimental cases: \n",
        "## Meta learning: fit model to linear interpolations of {0,1,2,3,4,5,6,7,8} making a 9-dim sub-manifold. \n",
        "## Illustrate effectiveness on fake, new, within-submanifold digits like p*2 + (1-p)*5 but ineffectiveness with 9. \n",
        "## Transfer learning: show how optimal abstraction dim on {0,1,2,3,4,5,6,7,8} results in greater effectiveness with 9. "
      ],
      "outputs": [],
      "execution_count": 4,
      "metadata": {
        "gather": {
          "logged": 1692676694077
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from torchvision import datasets\n",
        "\n",
        "dataset1 = datasets.MNIST('../../data', train=True, download=True) \n",
        "dataset2 = datasets.MNIST('../../data', train=False) \n",
        "\n",
        "image, label = dataset1[0]\n",
        "\n",
        "print(type(image)) \n",
        "print(image.shape) \n",
        "print(type(label))\n",
        "print(label)\n",
        "\n",
        "image"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": "<class 'PIL.Image.Image'>\n"
        },
        {
          "output_type": "error",
          "ename": "AttributeError",
          "evalue": "shape",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
            "Cell \u001b[0;32mIn [12], line 9\u001b[0m\n\u001b[1;32m      6\u001b[0m image, label \u001b[38;5;241m=\u001b[39m dataset1[\u001b[38;5;241m0\u001b[39m]\n\u001b[1;32m      8\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;28mtype\u001b[39m(image)) \n\u001b[0;32m----> 9\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[43mimage\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mshape\u001b[49m) \n\u001b[1;32m     10\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;28mtype\u001b[39m(label))\n\u001b[1;32m     11\u001b[0m \u001b[38;5;28mprint\u001b[39m(label)\n",
            "File \u001b[0;32m/anaconda/envs/azureml_py38/lib/python3.8/site-packages/PIL/Image.py:517\u001b[0m, in \u001b[0;36mImage.__getattr__\u001b[0;34m(self, name)\u001b[0m\n\u001b[1;32m    515\u001b[0m     deprecate(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mImage categories\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;241m10\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mis_animated\u001b[39m\u001b[38;5;124m\"\u001b[39m, plural\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[1;32m    516\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_category\n\u001b[0;32m--> 517\u001b[0m \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mAttributeError\u001b[39;00m(name)\n",
            "\u001b[0;31mAttributeError\u001b[0m: shape"
          ]
        }
      ],
      "execution_count": 12,
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "gather": {
          "logged": 1692677827738
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from torch.nn.functional import one_hot \n",
        "\n",
        "one_hot(torch.tensor([3,4]), num_classes=10)"
      ],
      "outputs": [
        {
          "output_type": "execute_result",
          "execution_count": 20,
          "data": {
            "text/plain": "tensor([[0, 0, 0, 1, 0, 0, 0, 0, 0, 0],\n        [0, 0, 0, 0, 1, 0, 0, 0, 0, 0]])"
          },
          "metadata": {}
        }
      ],
      "execution_count": 20,
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "gather": {
          "logged": 1692678235307
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from torchvision.transforms.functional import pil_to_tensor \n",
        "\n",
        "pil_to_tensor(image)/256. "
      ],
      "outputs": [
        {
          "output_type": "execute_result",
          "execution_count": 17,
          "data": {
            "text/plain": "tensor([[[0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n          0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n          0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n          0.0000, 0.0000, 0.0000, 0.0000],\n         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n          0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n          0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n          0.0000, 0.0000, 0.0000, 0.0000],\n         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n          0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n          0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n          0.0000, 0.0000, 0.0000, 0.0000],\n         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n          0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n          0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n          0.0000, 0.0000, 0.0000, 0.0000],\n         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n          0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n          0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n          0.0000, 0.0000, 0.0000, 0.0000],\n         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n          0.0000, 0.0000, 0.0000, 0.0000, 0.0117, 0.0703, 0.0703, 0.0703,\n          0.4922, 0.5312, 0.6836, 0.1016, 0.6484, 0.9961, 0.9648, 0.4961,\n          0.0000, 0.0000, 0.0000, 0.0000],\n         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n          0.1172, 0.1406, 0.3672, 0.6016, 0.6641, 0.9883, 0.9883, 0.9883,\n          0.9883, 0.9883, 0.8789, 0.6719, 0.9883, 0.9453, 0.7617, 0.2500,\n          0.0000, 0.0000, 0.0000, 0.0000],\n         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.1914,\n          0.9297, 0.9883, 0.9883, 0.9883, 0.9883, 0.9883, 0.9883, 0.9883,\n          0.9883, 0.9805, 0.3633, 0.3203, 0.3203, 0.2188, 0.1523, 0.0000,\n          0.0000, 0.0000, 0.0000, 0.0000],\n         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0703,\n          0.8555, 0.9883, 0.9883, 0.9883, 0.9883, 0.9883, 0.7734, 0.7109,\n          0.9648, 0.9414, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n          0.0000, 0.0000, 0.0000, 0.0000],\n         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n          0.3125, 0.6094, 0.4180, 0.9883, 0.9883, 0.8008, 0.0430, 0.0000,\n          0.1680, 0.6016, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n          0.0000, 0.0000, 0.0000, 0.0000],\n         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n          0.0000, 0.0547, 0.0039, 0.6016, 0.9883, 0.3516, 0.0000, 0.0000,\n          0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n          0.0000, 0.0000, 0.0000, 0.0000],\n         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n          0.0000, 0.0000, 0.0000, 0.5430, 0.9883, 0.7422, 0.0078, 0.0000,\n          0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n          0.0000, 0.0000, 0.0000, 0.0000],\n         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n          0.0000, 0.0000, 0.0000, 0.0430, 0.7422, 0.9883, 0.2734, 0.0000,\n          0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n          0.0000, 0.0000, 0.0000, 0.0000],\n         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n          0.0000, 0.0000, 0.0000, 0.0000, 0.1367, 0.9414, 0.8789, 0.6250,\n          0.4219, 0.0039, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n          0.0000, 0.0000, 0.0000, 0.0000],\n         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n          0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.3164, 0.9375, 0.9883,\n          0.9883, 0.4648, 0.0977, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n          0.0000, 0.0000, 0.0000, 0.0000],\n         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n          0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.1758, 0.7266,\n          0.9883, 0.9883, 0.5859, 0.1055, 0.0000, 0.0000, 0.0000, 0.0000,\n          0.0000, 0.0000, 0.0000, 0.0000],\n         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n          0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0625,\n          0.3633, 0.9844, 0.9883, 0.7305, 0.0000, 0.0000, 0.0000, 0.0000,\n          0.0000, 0.0000, 0.0000, 0.0000],\n         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n          0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n          0.0000, 0.9727, 0.9883, 0.9727, 0.2500, 0.0000, 0.0000, 0.0000,\n          0.0000, 0.0000, 0.0000, 0.0000],\n         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n          0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.1797, 0.5078,\n          0.7148, 0.9883, 0.9883, 0.8086, 0.0078, 0.0000, 0.0000, 0.0000,\n          0.0000, 0.0000, 0.0000, 0.0000],\n         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n          0.0000, 0.0000, 0.0000, 0.0000, 0.1523, 0.5781, 0.8945, 0.9883,\n          0.9883, 0.9883, 0.9766, 0.7109, 0.0000, 0.0000, 0.0000, 0.0000,\n          0.0000, 0.0000, 0.0000, 0.0000],\n         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n          0.0000, 0.0000, 0.0938, 0.4453, 0.8633, 0.9883, 0.9883, 0.9883,\n          0.9883, 0.7852, 0.3047, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n          0.0000, 0.0000, 0.0000, 0.0000],\n         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n          0.0898, 0.2578, 0.8320, 0.9883, 0.9883, 0.9883, 0.9883, 0.7734,\n          0.3164, 0.0078, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n          0.0000, 0.0000, 0.0000, 0.0000],\n         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0703, 0.6680,\n          0.8555, 0.9883, 0.9883, 0.9883, 0.9883, 0.7617, 0.3125, 0.0352,\n          0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n          0.0000, 0.0000, 0.0000, 0.0000],\n         [0.0000, 0.0000, 0.0000, 0.0000, 0.2148, 0.6719, 0.8828, 0.9883,\n          0.9883, 0.9883, 0.9883, 0.9531, 0.5195, 0.0430, 0.0000, 0.0000,\n          0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n          0.0000, 0.0000, 0.0000, 0.0000],\n         [0.0000, 0.0000, 0.0000, 0.0000, 0.5312, 0.9883, 0.9883, 0.9883,\n          0.8281, 0.5273, 0.5156, 0.0625, 0.0000, 0.0000, 0.0000, 0.0000,\n          0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n          0.0000, 0.0000, 0.0000, 0.0000],\n         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n          0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n          0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n          0.0000, 0.0000, 0.0000, 0.0000],\n         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n          0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n          0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n          0.0000, 0.0000, 0.0000, 0.0000],\n         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n          0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n          0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n          0.0000, 0.0000, 0.0000, 0.0000]]])"
          },
          "metadata": {}
        }
      ],
      "execution_count": 17,
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "gather": {
          "logged": 1692678016073
        }
      }
    }
  ],
  "metadata": {
    "kernelspec": {
      "name": "python310-sdkv2",
      "language": "python",
      "display_name": "Python 3.10 - SDK V2"
    },
    "language_info": {
      "name": "python",
      "version": "3.8.5",
      "mimetype": "text/x-python",
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "pygments_lexer": "ipython3",
      "nbconvert_exporter": "python",
      "file_extension": ".py"
    },
    "microsoft": {
      "ms_spell_check": {
        "ms_spell_check_language": "en"
      },
      "host": {
        "AzureML": {
          "notebookHasBeenCompleted": true
        }
      }
    },
    "kernel_info": {
      "name": "python310-sdkv2"
    },
    "nteract": {
      "version": "nteract-front-end@1.0.0"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 2
}