{
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "## Google's Generative AI search provided the initial draft of this code. \n",
        "## I have modified it since. \n",
        "## It provided these sources: \n",
        "## https://github.com/jk96491/RL_Algorithms?tab=readme-ov-file \n",
        "## https://github.com/abyaadrafid/Deep-Reinforcement-Learning \n",
        "## I couldn't find a draft of this code in the sources, \n",
        "## so Generative AI search may have generated the code. \n",
        "\n",
        "import gym\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim \n",
        "\n",
        "class ReplayBuffer(): \n",
        "    def __init__(self, capacity=10000): \n",
        "        self.n = 0 \n",
        "        self.capacity = capacity \n",
        "        self.state_list = [] \n",
        "        self.action_list = [] \n",
        "        self.reward_list = [] \n",
        "        self.next_state_list = [] \n",
        "        self.done_list = [] \n",
        "        pass \n",
        "    def add(self, state, action, reward, next_state, done): \n",
        "        if self.n >= self.capacity: \n",
        "            ## discard earliest observation \n",
        "            self.state_list = self.state_list[1:] \n",
        "            self.action_list = self.action_list[1:] \n",
        "            self.reward_list = self.reward_list[1:] \n",
        "            self.next_state_list = self.next_state_list[1:] \n",
        "            self.done_list = self.done_list[1:] \n",
        "            self.n -= 1 \n",
        "        pass \n",
        "        ## cast to torch  \n",
        "        state = torch.tensor(state) \n",
        "        action = torch.tensor(action) \n",
        "        reward = torch.tensor(reward) \n",
        "        next_state = torch.tensor(next_state) \n",
        "        done = torch.tensor(done) \n",
        "        ## append to buffer \n",
        "        self.state_list.append(state) \n",
        "        self.action_list.append(action) \n",
        "        self.reward_list.append(reward) \n",
        "        self.next_state_list.append(next_state) \n",
        "        self.done_list.append(done) \n",
        "        self.n += 1 \n",
        "        pass \n",
        "    def sample(self, batch_size=32): \n",
        "        # \n",
        "        pass \n",
        "    pass \n",
        "\n",
        "# Define the actor and critic networks\n",
        "class Actor(nn.Module):\n",
        "    def __init__(self, state_dim, action_dim):\n",
        "        super(Actor, self).__init__()\n",
        "\n",
        "        self.fc1 = nn.Linear(state_dim, 256)\n",
        "        self.fc2 = nn.Linear(256, 128)\n",
        "        self.fc3 = nn.Linear(128, action_dim)\n",
        "\n",
        "    def forward(self, state):\n",
        "        x = torch.relu(self.fc1(state))\n",
        "        x = torch.relu(self.fc2(x))\n",
        "        action = torch.tanh(self.fc3(x))\n",
        "\n",
        "        return action\n",
        "\n",
        "class Critic(nn.Module):\n",
        "    def __init__(self, state_dim, action_dim):\n",
        "        super(Critic, self).__init__()\n",
        "\n",
        "        self.fc1 = nn.Linear(state_dim + action_dim, 256)\n",
        "        self.fc2 = nn.Linear(256, 128)\n",
        "        self.fc3 = nn.Linear(128, 1)\n",
        "\n",
        "    def forward(self, state, action):\n",
        "        x = torch.cat([state, action], dim=1)\n",
        "        x = torch.relu(self.fc1(x))\n",
        "        x = torch.relu(self.fc2(x))\n",
        "        value = self.fc3(x)\n",
        "\n",
        "        return value\n",
        "\n",
        "# Create the actor and critic networks\n",
        "actor = Actor(state_dim=4, action_dim=1)\n",
        "critic = Critic(state_dim=4, action_dim=1)\n",
        "\n",
        "# Define the optimizers\n",
        "actor_optimizer = optim.Adam(actor.parameters(), lr=1e-3)\n",
        "critic_optimizer = optim.Adam(critic.parameters(), lr=1e-3)\n",
        "\n",
        "# Create the replay buffer\n",
        "replay_buffer = ReplayBuffer(capacity=100000) \n",
        "\n",
        "# Define the environment\n",
        "env = gym.make('CartPole-v1')\n",
        "\n",
        "# Train the agent\n",
        "for episode in range(1000):\n",
        "    state = env.reset()\n",
        "\n",
        "    for t in range(1000):\n",
        "        action = actor(state)\n",
        "\n",
        "        next_state, reward, done, _ = env.step(action)\n",
        "\n",
        "        replay_buffer.add(state, action, reward, next_state, done)\n",
        "\n",
        "        if len(replay_buffer) > 1000:\n",
        "            # Sample a batch of transitions from the replay buffer\n",
        "            transitions = replay_buffer.sample(batch_size=32)\n",
        "\n",
        "            # Calculate the target Q-values\n",
        "            target_Q = critic(transitions.next_state, actor(transitions.next_state))\n",
        "            target_Q = target_Q.detach()\n",
        "\n",
        "            # Calculate the current Q-values\n",
        "            current_Q = critic(transitions.state, transitions.action)\n",
        "\n",
        "            # Calculate the critic loss\n",
        "            critic_loss = torch.mean((target_Q - current_Q).pow(2))\n",
        "\n",
        "            # Calculate the actor loss\n",
        "            actor_loss = -torch.mean(critic(transitions.state, actor(transitions.state)))\n",
        "\n",
        "            # Update the critic network\n",
        "            critic_optimizer.zero_grad()\n",
        "            critic_loss.backward()\n",
        "            critic_optimizer.step()\n",
        "\n",
        "            # Update the actor network\n",
        "            actor_optimizer.zero_grad()\n",
        "            actor_loss.backward()\n",
        "            actor_optimizer.step()\n",
        "\n",
        "        state = next_state\n",
        "\n",
        "        if done:\n",
        "            break\n",
        "\n",
        "    # Evaluate the agent\n",
        "    episode_reward = 0\n",
        "\n",
        "    for t in range(1000):\n",
        "        state = env.reset()\n",
        "\n",
        "        action = actor(state)\n",
        "\n",
        "        next_state, reward, done, _ = env.step(action)\n",
        "\n",
        "        episode_reward += reward\n",
        "\n",
        "        if done:\n",
        "            break\n",
        "\n",
        "    print('Episode {}: {}'.format(episode, episode_reward))"
      ],
      "outputs": [
        {
          "output_type": "error",
          "ename": "ImportError",
          "evalue": "cannot import name 'tree_map_' from 'torch.utils._pytree' (/anaconda/envs/azureml_py38/lib/python3.8/site-packages/torch/utils/_pytree.py)",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mImportError\u001b[0m                               Traceback (most recent call last)",
            "Cell \u001b[0;32mIn [5], line 13\u001b[0m\n\u001b[1;32m     11\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mtorch\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mnn\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mnn\u001b[39;00m\n\u001b[1;32m     12\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mtorch\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01moptim\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01moptim\u001b[39;00m \n\u001b[0;32m---> 13\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtorchrl\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mdata\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m ReplayBuffer \n\u001b[1;32m     15\u001b[0m \u001b[38;5;66;03m# Define the actor and critic networks\u001b[39;00m\n\u001b[1;32m     16\u001b[0m \u001b[38;5;28;01mclass\u001b[39;00m \u001b[38;5;21;01mActor\u001b[39;00m(nn\u001b[38;5;241m.\u001b[39mModule):\n",
            "File \u001b[0;32m/anaconda/envs/azureml_py38/lib/python3.8/site-packages/torchrl/__init__.py:10\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mwarnings\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m warn\n\u001b[1;32m      8\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mtorch\u001b[39;00m\n\u001b[0;32m---> 10\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtensordict\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m set_lazy_legacy\n\u001b[1;32m     12\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtorch\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m multiprocessing \u001b[38;5;28;01mas\u001b[39;00m mp\n\u001b[1;32m     14\u001b[0m set_lazy_legacy(\u001b[38;5;28;01mFalse\u001b[39;00m)\u001b[38;5;241m.\u001b[39mset()\n",
            "File \u001b[0;32m/anaconda/envs/azureml_py38/lib/python3.8/site-packages/tensordict/__init__.py:6\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;66;03m# Copyright (c) Meta Platforms, Inc. and affiliates.\u001b[39;00m\n\u001b[1;32m      2\u001b[0m \u001b[38;5;66;03m#\u001b[39;00m\n\u001b[1;32m      3\u001b[0m \u001b[38;5;66;03m# This source code is licensed under the MIT license found in the\u001b[39;00m\n\u001b[1;32m      4\u001b[0m \u001b[38;5;66;03m# LICENSE file in the root directory of this source tree.\u001b[39;00m\n\u001b[0;32m----> 6\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtensordict\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m_lazy\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m LazyStackedTensorDict\n\u001b[1;32m      7\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtensordict\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m_td\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m is_tensor_collection, SubTensorDict, TensorDict\n\u001b[1;32m      8\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtensordict\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mbase\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m TensorDictBase\n",
            "File \u001b[0;32m/anaconda/envs/azureml_py38/lib/python3.8/site-packages/tensordict/_lazy.py:24\u001b[0m\n\u001b[1;32m     22\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mtorch\u001b[39;00m\n\u001b[1;32m     23\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mtorch\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mdistributed\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mdist\u001b[39;00m\n\u001b[0;32m---> 24\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mfunctorch\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m dim \u001b[38;5;28;01mas\u001b[39;00m ftdim\n\u001b[1;32m     25\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtensordict\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m_td\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m _SubTensorDict, _TensorDictKeysView, TensorDict\n\u001b[1;32m     26\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtensordict\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m_tensordict\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m _unravel_key_to_tuple, unravel_key_list\n",
            "File \u001b[0;32m/anaconda/envs/azureml_py38/lib/python3.8/site-packages/functorch/__init__.py:8\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;66;03m# Copyright (c) Facebook, Inc. and its affiliates.\u001b[39;00m\n\u001b[1;32m      2\u001b[0m \u001b[38;5;66;03m# All rights reserved.\u001b[39;00m\n\u001b[1;32m      3\u001b[0m \u001b[38;5;66;03m#\u001b[39;00m\n\u001b[1;32m      4\u001b[0m \u001b[38;5;66;03m# This source code is licensed under the BSD-style license found in the\u001b[39;00m\n\u001b[1;32m      5\u001b[0m \u001b[38;5;66;03m# LICENSE file in the root directory of this source tree.\u001b[39;00m\n\u001b[1;32m      6\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mtorch\u001b[39;00m\n\u001b[0;32m----> 8\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtorch\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m_functorch\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mdeprecated\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m (\n\u001b[1;32m      9\u001b[0m     combine_state_for_ensemble,\n\u001b[1;32m     10\u001b[0m     functionalize,\n\u001b[1;32m     11\u001b[0m     grad,\n\u001b[1;32m     12\u001b[0m     grad_and_value,\n\u001b[1;32m     13\u001b[0m     hessian,\n\u001b[1;32m     14\u001b[0m     jacfwd,\n\u001b[1;32m     15\u001b[0m     jacrev,\n\u001b[1;32m     16\u001b[0m     jvp,\n\u001b[1;32m     17\u001b[0m     make_functional,\n\u001b[1;32m     18\u001b[0m     make_functional_with_buffers,\n\u001b[1;32m     19\u001b[0m     vjp,\n\u001b[1;32m     20\u001b[0m     vmap,\n\u001b[1;32m     21\u001b[0m )\n\u001b[1;32m     23\u001b[0m \u001b[38;5;66;03m# utilities. Maybe these should go in their own namespace in the future?\u001b[39;00m\n\u001b[1;32m     24\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtorch\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m_functorch\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mmake_functional\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m (\n\u001b[1;32m     25\u001b[0m     FunctionalModule,\n\u001b[1;32m     26\u001b[0m     FunctionalModuleWithBuffers,\n\u001b[1;32m     27\u001b[0m )\n",
            "File \u001b[0;32m/anaconda/envs/azureml_py38/lib/python3.8/site-packages/torch/_functorch/deprecated.py:1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mtorch\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m_functorch\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mapis\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mapis\u001b[39;00m\n\u001b[1;32m      2\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mtorch\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m_functorch\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01meager_transforms\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01m_impl\u001b[39;00m\n\u001b[1;32m      3\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mtorch\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m_functorch\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mmake_functional\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01m_nn_impl\u001b[39;00m\n",
            "File \u001b[0;32m/anaconda/envs/azureml_py38/lib/python3.8/site-packages/torch/_functorch/apis.py:6\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;66;03m# NOTE: We allow Dynamo to see this file (via torch/_dynamo/skipfiles.py) so that it can\u001b[39;00m\n\u001b[1;32m      2\u001b[0m \u001b[38;5;66;03m#       trace through functorch transforms.\u001b[39;00m\n\u001b[1;32m      3\u001b[0m \u001b[38;5;66;03m#       Currently, we can't allow Dynamo to see `eager_transforms.py`/`vmap.py` as that break a lot of thing\u001b[39;00m\n\u001b[1;32m      4\u001b[0m \u001b[38;5;66;03m#       and there isn't a mechanism to selectively expose only some functions (eg. grad) from a file\u001b[39;00m\n\u001b[1;32m      5\u001b[0m \u001b[38;5;66;03m#       to Dynamo.\u001b[39;00m\n\u001b[0;32m----> 6\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtorch\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m_functorch\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mvmap\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m (vmap_impl, _check_randomness_arg,\n\u001b[1;32m      7\u001b[0m                                    Callable, in_dims_t, out_dims_t, _check_out_dims_is_int_or_int_pytree,\n\u001b[1;32m      8\u001b[0m                                    _process_batched_inputs, _chunked_vmap)\n\u001b[1;32m      9\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtorch\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m_functorch\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mutils\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m exposed_in, argnums_t\n\u001b[1;32m     10\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mfunctools\u001b[39;00m\n",
            "File \u001b[0;32m/anaconda/envs/azureml_py38/lib/python3.8/site-packages/torch/_functorch/vmap.py:12\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtorch\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m Tensor\n\u001b[1;32m     11\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtyping\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m Any, Callable, Optional, Tuple, Union, List\n\u001b[0;32m---> 12\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtorch\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mutils\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m_pytree\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m (\n\u001b[1;32m     13\u001b[0m     tree_flatten,\n\u001b[1;32m     14\u001b[0m     tree_unflatten,\n\u001b[1;32m     15\u001b[0m     tree_map_,\n\u001b[1;32m     16\u001b[0m     _broadcast_to_and_flatten,\n\u001b[1;32m     17\u001b[0m     TreeSpec,\n\u001b[1;32m     18\u001b[0m )\n\u001b[1;32m     19\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mfunctools\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m partial\n\u001b[1;32m     20\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mos\u001b[39;00m\n",
            "\u001b[0;31mImportError\u001b[0m: cannot import name 'tree_map_' from 'torch.utils._pytree' (/anaconda/envs/azureml_py38/lib/python3.8/site-packages/torch/utils/_pytree.py)"
          ]
        }
      ],
      "execution_count": 5,
      "metadata": {
        "gather": {
          "logged": 1710768570048
        }
      }
    }
  ],
  "metadata": {
    "kernelspec": {
      "name": "python38-azureml",
      "language": "python",
      "display_name": "Python 3.8 - AzureML"
    },
    "language_info": {
      "name": "python",
      "version": "3.8.5",
      "mimetype": "text/x-python",
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "pygments_lexer": "ipython3",
      "nbconvert_exporter": "python",
      "file_extension": ".py"
    },
    "microsoft": {
      "ms_spell_check": {
        "ms_spell_check_language": "en"
      },
      "host": {
        "AzureML": {
          "notebookHasBeenCompleted": true
        }
      }
    },
    "kernel_info": {
      "name": "python38-azureml"
    },
    "nteract": {
      "version": "nteract-front-end@1.0.0"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 2
}