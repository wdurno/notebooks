{
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# Sufficiency and Efficiency in Deep RL\n",
        "\n",
        "_W. Evan Durno, 2023_\n",
        "\n",
        "**TODO:** the whole document contains a mixture of multivariate and univariate representations of $\\theta$. Switch-over to multivariate.  \n",
        "\n",
        "This work produces miniaturization and optimal efficiency results for reinforcement learning (RL). \n",
        "Miniaturization is achieved by modernizing the definition of sufficient statistics to accommodate the needs of deep learning, \n",
        "and thus produces infinite storage under the right circumstances. \n",
        "The optimal efficiency result is achieved by modernizing the Cramer-Rao Lower Bound (CRLB) away from classical statistics \n",
        "and toward the needs of RL, where sampling distributions can change. \n",
        "\n",
        "The key observation is that RL agents' change their sampling distributions as they learn. \n",
        "This violates the simple random sampling assumptions of classical statistics, \n",
        "thereby making old results less applicable. \n",
        "To account for this change, this work introduces the concept of a sufficient statistic regularizer (SSR), \n",
        "an approximately correct sufficient statistic applicable to deep learning. \n",
        "Further, we adjust the CRLB to account for smoothly deforming sampling distributions, \n",
        "and discover SSRs are used to yield optimally efficient data utilization in RL. "
      ],
      "metadata": {
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Introduction \n",
        "\n",
        "TODO: Describe the problem precisely \n",
        "\n",
        "TODO: Cover similar research. \n",
        "Mention Yann LeCun's work on memory. \n",
        "Motivate targetting RL with \"RL is enough\". "
      ],
      "metadata": {
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## SSRs \n",
        "\n",
        "**Sufficient statistics as regularizers** \n",
        "\n",
        "Data reduction is the purpose of sufficient statistics. \n",
        "This becomes particularly apparent when studying their behavior under maximum likelihood estimation. \n",
        "The Fisher-Neyman defintion of a sufficient statistic $T(x)$ is that there \n",
        "exists $g$ and $h$ for density $f$ such that $f(x; \\theta) = h(x) g(T(x) ; \\theta)$. \n",
        "Notice that under maximum likelihood estimation, the $h$ term becomes irrelevant, leaving only $T(x)$, \n",
        "thereby providing an opportunity to reduce dimensionality of all data stored. \n",
        "\n",
        "$ \\hat \\theta = \\arg \\max_\\theta f(x; \\theta) = \\arg \\max_\\theta \\log f(x; \\theta) $\n",
        "$ = \\arg \\max_\\theta \\log(h(x)) + \\log(g(x; T(x))) = \\arg \\max_\\theta \\log(g(x; T(x)))$ \n",
        "\n",
        "For example, dataset $x$ may require $O(n)$ space to store, but for $\\theta \\in \\mathbb{R}^p$, \n",
        "it's common that $T$ only require $O(p)$ storage space. \n",
        "So, for a model with fixed parameter dimension, \n",
        "it is reasonably possible to have theoretically infinite data storage in a finite space. \n",
        "Of course, the amount of information truly stored will be practically bounded. \n",
        "\n",
        "For the purposes of this work, it is convenient to view sufficient statistics as regularizers. \n",
        "In situations where new data is added to old, like RL, this is particularly relevant. \n",
        "For example, with old data $X_A$ packed into $T_A = T(X_A)$ supplanting $\\hat \\theta_A$, \n",
        "we may add data $X_B$ ultimately producing $T_B = T(X_B)$ sufficiently estimating $\\theta_B$. \n",
        "\n",
        "$\\hat \\theta_B = \\arg\\max_\\theta f_X(X; \\theta) = \\arg \\max_\\theta \\log f_X(X_A;\\theta) + \\log f_X(X_B;\\theta) $\n",
        "$ = \\arg\\max_\\theta \\log f_X(X_A;\\theta) + \\log g(T(X_B; \\theta))$\n",
        "\n",
        "Here, $X$ is the vector containing both $X_A$ and $X_B$, concatenated. \n",
        "\n",
        "If we then insert a scalar multiple $\\lambda$, we recover the familiar regularizer form. \n",
        "\n",
        "$\\hat \\theta_B = \\arg\\max_\\theta \\log f_X(X_A;\\theta) + \\lambda \\log g(T(X_B; \\theta)) $\n",
        "\n",
        "Let this form of regularizer be the SSR. \n",
        "Like other regularizers, $\\lambda \\log g(T(X_B); \\theta)$ causes $\\theta$ to \n",
        "stay near some point $\\theta_A$. \n",
        "For example and without loss of generality (WLOG), $\\lambda \\| \\theta \\|^2$ centers $\\theta$ on zero. \n",
        "\n",
        "**Universal SSRs via approximation** \n",
        "\n",
        "Data reduction via sufficient statistics is like compression. \n",
        "A breadth of theory has been developed for losses compression. \n",
        "Here, we'll highlight the benefits of lossy compression \n",
        "by relaxing our sufficient statistic definition to accommodate an approximation. \n",
        "Define $X_n \\approx_{a.s.} Y$ to mean $\\lim_{n \\to \\infty} X_n = Y \\; a.s.$, \n",
        "and $X_n \\approx_{\\mathbb{P}} Y$ to mean $\\lim_{n \\to \\infty} X_n = Y$ in $\\mathbb{P}$.\n",
        "Then, instead of defining $T$ sufficient if $f_X(x; \\theta) = h(x) g(T(x); \\theta)$, \n",
        "we'll accept $f_X(x; \\theta) \\approx_{\\mathbb{P}} h(x) g(T(x); \\theta)$ for large sample size $n$. \n",
        "\n",
        "With this relaxation, we are free to create approximate universal sufficient statistics \n",
        "only requiring sufficient regularity assumptions apply that the central limit theorem (CLT) \n",
        "apply to make the log likelihood normally distributed. \n",
        "\n",
        "First, recognize that the following Taylor expansion is accurate for $\\theta$ near $\\theta_A$. \n",
        "\n",
        "$n^{-1} \\log f_X(X;\\theta) \\approx n^{-1}\\log f_X(X; \\theta_A) $\n",
        "$ + (\\theta - \\theta_A) n^{-1}\\frac{\\partial}{\\partial \\theta} \\log f_X(X; \\theta_A)$\n",
        "$ + 2^{-1}(\\theta - \\theta_A)^2 n^{-1} \\frac{\\partial^2}{\\partial \\theta^2} \\log f_X(X; \\theta_A) $  \n",
        "\n",
        "$\\approx_{a.s.} \\mathbb{E} \\log f_X(X_1; \\theta_A) + (\\theta - \\theta_A) \\mathbb{E} \\frac{\\partial}{\\partial \\theta} \\log f_X(X_1; \\theta_A)$ \n",
        "$ + 2^{-1} (\\theta - \\theta_A)^2 \\mathbb{E} \\frac{\\partial^2}{\\partial \\theta^2} \\log f_X(X_1;\\theta_A) $ (apply the strong law of large numbers (SLLN))\n",
        "\n",
        "$ = \\mathbb{E} \\log f_X(X_1; \\theta_A) + 0 - 2^{-1} (\\theta - \\theta_A)^2 \\mathcal{I}_{\\theta_A} $\n",
        "\n",
        "Here, we utilize further approximations:\n",
        "- $\\hat{\\mathcal{I}}(X_A) = \\hat{\\mathcal{I}} = n^{-1}\\sum_{i=1}^n G_i G_i^T \\approx_{a.s.} \\mathcal{I}$ \n",
        "where $G_i = \\nabla_\\theta \\log f_X(X_i; \\theta_A) $ \n",
        "- $\\hat \\theta_A(X_A) = \\hat \\theta_A \\arg \\max_\\theta f_X(X_A;\\theta) \\approx_{\\mathbb{P}} \\theta_A$\n",
        "\n",
        "Then we realize the following. \n",
        "\n",
        "$\\mathbb{E} \\log f_X(X_1; \\theta_A) - 2^{-1} (\\theta - \\theta_A)^2 \\mathcal{I}_{\\theta_A}$\n",
        "\n",
        "$\\approx_{\\mathbb{P}} \\mathbb{E} \\log f_X(X_1; \\theta_A) - n_A 2^{-1} (\\theta - \\hat \\theta_A(X_A))^2 \\hat{\\mathcal{I}}(X_A)$\n",
        "\n",
        "Here, $n_A$ is the sample size of $X_A$. \n",
        "\n",
        "This approximation is not-yet useful, still depending on $\\theta_A$. \n",
        "So, we must apply it in maximum likelihood estimation to drop the $\\mathbb{E} \\log f_X(X_1; \\theta_A)$ term. \n",
        "Here, we add new data $X_B$ to the sample, while approximately retaining all information of $X_A$ \n",
        "in $T(X_A) = \\left(\\hat \\theta_A(X_A), \\hat{\\mathcal{I}}(X_A) \\right)$.\n",
        "\n",
        "$\\hat \\theta_B = \\arg\\max_\\theta f_X(X; \\theta) = \\arg\\max_\\theta \\log f_X(X_B; \\theta) + \\log f_X(X_A;\\theta) $\n",
        "\n",
        "$ \\approx_{\\mathbb{P}} \\arg\\max_\\theta \\log f_X(X_B; \\theta) $\n",
        "$+ \\mathbb{E} \\log f_X(X_1; \\theta_A) - n_A 2^{-1} (\\theta - \\hat \\theta_A(X_A))^2 \\hat{\\mathcal{I}}(X_A) $\n",
        "\n",
        "$ = \\arg\\max_\\theta \\log f_X(X_B; \\theta) - n_A 2^{-1} (\\theta - \\hat \\theta_A(X_A))^2 \\hat{\\mathcal{I}}(X_A) $\n",
        "\n",
        "We thus identify the universal SSR $2^{-1} (\\theta - \\hat \\theta_A(X_A))^2 \\hat{\\mathcal{I}}(X_A)$ \n",
        "with its natural regularization parameter value $\\lambda = n_A$. \n",
        "\n",
        "**Miniaturization** \n",
        "\n",
        "Storing $\\hat \\theta(X_A)$ takes $O(p)$ space and $\\hat{\\mathcal{I}}(X_A)$ takes $O(p^2)$. \n",
        "So, while technically finite relative to $O(n)$, the sheer size of modern deep learning models \n",
        "makes any $O(p^2)$ storage requirement infeasible. \n",
        "So, this work will leverage a series of approximations that keep practically effective approximations \n",
        "to $\\mathcal{I}$ in $O(p)$. \n",
        "- The simplest approximation is only storing diagonal terms, and zeroing all others. \n",
        "- A better (but usually unnecessary) approach is leveraging a Krylov estimate to \n",
        "approximate the major eigenvectors of $\\mathcal{I}$. \n",
        "These are calculated via a modified version of the Lanczos algorithm. \n",
        "\n",
        "For experimental validation showing these approximations are effective, see Appendix B."
      ],
      "metadata": {
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Optimal MLE efficiency under deforming distributions \n",
        "\n",
        "As an RL agent learns from its environment, it tries new things and produces new kinds of data. \n",
        "Accepting that RL doesn't sample from identical distributions invites us to find an optimal transition paradigm. \n",
        "Interpreting _optimality_ as _efficiency_, this means working with the Cramer-Rao lower bound (CRB). \n",
        "Particularly, since maximum likelihood estimates (MLEs) from different distributions appear biased to another, \n",
        "we'll work with the mean squared error (MSE) form of the CRB. \n",
        "The strategy is simple: calculate the MSE under biased MLE deformations, and minimize it with respect to $\\lambda$. \n",
        "\n",
        "To recover a optimal $\\lambda$, we use the following definitions. \n",
        "- $X_A$ is the vector (or matrix) of observations having density $f_X(x; \\theta_A)$. \n",
        "- $X_B$ similarly has density $f_X(x; \\theta_B)$. \n",
        "- $\\hat \\theta_A = \\arg\\max_\\theta f_X(X_A; \\theta)$ is a simple MLE. \n",
        "- $\\hat \\theta_B = \\arg\\max_\\theta f_X(X_B; \\theta)$\n",
        "- $\\hat \\theta_{AB} = \\arg\\max_\\theta \\log f_X(X_A ; \\theta) + \\log f_X(X_B; \\theta) $ \n",
        "$ = \\arg\\max_\\theta \\sum_{i \\in A} \\log f_X(X_i ; \\theta) + \\sum_{i \\in B} \\log f_X(X_i; \\theta) $ \n",
        "- $n_A = \\#A, n_B = \\#B, n = n_A + n_B$\n",
        "- $p = \\lim_{n \\to \\infty} n_B/n$. WLOG, we assume this series converges so we may have $p \\approx n_B/n$. \n",
        "\n",
        "With these definitions in-place, we can realize this $\\theta_{AB}$ form which can optimize MSE in $p$, determining optimal $\\lambda$. \n",
        "\n",
        "$\\hat \\theta_{AB} = \\arg\\max_\\theta \\log f_X(X_A ; \\theta) + \\log f_X(X_B; \\theta) $\n",
        "\n",
        "$ \\approx_{\\mathbb{P}} \\arg\\max_\\theta \\log f_X(X_B; \\theta) - n_A 2^{-1} (\\theta - \\hat \\theta_A)^T \\hat{\\mathcal{I}} (\\theta - \\hat \\theta_A)$\n",
        "\n",
        "$ \\approx n^{-1}\\arg\\max_\\theta \\log f_X(X_B; \\theta) - (1-p) 2^{-1} (\\theta - \\hat \\theta_A)^T \\hat{\\mathcal{I}} (\\theta - \\hat \\theta_A)$\n",
        "\n",
        "**CRB for mixed data** \n",
        "\n",
        "The CRB was designed with independent and identically distributed (iid) observations in-mind. \n",
        "Given our core observation that RL deforms distributions during sampling, \n",
        "we'll apply some regularity assumptions on our distributions to keep the CRB relevant. \n",
        "Assume that: \n",
        "- $f_X(x; \\theta)$ is smooth in $\\theta$ near $\\theta_B$. \n",
        "- $\\theta_A$ is sufficiently near to $\\theta_B$ that $\\log f_X(x; \\theta_A) \\approx \\log f_X(x; \\theta_B) + (\\theta_A - \\theta_B)^T \\nabla_\\theta \\log f_X(x; \\theta_B) $\n",
        "$+ 2^{-1} (\\theta_A - \\theta_B)^T \\left( \\nabla^2_\\theta \\log f_X(x; \\theta_B) \\right) (\\theta_A - \\theta_B) $ holds.\n",
        "\n",
        "This implies both $\\theta_A$ and $\\theta_B$ have approximately the same Hessians, $-\\mathcal{I}$. \n",
        "Leveraging equivalent Hessians, the CRB can be applied to minimize the MSE. \n",
        "\n",
        "For bias term $b = \\mathbb{E} \\hat \\theta_{AB} - \\theta_B$ and $b' = \\nabla_{\\theta_B}b$, the CRB clearly states this effect of a biased estimate.\n",
        "\n",
        "$\\mathbb{E}(\\hat \\theta_{AB} - \\theta_B) \\geq (1 + b')^2 \\mathcal{I}^{-1} + b^2$\n",
        "\n",
        "Recognizing $\\mathbb{E}\\hat \\theta_{AB} \\approx p \\theta_B + (1-p) \\theta_A$, we recover this inequality. \n",
        "\n",
        "$\\mathbb{E}(\\hat \\theta_{AB} - \\theta_B) \\gtrsim (1 - 1 + p)^2/(p\\mathcal{I} + (1-p) \\mathcal{I}) + (1-p)^2(\\theta_A - \\theta_B)^2 $\n",
        "$ = p^2 \\mathcal{I}^{-1} + (1-p)^2 (\\theta_A - \\theta_B)^2$\n",
        "\n",
        "Differentiating by $p$ and setting to zero, we recover an optimal approximate value for $\\lambda$. \n",
        "\n",
        "$\\frac{n_A}{n_B} \\approx \\frac{p}{1-p} = (\\theta_B - \\theta_A)^2 \\mathcal{I} $\n",
        "\n",
        "Using the natural value for $\\lambda = n_A$, we recover $\\hat \\lambda = n_B (\\theta_A - \\theta_B)^2 \\mathcal{I} $.\n",
        "\n",
        "Unfortunately, $\\hat \\lambda$ is used to estimate $\\theta_B$, so we do not yet know $(\\theta_A - \\theta_B)^2$. \n",
        "However, it's fair that to assume that a sufficiently complex agent will eventually understand an entire game, \n",
        "resulting in true $\\theta$ converging. In this case, the standard CRB applies, and eventually $(\\theta_A - \\theta_B)^2 \\sim N(0, \\mathcal{I}^{-1}/n_B)$, resulting in $\\hat \\lambda = 1$. \n",
        "\n",
        "Under this paradigm, $n_A$ is still useful when arbitrarily large. \n",
        "However, setting it to $n_A = \\hat \\lambda$ virtually up-samples $X_A$ or $X_B$. "
      ],
      "metadata": {
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Experimental results: Cart Pole**\n",
        "\n",
        "This initial experiment demonstrates the effectiveness of SSRs, \n",
        "and studies the behavior of $\\| \\theta_A - \\theta_B \\|^2_F$ near the solution point. \n",
        "The experiment is kept purposefully simple to isolate experimental effects. \n",
        "We apply a [small deep net](https://github.com/wdurno/notebooks/commit/8e20a0ec7a5c2376b954d2a04a930064e8e77f69#diff-9067e1aea905e3792706d011ba5a0007ba0147bbc9f8b02e76a0b9b07acbd13d) \n",
        "to [Cart Pole with a 4-dimensional state space](https://www.gymlibrary.dev/environments/classic_control/cart_pole/). \n",
        "\n",
        "Experimental conditions are \n",
        "1. SSRs are applied with $\\lambda = 1$. The observation cache is entirely cleared after each memorization event.\n",
        "2. SSRs are applied with approximately optimal $\\lambda = \\hat \\lambda = (\\theta_A - \\theta_B)^T \\hat{\\mathcal{I}} (\\theta_A - \\theta_B)$. Since $\\theta_A$ is never known, we use the $\\theta_A - \\theta_B$ difference from the prior memorization event. The observation cache is entirely cleared after each memorization event.\n",
        "3. SSRs are applied with $\\lambda = \\hat \\lambda / 10$. The observation cache is entirely cleared after each memorization event.\n",
        "4. SSRs are applied with $\\lambda = \\hat \\lambda * 10$. The observation cache is entirely cleared after each memorization event. \n",
        "5. Control: No SSRs are applied, but the observation cache is cleared at moments coinciding with each memorization event. \n",
        "6. Control: No SSRs are applied, and observations caches are entirely retained. \n",
        "\n",
        "**TODO:** clean-up this graphic: axes, title, number conditions \n",
        "\n",
        "In the below graphic, the x-axis tracks the game iteration, \n",
        "and the y-axis tracks average game score over 1000 agents. \n",
        "Agents restart their games when they lose and during memorization events. \n",
        "Three memorization events can clearly be seen in the graph.\n",
        "\n",
        "![cart pole](./data/df-experiment-22.png)\n",
        "\n",
        "\n",
        "This graphic clearly supports the optimality of the SSR method in RL applications. \n",
        "Lift is clearly more-efficient, as the method uses data most-efficiently. \n",
        "Better yet, the method enjoys the miniaturization benefits of storing any amount of data in an $O(p)$ space. \n",
        "\n",
        "It can be seen that the lagged estimate of $\\hat \\lambda$ is decently accurate, \n",
        "but so is taking $\\hat \\lambda = 1$ even during early gameplay. "
      ],
      "metadata": {
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Experimental result: robotics**\n",
        "\n",
        "This work's sufficiency and efficiency results are asymptotic results, \n",
        "so are theoretically valid for a large breadth of models. \n",
        "So, the sufficiency and efficiency should be demonstrated in another game beyond Cart Pole.\n",
        "Further, sufficiency and efficiency are particularly useful toward robotics, \n",
        "this new game is played by a real-world robot. \n",
        "\n",
        "The robot is a PiCar V \\[1\\] wheeled robot with articulated camera, \n",
        "capable of driving forward & backward, turning left & right, \n",
        "and looking up, forward, left & right. \n",
        "Video processing and servo articulation is processed by an on-board Raspberry Pi 4B.\n",
        "\n",
        "![robot](./data/robot.jpg)\n",
        "\n",
        "This PiCar is customized to minimize on-board processing, \n",
        "instead running [this](https://github.com/wdurno/picar-v-rl-env/blob/1d5f5e15b390ef7cceae3fbe8875f71fbc76995f/run_api.py) server, offloading deep net processing to \n",
        "[this](https://github.com/wdurno/notebooks/blob/814f7cfed779fc4990f770b20a5ad924fbd7c693/regularizers-as-memory/car.py)\n",
        "GPU-accelerated client. \n",
        "\n",
        "Similar to the out-of-the-box [software](https://github.com/sunfounder/SunFounder_PiCar-V/blob/master/ball_track/ball_tracker.py), \n",
        "the RL game is to chase a red ball and have the agent get close to it, \n",
        "confirming the presence visually. \n",
        "Experiments were conducted in the same household office, \n",
        "under near-consistent lighting conditions. \n",
        "\n",
        "Three experiments were run.\n",
        "\n",
        "1. (Control) standard Q-Learning, retaining all data in the memory buffer \n",
        "2. (Experimental 1) Using memorization, clearing the memory buffer after each memorization, \n",
        "using $\\hat \\lambda_t = (\\hat \\theta_{t} - \\hat \\theta_{t-1})^T \\hat{\\mathcal{I}}(\\hat \\theta_{t} - \\hat \\theta_{t-1}) $, where $\\hat{\\mathcal{I}}$ is estimated with a Krylov rank of 10 (see Appendix A).\n",
        "Memorization occurs 40 times.\n",
        "3. (Experimental 2) Same as experimental 1, but with $\\hat \\lambda = 1$ for every iteration.\n",
        "\n",
        "Data were all sampled by an agent following experimental condition 2.\n",
        "All three experimental conditions used the same datasets, \n",
        "with the agent being exposed to data in the same order it was sampled. \n",
        "Thus, this was an offline RL experiment. \n",
        "Since optimal offline RL metrics are unclear \\[2\\], \n",
        "we simply use expected discounted reward per batch at teach time step. \n",
        "\n",
        "**TODO**: This graphic is _terrible_. Also, not pictured: $\\hat \\lambda = 1$ is lowest performer.\n",
        "![robot metrics](./data/df-experiment-24.png)\n",
        "\n",
        "As can be seen, this new game has exceptional results when \n",
        "SSRs are applied and $\\hat \\lambda$ is projected. \n",
        "This illustrates the potential for universal effectiveness of SSR efficiency. \n",
        "Further, the failure of the $\\hat \\lambda = 1$ case shows that complex games \n",
        "require accurate $\\hat \\lambda$ projection. "
      ],
      "metadata": {
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Discussion \n",
        "\n",
        "TODO: SSRs provide a universal miniaturization paradigm \n",
        "\n",
        "TODO: RL lift should be expected by accounting for deforming distributions \n",
        "\n",
        "TODO: $\\hat \\lambda$ projection needs further work. \n",
        "\n",
        "TODO: The other half of CRLB $\\mathcal{I}^{-1}/n$ can be explored. \n",
        "I've optimized $n$, but there's a rich structure to $\\mathcal{I}$. \n",
        "\n",
        "TODO: Continuous sampling and Ito integrals? \n",
        "\n",
        "TODO: Robotics ought to be tested again with a real budget \n",
        "\n",
        "TODO: alternative methods to estimating $\\hat{\\mathcal{I}}$ and $\\| \\hat \\theta_B - \\hat \\theta_A \\| $. "
      ],
      "metadata": {
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## References \n",
        "\n",
        "\\[1\\] https://www.sunfounder.com/products/smart-video-car\n",
        "\n",
        "\\[2\\] Romain Deffayet, Thibaut Thonet, Jean-Michel Renders, & Maarten de Rijke (2022) \"Offline Evaluation for Reinforcement Learning-based Recommendation: A Critical Issue and Some Alternatives\", ACM SIGIR Forum, Vol. 56 No. 2. "
      ],
      "metadata": {
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Appendix A: modified Lanczos algorithm \n",
        "\n",
        "TODO: Describe the $LL^T + \\Lambda$ estimate, and motivate it with Shun Ichi Amari's work on eigenvalue distributions. \n",
        "\n",
        "TODO: my limited-memory Lanczos algorithm "
      ],
      "metadata": {
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Appendix B: Effectiveness of $O(p)$ Hessian approximations \n",
        "\n",
        "TODO: Show results "
      ],
      "metadata": {
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      }
    }
  ],
  "metadata": {
    "kernelspec": {
      "name": "python310-sdkv2",
      "language": "python",
      "display_name": "Python 3.10 - SDK V2"
    },
    "language_info": {
      "name": "python",
      "version": "3.10.6",
      "mimetype": "text/x-python",
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "pygments_lexer": "ipython3",
      "nbconvert_exporter": "python",
      "file_extension": ".py"
    },
    "microsoft": {
      "ms_spell_check": {
        "ms_spell_check_language": "en"
      }
    },
    "kernel_info": {
      "name": "python310-sdkv2"
    },
    "nteract": {
      "version": "nteract-front-end@1.0.0"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 2
}