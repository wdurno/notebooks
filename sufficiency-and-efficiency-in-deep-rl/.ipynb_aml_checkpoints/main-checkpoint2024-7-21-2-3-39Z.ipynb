{
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# Sufficiency and Efficiency in Deep Reinforcement Learning\n",
        "\n",
        "_W. Evan Durno, 2024_\n",
        "\n",
        "This work produces miniaturization and optimal efficiency results for reinforcement learning (RL) with deep neural networks. \n",
        "Miniaturization is achieved by modernizing the definition of sufficient statistics to accommodate the needs of deep learning, \n",
        "thus producing theoretically infinite storage under the right circumstances. \n",
        "The optimal efficiency result is achieved by adjusting the Cramer-Rao Lower Bound (CRLB) away from classical statistics \n",
        "and toward the needs of RL, where sampling distributions can change. \n",
        "Efficiency is important, because it means we're getting the most out of our data. \n",
        "Results are theoretically general in that they are applicable to much of deep learning, \n",
        "and supported by observations from two different games. \n",
        "\n",
        "The key mathematical premise is that RL agents change their sampling distributions as they learn. \n",
        "This violates the simple random sampling assumptions of classical statistics, \n",
        "thereby making old results less applicable. \n",
        "To account for this change, this work introduces the concept of a sufficient statistic regularizer (SSR), \n",
        "an approximately correct sufficient statistic applicable to deep learning. \n",
        "Further, we adjust the CRLB to account for continuously deforming sampling distributions, \n",
        "and discover SSRs are used to yield optimally efficient data utilization in RL. "
      ],
      "metadata": {
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Introduction \n",
        "\n",
        "The success of modern deep learning depends substantially on massive compute tasks. \n",
        "This can be seen in multi-million dollar model-fitting costs \\[7\\] of large language models (LLMs). \n",
        "With compute at this scale, the next frontier of progress is likely to lay in the pursuit of efficiency. \n",
        "This work contributes to efficiency by revisiting older statistical concepts in-need of modernization: \n",
        "sufficient statistics and statistical efficiency via the Cramer Rao Lower Bound (CRLB). \n",
        "Sufficient statistics provide miniaturization benefits by bounding computational \n",
        "processing and storage requirements. \n",
        "Statistical efficiency is optimized analyzing the CRLB in the Reinforcement Learning (RL) context, \n",
        "ensuring we get best-possible value from our data. \n",
        "\n",
        "This work's applied targets focus on RL \n",
        "because it's our current best bet in delivering artificial general intelligence (AGI) \\[9\\]. \n",
        "Further, RL \\[12: chapter 11 \"Markov Decision Processes\"\\] is new enough that there is room for impactful theoretical development. \n",
        "This is indeed the case, as following the needs of RL challenges foundational assumptions of statistics, \n",
        "and invites development of an AI-flavored theory of statistics. \n",
        "\n",
        "In 1922, a world before an explosion of computational resources, \n",
        "R. A. Fisher described the chief task of statistics as \"reduction of data,\" \n",
        "and promptly introduced his formalization of _sufficient statistics_ as \n",
        "one of a few primary tools for achieving this \\[8\\].\n",
        "This work brings sufficient statistics into the modern era through approximate \n",
        "methods making them computationally tractable for deep learning models. \n",
        "The result carries Fisher's vision forward by ultimately setting limits \n",
        "on the amount of data that must be stored and processed in the handling \n",
        "of modern models. \n",
        "I call this method the _sufficient statistic regularizer_ (SSR). \n",
        "The method isn't entirely novel \\[10, 11\\], \n",
        "but recognizing its approximate sufficiency is. \n",
        "Exponential family sufficient statistics are known to produce finite-dimensional \n",
        "storage opportunities \\[13\\] which are yielded here, \n",
        "so a miniaturization opportunity exists - this is how theoretically infinite storage is achieved. \n",
        "However, the bounds are large, so applications may be patchy or require \n",
        "more-intensive data processing before they are useful. \n",
        "Regardless, developing SSRs sets a useful framing for describing my \n",
        "immediately-applicable contributions to the CRLB. \n",
        "\n",
        "The CRLB \\[14, 15\\] was developed in a statistical era focussed on experimentalist science, \n",
        "and so related theory depends on a simple random sample assumption, \n",
        "frequently called the _independence and identical distribution_ (_iid_) assumption. \n",
        "The iid assumption has served us well as a foundation for building powerful statistical theories \n",
        "ultimately allowing modern AI to occur. \n",
        "The maximum likelihood estimate (MLE) is a good example of this \\[8, 16\\]. \n",
        "However, the further we follow AI's arc, the further we stray from simple random samples. \n",
        "RL agents learn as samples are generated and thus change their sampling distributions as sampling occurs. \n",
        "So, we must contend with drifting measures $\\mathbb{P}_t, \\mathbb{P}_{t+1}, \\ldots$, \n",
        "and reconcile their differences usefully. \n",
        "Despite explicitly violating the _iid assumption_, \n",
        "we explore how to combine datasets usefully and optimally. \n",
        "The result is an RL-adjusted version of the CRLB, \n",
        "built on independence assumptions but _less identical_ distributions. "
      ],
      "metadata": {
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Formalizing transitions via a mixture model** \n",
        "\n",
        "This work ultimately updates the CRLB for RL by accommodating the need for continuously deforming distributions, \n",
        "$\\mathbb{P}_t, \\mathbb{P}_{t+1}, \\ldots$.\n",
        "To achieve this, we reasonably assume our deep learning model can accommodate the complexity of each measure $\\mathbb{P}_t$, \n",
        "so instead have a single measure $\\mathbb{P}$ and have a series of parameter points $\\theta_t, \\theta_{t+1}, \\ldots$ in our parameter space $\\Theta \\subset \\mathbb{R}^p$. \n",
        "To simplify analysis, we'll only focus on a single transition at a time $(\\theta_t, \\theta_{t+1}) = (\\theta_A, \\theta_B)$. \n",
        "We assume we are free to sample from each point as needed, without a change of distribution.  \n",
        "\n",
        "To coherently apply the theory of experimentalist statistics to RL's changing distributions, \n",
        "we use a mixture model. \n",
        "For each observation $X_i$, we assume it is selected randomly from either $A$ or $B$, \n",
        "despite the model sampling sequentially from $A$ then $B$. \n",
        "This hand-off facilitates a change of distribution while using older statistical machinery which \n",
        "assumes a single distribution. \n",
        "\n",
        "1. $X_i = M_i X_{B_i} + (1 - M_i) X_{A_i}$\n",
        "2. $i \\in \\{0, 1, 2, \\ldots, n\\}$\n",
        "3. $\\mathbb{P}[M_i = 1] = \\pi = 1 - \\mathbb{P}[M_i = 0]$\n",
        "4. $X_{A_i} \\sim f_{X_1} (x ; \\theta_A) $\n",
        "5. $X_{B_i} \\sim f_{X_1} (x ; \\theta_B) $\n",
        "\n",
        "Despite being a mixture model, our sampling procedure reveals $M_i$. \n",
        "We choose when to update our model and when to sample, \n",
        "so we know which version generated which data. \n",
        "So, our analysis is effectively under the $\\mathbb{P}_\\theta[\\; \\cdot \\;| M]$ measure. \n",
        "\n",
        "This estimation paradigm accommodates for the non-_iid_ nature of RL \n",
        "by assuming _iid_ sampling per version of the model. \n",
        "This opens-up questions around how to optimally combine data. \n",
        "In RL applications, it'll be typical to have a lot of data, \n",
        "but each $n_t$ will be small. \n",
        "For example, if $n_B$ is small, \n",
        "then any estimator will have variance of at least $\\mathcal{I}^{-1}/n_B$, \n",
        "so it may be preferable to accommodate a little bias by leveraging all prior data. \n",
        "We call the combined estimate $\\hat \\theta_{AB}$. \n",
        "Since $n_B$ is small and $n$ quite large, \n",
        "we should expect that $\\text{MSE}(\\hat \\theta_B) > \\text{MSE}(\\hat \\theta_{AB})$ holds generally, \n",
        "provided $\\theta_A$ and $\\theta_B$ are not too far apart. \n",
        "Below, I build-out the theory proving optimality of $\\hat \\theta_{AB}$. "
      ],
      "metadata": {
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Structure of this document** \n",
        "\n",
        "This document has opened with a description of the problem, \n",
        "relevant literature, and describes our fundamental \n",
        "mathematical framework. \n",
        "\n",
        "The following section describes a modernized perspective on sufficient statistics, via SSRs. \n",
        "SSRs bring sufficient statistic theory into the deep learning era via \n",
        "an approximate framework, instead of the usual exact one. \n",
        "SSRs are built-out because they provide an appropriate framing for my efficiency result. \n",
        "\n",
        "After describing SSRs, the CRLB is applied to our mixture process, \n",
        "thereby building a framework for optimally efficient use of data in RL. \n",
        "The result is derived mathematically, then verified with two experiments. \n",
        "The first experiment applies this RL-adjusted CRLB to a very simple game: \n",
        "Cart Pole with a 4-dimensional state space. \n",
        "The second experiment is uses offline RL and real-world robotics. \n",
        "\n",
        "The discussion shares a few perspectives, \n",
        "and follow-up research opportunities. \n",
        "\n",
        "The appendix covers a limited-memory version of the Lanczos algorithm, \n",
        "which can be an eigenvector algorithm with small modifications. \n",
        "It calculates a basis of an $r$-dimensional Krylov space for a covariance matrix \n",
        "$\\hat\\Sigma \\in \\mathbb{R}^{p \\times p}$ without actually storing the whole matrix in-memory. \n",
        "For $n$ sample vectors estimating $\\hat \\Sigma$, the algorithm can calculate the basis \n",
        "in $O(nrp)$ time and using about $O(rp)$ space. \n",
        "This gets around the typically prohibitive $O(p^2)$ space requirement of deep \n",
        "learning models. \n",
        "I use this algorithm to provide computationally tractable Fisher Information matrices. "
      ],
      "metadata": {
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## SSRs \n",
        "\n",
        "**Sufficient statistics as regularizers** \n",
        "\n",
        "Data reduction is the purpose of sufficient statistics. \n",
        "This becomes particularly apparent when studying their behavior under maximum likelihood estimation. \n",
        "The Fisher-Neyman defintion of a sufficient statistic $T(x)$ is that there \n",
        "exists $g$ and $h$ for density $f$ such that $f(x; \\theta) = h(x) g(T(x) ; \\theta)$. \n",
        "Notice that under maximum likelihood estimation, the $h$ term becomes irrelevant, leaving only $T(x)$, \n",
        "thereby providing an opportunity to reduce dimensionality of all data stored. \n",
        "\n",
        "$ \\hat \\theta = \\arg \\max_\\theta f(x; \\theta) = \\arg \\max_\\theta \\log f(x; \\theta) $\n",
        "$ = \\arg \\max_\\theta \\log(h(x)) + \\log(g(x; T(x))) = \\arg \\max_\\theta \\log(g(x; T(x)))$ \n",
        "\n",
        "For example, dataset $x$ may require $O(n)$ space to store, but for $\\theta \\in \\mathbb{R}^p$, \n",
        "it's common that $T$ only require $O(p)$ storage space. \n",
        "So, for a model with fixed parameter dimension, \n",
        "it is reasonably possible to have theoretically infinite data storage in a finite space. \n",
        "Of course, the amount of information truly stored will be practically bounded. \n",
        "\n",
        "For the purposes of this work, it is convenient to view sufficient statistics as regularizers. \n",
        "In situations where new data is added to old, like RL, this is particularly relevant. \n",
        "For example, with old data $X_A$ packed into $T_A = T(X_A)$ supplanting $\\hat \\theta_A$, \n",
        "we may add data $X_B$ ultimately producing $T_B = T(X_B)$ sufficiently estimating $\\theta_B$. \n",
        "\n",
        "$\\hat \\theta_B = \\arg\\max_\\theta f_X(X; \\theta) = \\arg \\max_\\theta \\log f_X(X_A;\\theta) + \\log f_X(X_B;\\theta) $\n",
        "$ = \\arg\\max_\\theta \\log f_X(X_A;\\theta) + \\log g(T(X_B; \\theta))$\n",
        "\n",
        "Here, $X$ is the vector containing both $X_A$ and $X_B$, concatenated. \n",
        "\n",
        "If we then insert a scalar multiple $\\lambda$, we recover the familiar regularizer form. \n",
        "\n",
        "$\\hat \\theta_B = \\arg\\max_\\theta \\log f_X(X_A;\\theta) + \\lambda \\log g(T(X_B; \\theta)) $\n",
        "\n",
        "Let this form of regularizer be the SSR. \n",
        "Like other regularizers, $\\lambda \\log g(T(X_B); \\theta)$ causes $\\theta$ to \n",
        "stay near some point $\\theta_A$. \n",
        "For example and without loss of generality (WLOG), $\\lambda \\| \\theta \\|^2$ centers $\\theta$ on zero. "
      ],
      "metadata": {
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Universal SSRs via approximation** \n",
        "\n",
        "Data reduction via sufficient statistics is like compression. \n",
        "A breadth of theory has been developed for losses compression. \n",
        "Here, we'll highlight the benefits of lossy compression \n",
        "by relaxing our sufficient statistic definition to accommodate an approximation. \n",
        "Define $X_n \\approx_{a.s.} Y$ to mean $\\lim_{n \\to \\infty} X_n = Y \\; a.s.$, \n",
        "and $X_n \\approx_{\\mathbb{P}} Y$ to mean $\\lim_{n \\to \\infty} X_n = Y$ in $\\mathbb{P}$.\n",
        "Then, instead of defining $T$ sufficient if $f_X(x; \\theta) = h(x) g(T(x); \\theta)$, \n",
        "we'll accept $f_X(x; \\theta) \\approx_{\\mathbb{P}} h(x) g(T(x); \\theta)$ for large sample size $n$. \n",
        "\n",
        "With this relaxation, we are free to create approximate universal sufficient statistics \n",
        "only requiring sufficient regularity assumptions apply that the central limit theorem (CLT) \n",
        "apply to make the log likelihood normally distributed. \n",
        "\n",
        "First, recognize that the following Taylor expansion is accurate for $\\theta$ near $\\theta_A$. \n",
        "\n",
        "$n^{-1} \\log f_X(X;\\theta) \\approx n^{-1}\\log f_X(X; \\theta_A) $\n",
        "$ + (\\theta - \\theta_A)^T n^{-1} \\nabla_\\theta \\log f_X(X; \\theta_A)$\n",
        "$ + 2^{-1}(\\theta - \\theta_A)^T n^{-1} \\left( \\nabla_\\theta^2 \\log f_X(X; \\theta_A) \\right) (\\theta - \\theta_A) $  \n",
        "\n",
        "$\\approx_{a.s.} \\mathbb{E} \\log f_X(X_1; \\theta_A) + (\\theta - \\theta_A)^T \\mathbb{E} \\nabla_\\theta \\log f_X(X_1; \\theta_A)$ \n",
        "$ + 2^{-1} (\\theta - \\theta_A)^T \\left( \\mathbb{E} \\nabla_\\theta^2 \\log f_X(X_1;\\theta_A) \\right) (\\theta - \\theta_A) $ \n",
        "(apply the strong law of large numbers (SLLN))\n",
        "\n",
        "$ = \\mathbb{E} \\log f_X(X_1; \\theta_A) + 0 - 2^{-1} (\\theta - \\theta_A)^T \\mathcal{I}_{\\theta_A} (\\theta - \\theta_A) $\n",
        "\n",
        "Here, we utilize further approximations:\n",
        "- $\\hat{\\mathcal{I}}(X_A) = \\hat{\\mathcal{I}} = n^{-1}\\sum_{i=1}^n G_i G_i^T \\approx_{a.s.} \\mathcal{I}$ \n",
        "where $G_i = \\nabla_\\theta \\log f_X(X_i; \\theta_A) $ \n",
        "- $\\hat \\theta_A(X_A) = \\hat \\theta_A = \\arg \\max_\\theta f_X(X_A;\\theta) \\approx_{\\mathbb{P}} \\theta_A$\n",
        "\n",
        "Then we realize the following. \n",
        "\n",
        "$\\mathbb{E} \\log f_X(X_1; \\theta_A) - 2^{-1} (\\theta - \\theta_A)^T \\mathcal{I}_{\\theta_A} (\\theta - \\theta_A)$\n",
        "\n",
        "$\\approx_{\\mathbb{P}} \\mathbb{E} \\log f_X(X_1; \\theta_A) - n_A 2^{-1} (\\theta - \\hat \\theta_A(X_A))^T \\hat{\\mathcal{I}}(X_A) (\\theta - \\hat \\theta_A(X_A))$\n",
        "\n",
        "Here, $n_A$ is the sample size of $X_A$. \n",
        "\n",
        "This approximation is not-yet useful, still depending on $\\theta_A$. \n",
        "So, we must apply it in maximum likelihood estimation to drop the $\\mathbb{E} \\log f_X(X_1; \\theta_A)$ term. \n",
        "Here, we add new data $X_B$ to the sample, while approximately retaining all information of $X_A$ \n",
        "in $T(X_A) = \\left(\\hat \\theta_A(X_A), \\hat{\\mathcal{I}}(X_A) \\right)$.\n",
        "\n",
        "$\\hat \\theta_B = \\arg\\max_\\theta f_X(X; \\theta) = \\arg\\max_\\theta \\log f_X(X_B; \\theta) + \\log f_X(X_A;\\theta) $\n",
        "\n",
        "$ \\approx_{\\mathbb{P}} \\arg\\max_\\theta \\log f_X(X_B; \\theta) $\n",
        "$+ \\mathbb{E} \\log f_X(X_1; \\theta_A) - n_A 2^{-1} (\\theta - \\hat \\theta_A(X_A))^T \\hat{\\mathcal{I}}(X_A) (\\theta - \\hat \\theta_A(X_A)) $\n",
        "\n",
        "$ = \\arg\\max_\\theta \\log f_X(X_B; \\theta) - n_A 2^{-1} (\\theta - \\hat \\theta_A(X_A))^T \\hat{\\mathcal{I}}(X_A) (\\theta - \\hat \\theta_A(X_A)) $\n",
        "\n",
        "We thus identify the universal SSR $2^{-1} (\\theta - \\hat \\theta_A(X_A))^T \\hat{\\mathcal{I}}(X_A) (\\theta - \\hat \\theta_A(X_A))$ \n",
        "and its regularization parameter _natural value_ $\\lambda = n_A$. \n",
        "\n",
        "Through the lens of SSRs, we find the regularization parameter $\\lambda$ is just a ratio of sample sizes. \n",
        "\n",
        "Note that the discovery of this particular regularizer is not novel \\[6\\], \n",
        "but recognizing that it approximates a sufficient statistic is."
      ],
      "metadata": {
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Miniaturization** \n",
        "\n",
        "Storing $\\hat \\theta(X_A)$ takes $O(p)$ space and $\\hat{\\mathcal{I}}(X_A)$ takes $O(p^2)$. \n",
        "So, while technically finite relative to $O(n)$, the sheer size of modern deep learning models \n",
        "makes any $O(p^2)$ storage requirement infeasible. \n",
        "So, this work will leverage a series of approximations that keep practically effective approximations \n",
        "to $\\mathcal{I}$ in $O(p)$. \n",
        "- The simplest approximation is only storing diagonal terms, and zeroing all others. \n",
        "- A better (but usually unnecessary) approach is leveraging a Krylov estimate to \n",
        "approximate the major eigenvectors of $\\mathcal{I}$. \n",
        "These are calculated via a modified version of the Lanczos algorithm described in Appendix A.\n",
        "\n",
        "Sufficient statistics have always been known to have this theoretically infinite storage property. \n",
        "This work merely modernizes the concept for today's massive models. \n",
        "\n",
        "These low-dimensional Fisher Information approximations provide a way to again yield sufficient statistics \n",
        "for deep learning in a computationally tractable way. \n",
        "However, the cheap cost of storage makes this technology valuable in specific contexts:\n",
        "- when miniaturization is important, \n",
        "- and when input data is larger than the $O(rp)$ sufficient statistic storage requirement. \n",
        "\n",
        "While SSR miniaturization is not immediately valuable to all deep learning approaches, \n",
        "it provides a framing which is useful for optimal efficiency in most deep RL applications. "
      ],
      "metadata": {
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## RL-adjusted CRLB\n",
        "\n",
        "As an RL agent learns from its environment, it tries new things and produces new kinds of data. \n",
        "Accepting that RL doesn't sample from identical distributions invites us to find an optimal transition paradigm. \n",
        "Interpreting _optimality_ as _efficiency_, this means working with the CRLB. \n",
        "Particularly, since maximum likelihood estimates (MLEs) from different distributions appear biased to another, \n",
        "we'll work with the mean squared error (MSE) form of the CRB. \n",
        "The strategy is simple: calculate the MSE under biased MLE deformations, and minimize it with respect to $\\lambda$. \n",
        "\n",
        "To recover a optimal $\\lambda$, we use the following definitions. \n",
        "- $X_A$ is the vector (or matrix) of observations having density $f_X(x; \\theta_A)$. \n",
        "- $X_B$ similarly has density $f_X(x; \\theta_B)$. \n",
        "- $\\hat \\theta_A = \\arg\\max_\\theta f_X(X_A; \\theta)$ is a simple MLE. \n",
        "- $\\hat \\theta_B = \\arg\\max_\\theta f_X(X_B; \\theta)$\n",
        "- $\\hat \\theta_{AB} = \\arg\\max_\\theta \\log f_X(X_B; \\theta) - \\lambda 2^{-1} (\\theta - \\theta_A)^T \\mathcal{I}_A (\\theta - \\theta_A) $ \n",
        "- $\\theta_{AB} = \\arg\\max_\\theta \\pi 2^{-1} (\\theta - \\theta_B)^T \\hat{\\mathcal{I}} (\\theta - \\theta_B) + (1 - \\pi) 2^{-1} (\\theta - \\theta_A)^T \\hat{\\mathcal{I}} (\\theta - \\theta_A)  $\n",
        "- $n_A = \\#A, n_B = \\#B, n = n_A + n_B$\n",
        "- $\\pi = \\lim_{n \\to \\infty} n_B/n$. WLOG, we assume this series converges so we may have $\\pi \\approx n_B/n$. \n",
        "\n",
        "WLOG, assume $\\mathcal{I} > 0$.\n",
        "\n",
        "We'll further assume $f_X$ smooth in $\\theta$ and $\\theta_A$ and $\\theta_B$ sufficiently near that they share approximately equivalent Hessians. \n",
        "So, $\\mathcal{I} \\approx n_B^{-1} \\nabla_\\theta^2 \\log f_X(X; \\theta_B) \\approx n_A^{-1} \\nabla_\\theta^2 \\log f_X(X; \\theta_A) $. \n",
        "After building-out Lemma 1, we'll see how this produces natural values for $\\mathcal{I}_B = \\pi \\mathcal{I}$ and $\\mathcal{I}_A = (1-\\pi) \\mathcal{I}$.\n",
        "\n",
        "Lemmas 1 and 4 will likely be considered trivial by some readers, but I'm keeping them to engage a wider audience. "
      ],
      "metadata": {
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Lemma 1: Double Taylor Series**\n",
        "\n",
        "**Lemma 1:** For smooth $f$, $g$, \n",
        "and $\\theta_A$ sufficiently near $\\theta_B$, $f(\\theta) + g(\\theta) \\approx T_k(f, \\theta_A, \\theta) + T_k(g, \\theta_B, \\theta)$, \n",
        "where $T_k(h, x, y)$ is a $k$-term Taylor series expansion around $x$ as a function of $y$. \n",
        "\n",
        "**Proof:** Since $f$ smooth, for all $\\varepsilon > 0$ \n",
        "there exists open neighborhood $\\Theta_A \\subset \\Theta$ around $\\theta_A$ \n",
        "such that $\\| T_k(f, \\theta_A, \\theta) - f(\\theta) \\| < \\varepsilon/2$, \n",
        "by Taylor's Theorem. \n",
        "\n",
        "Since $\\theta_B$ arbitrarily near $\\theta_A$, choose $\\theta_B \\in \\Theta_A$. \n",
        "Again by Taylor's Theorem, there exists $\\Theta_B \\subset \\Theta_A$ such that $\\theta_B \\in \\Theta_B$, \n",
        "and $\\| T_k(g, \\theta_B, \\theta) - f(\\theta) \\| < \\varepsilon/2$. \n",
        "\n",
        "So, $ \\| f(\\theta) + g(\\theta) - T_k(f, \\theta_A, \\theta) - T_k(g, \\theta_B, \\theta) \\|$\n",
        "$ \\leq \\| f(\\theta) - T_k(f, \\theta_A, \\theta) \\| + \\| g(\\theta) - T_k(g, \\theta_B, \\theta) \\| $\n",
        "$ \\leq \\varepsilon/2 + \\varepsilon/2 $.\n",
        "\n",
        "Thus, for all $\\theta \\in \\Theta_B$, our total approximation error does not exceed $\\varepsilon$, \n",
        "so $f(\\theta) + g(\\theta) \\approx T_k(f, \\theta_A, \\theta) + T_k(g, \\theta_B, \\theta)$. \n",
        "\n",
        "$\\square$"
      ],
      "metadata": {
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "To motivate our $\\mathcal{I}_{A,B} \\approx \\pi \\mathcal{I} + (1-\\pi)\\mathcal{I} = \\mathcal{I}_B + \\mathcal{I}_A$ assumption, \n",
        "start by recognizing that $\\mathcal{I} = \\mathcal{I}_{A,B} = \\mathcal{I}_B + \\mathcal{I}_A$ is generally true by independence of $X_B$ and $X_A$. \n",
        "However, discovering natural values for $\\mathcal{I}_B$ and $\\mathcal{I}_A$ requires we\n",
        "apply the Double Taylor Series expansion to the log likelihood estimate.\n",
        "\n",
        "$\\arg\\max_\\theta \\log f_X(X;\\theta) $ \n",
        "$= \\arg\\max_\\theta n^{-1} \\log f_X(X;\\theta) $ \n",
        "$= \\arg\\max_\\theta n^{-1} \\log f_X(X_B;\\theta) + n^{-1} \\log f_X(X_A;\\theta) $\n",
        "\n",
        "Apply Lemma 1 around $\\theta_B$ and $\\theta_A$. \n",
        "\n",
        "$ \\approx \\arg\\max_\\theta n^{-1} \\log f_X(X_B;\\theta_B) + n^{-1} (\\theta - \\theta_B)^T \\nabla_\\theta \\log f_X(X_B; \\theta_B) $\n",
        "$ + n^{-1} 2^{-1} (\\theta - \\theta_B)^T \\left( \\nabla_\\theta^2 \\log f_X(X_B; \\theta_B) \\right) (\\theta - \\theta_B) $\n",
        "$ + n^{-1} \\log f_X(X_A;\\theta_A) + n^{-1} (\\theta - \\theta_A)^T \\nabla_\\theta \\log f_X(X_A; \\theta_A) $\n",
        "$ + n^{-1} 2^{-1} (\\theta - \\theta_A)^T \\left( \\nabla_\\theta^2 \\log f_X(X_A; \\theta_A) \\right) (\\theta - \\theta_A) $\n",
        "\n",
        "Multiply by $1 = n_A/n_A = n_B/n_B$ and to line-up limits.\n",
        "\n",
        "$ \\approx \\arg\\max_\\theta n_B n^{-1} n_B^{-1} \\log f_X(X_B;\\theta_B) + n_B n^{-1} n_B^{-1} (\\theta - \\theta_B)^T \\nabla_\\theta \\log f_X(X_B; \\theta_B) $\n",
        "$ + n_B n^{-1} n_B^{-1} 2^{-1} (\\theta - \\theta_B)^T \\left( \\nabla_\\theta^2 \\log f_X(X_B; \\theta_B) \\right) (\\theta - \\theta_B) $\n",
        "$ + n_B n^{-1} n_B^{-1} \\log f_X(X_A;\\theta_A) + n_B n^{-1} n_B^{-1} (\\theta - \\theta_A)^T \\nabla_\\theta \\log f_X(X_A; \\theta_A) $\n",
        "$ + n_B n^{-1} n_B^{-1} 2^{-1} (\\theta - \\theta_A)^T \\left( \\nabla_\\theta^2 \\log f_X(X_A; \\theta_A) \\right) (\\theta - \\theta_A) $\n",
        "\n",
        "Apply the SLLN. The key observation is that we've assumed all Hessians average to the same value $\\mathcal{I}$, approximately.\n",
        "\n",
        "$ \\approx_{a.s.} \\arg\\max_\\theta \\pi \\mathbb{E} \\log f_X(X_{B_1};\\theta_B) + 0 $\n",
        "$ - \\pi 2^{-1} (\\theta - \\theta_B)^T \\mathcal{I} (\\theta - \\theta_B) $\n",
        "$ + (1-\\pi) \\mathbb{E} \\log f_X(X_{A_1};\\theta_A) + 0 $\n",
        "$ - (1-\\pi) 2^{-1} (\\theta - \\theta_A)^T \\mathcal{I} (\\theta - \\theta_A) $\n",
        "\n",
        "$ = \\arg\\max_\\theta - 2^{-1} (\\theta - \\theta_B)^T \\pi \\mathcal{I} (\\theta - \\theta_B) $\n",
        "$ - 2^{-1} (\\theta - \\theta_A)^T (1-\\pi) \\mathcal{I} (\\theta - \\theta_A) $\n",
        "\n",
        "$ = \\arg\\max_\\theta - 2^{-1} (\\theta - \\pi\\theta_B - (1-\\pi)\\theta_A)^T \\left( \\pi \\mathcal{I} + (1-\\pi) \\mathcal{I} \\right) (\\theta - \\pi\\theta_B - (1-\\pi)\\theta_A) $\n",
        "\n",
        "In the natural place of $\\mathcal{I}_B$ we find $\\pi \\mathcal{I}$. \n",
        "Similarly, we are free to take $\\mathcal{I}_A = (1-\\pi)\\mathcal{I}$. "
      ],
      "metadata": {
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Lemma 2: The small differences assumption**\n",
        "\n",
        "$\\theta_A$ and $\\theta_B$ need to quite close for our analysis to hold rigorously. \n",
        "They must be closer than our sample size is large. \n",
        "Mathematically, we assume WLOG that $\\theta_B - \\theta_A = O(n^{-s}), s > 1/2$, \n",
        "similar to Holder continuity. \n",
        "While technically useful, this assumption is counter-intuitive. \n",
        "After all, our parameters are not functions of our sample size. \n",
        "Fortunately, in application, $n$ is fixed by the time estimation occurs. \n",
        "So, we are free to assume that parameters are indeed progressing along some limit, \n",
        "but all sampling has simply occurred at the $n^{th}$ step, \n",
        "causing estimation to remain undisturbed.  \n",
        "\n",
        "This strange analytic tool has a practical interpretation: \n",
        "not only must $\\theta_t$ progress continuously in $t$, \n",
        "but also change slowly relative to $\\sqrt{n}$. \n",
        "\n",
        "**Lemma 2:** If $\\theta_B - \\theta_A = O(n^{-s}), s > 1/2$, then $\\sqrt{n}(\\hat \\theta_{AB} - \\pi\\theta_B - (1-\\pi)\\theta_A) \\to_D \\cdot$ \n",
        "and $\\sqrt{n}(\\hat \\theta_{AB} - \\theta_A) \\to_D \\cdot$. \n",
        "So, these limits exist, converging in distribution. \n",
        "\n",
        "**Proof:** First, we derive the limiting expected value. \n",
        "\n",
        "$\\hat \\theta_{AB} \\approx \\arg\\max_\\theta n^{-1} \\log f_X(X_B; \\theta) + n^{-1} \\log f_X(X_A; \\theta) $\n",
        "\n",
        "Apply Lemma 1 and the SLLN. \n",
        "\n",
        "$ \\approx \\arg\\max_\\theta -\\pi 2^{-1}(\\theta - \\theta_B)^T \\mathcal{I} (\\theta - \\theta_B) - (1-\\pi) 2^{-1}(\\theta - \\theta_A)^T \\mathcal{I} (\\theta - \\theta_A) $\n",
        "\n",
        "Optimized at $ 0 = \\nabla_\\theta \\left( - 2^{-1} (\\theta - \\theta_B)^T \\pi \\mathcal{I} (\\theta - \\theta_B) - 2^{-1} (\\theta - \\theta_A)^T (1-\\pi) \\mathcal{I} (\\theta - \\theta_A) \\right) $\n",
        "\n",
        "$ = - (\\theta - \\theta_B)^T \\pi \\mathcal{I} - (\\theta - \\theta_A)^T (1-\\pi) \\mathcal{I} $\n",
        "\n",
        "$ \\Leftrightarrow 0 = 0 \\mathcal{I}^{-1} = - (\\theta - \\theta_B)^T \\pi - (\\theta - \\theta_A)^T (1-\\pi) $\n",
        "$ = - \\theta^T + \\pi \\theta_B^T + (1-\\pi) \\theta_A^T $\n",
        "\n",
        "$ \\Rightarrow \\theta = \\pi \\theta_B + (1-\\pi) \\theta_A$.\n",
        "\n",
        "So, $\\mathbb{E}\\hat \\theta_{AB} \\approx \\pi \\theta_B + (1-\\pi) \\theta_A$ for $n$ large. \n",
        "\n",
        "Next, we use to exact definition of $\\hat \\theta_{AB}$ to recognize it's just an MLE constrained to an elliptical sub-manifold of $\\Theta$. \n",
        "\n",
        "$\\hat \\theta_{AB} = \\arg\\max_\\theta \\log f_X(X_B; \\theta) - \\lambda 2^{-1}(\\theta - \\theta_A)^T \\mathcal{I} (\\theta - \\theta_A)$ \n",
        "has a solution satisfying \n",
        "$0 = \\nabla_\\theta \\log f_X(X_B; \\theta) - \\lambda \\nabla_\\theta 2^{-1}(\\theta - \\theta_A)^T \\mathcal{I} (\\theta - \\theta_A) + 0 $\n",
        "$ = \\nabla_\\theta \\log f_X(X_B; \\theta) - \\lambda \\nabla_\\theta \\left( 2^{-1}(\\theta - \\theta_A)^T \\mathcal{I} (\\theta - \\theta_A) - c \\right) $, \n",
        "for some $c \\in \\mathbb{R}_{\\geq 0}$. \n",
        "\n",
        "Define $\\mathcal{L}(\\theta, \\lambda') := \\log f_X(X_B; \\theta) - \\lambda' \\left( 2^{-1}(\\theta - \\theta_A)^T \\mathcal{I} (\\theta - \\theta_A) - c \\right) $.  \n",
        "Notice that $\\lambda$ is a fixed value during estimation, so $\\lambda'$ is a parameter.\n",
        "\n",
        "Recognize that by construction, $\\nabla_\\theta \\mathcal{L}\\left(\\hat \\theta_{AB}, \\lambda \\right) $ \n",
        "$ = \\frac{\\partial}{\\partial \\lambda'} \\mathcal{L}\\left(\\hat \\theta_{AB}, \\lambda \\right) = 0 $. \n",
        "\n",
        "Thus, $\\mathcal{L}$ is the Lagrangian of an elliptically constrained parameter. \n",
        "Specifically, the sub-manifold is $H := \\{ \\theta \\in \\Theta \\; : \\; c = 2^{-1}(\\theta - \\theta_A)^T \\mathcal{I} (\\theta - \\theta_A) \\}$. \n",
        "\n",
        "So, $\\hat \\theta_{AB} = \\arg\\max_{\\theta \\in H} \\log f_X(X_B; \\theta) $ is just an MLE.\n",
        "\n",
        "Hence, $\\sqrt{n}(\\hat \\theta_{AB} - \\mathbb{E}\\hat \\theta_{AB})$ converges in distribution. \n",
        "\n",
        "Further, $\\sqrt{n}(\\hat \\theta_{AB} - \\theta_A) $\n",
        "$ = \\sqrt{n}(\\hat \\theta_{AB} - \\theta_A - \\mathbb{E}\\hat \\theta_{AB} + \\mathbb{E}\\hat \\theta_{AB})$\n",
        "$ \\approx \\sqrt{n}(\\hat \\theta_{AB} - \\theta_A - \\mathbb{E}\\hat \\theta_{AB} + \\pi \\theta_B + (1-\\pi) \\theta_A) $\n",
        "$ = \\sqrt{n}(\\hat \\theta_{AB} - \\mathbb{E}\\hat \\theta_{AB}) - \\pi \\sqrt{n}(\\theta_B - \\theta_A) $\n",
        "\n",
        "Apply the _small differences assumption_.\n",
        "\n",
        "$ = \\sqrt{n}(\\hat \\theta_{AB} - \\mathbb{E}\\hat \\theta_{AB}) - \\pi O(n^{1/2-s}) $ which converges in distribution because $O(n^{1/2-s}) \\to_{a.s} 0$.\n",
        "\n",
        "$\\square$"
      ],
      "metadata": {
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Lemma 3: Asymptotic behavior of $\\hat \\theta_{AB}$** \n",
        "\n",
        "The closed-form expected value and variance will be used in proving and demonstrating efficiency. \n",
        "\n",
        "**Lemma 3:** As $n \\to \\infty$, $\\hat \\theta_{AB} \\sim \\mathcal{N} \\left(\\pi \\theta_B + (1-\\pi) \\theta_A, \\pi \\mathcal{I}^{-1}/n \\right)$, \n",
        "provided $\\lambda = n_A$ and the _small differences assumption_ is met. \n",
        "\n",
        "**Proof:** Our proof strategy is very similar to that of MLE asymptotic normality. \n",
        "However, we'll need to construct a few additional limits converging to $\\pi$. \n",
        "As with other MLE asymptotic normality proofs, we start by recognizing $0 = \\nabla_\\theta \\log f_X(X_B; \\theta) - \\lambda (\\theta - \\theta_A)^T \\mathcal{I} $.\n",
        "\n",
        "$0 = n^{-1/2} \\nabla_\\theta \\log f_X(X_B; \\theta) - n^{-1/2} \\lambda (\\theta - \\theta_A)^T \\mathcal{I} $\n",
        "\n",
        "Apply Taylor series expansion of $\\nabla_\\theta \\log f_X(X_B; \\theta)$ around $\\theta_B$. \n",
        "\n",
        "$ \\approx n^{-1/2} \\nabla_\\theta \\log f_X(X_B; \\theta_B) + n^{-1/2} (\\theta -\\theta_B)^T \\nabla_\\theta^2 \\log f_X(X_B; \\theta_B) $\n",
        "$ - n^{-1/2} \\lambda (\\theta - \\theta_A)^T \\mathcal{I} $\n",
        "\n",
        "Prepare limits by multiplying by 1 and setting $\\lambda = n_A$. \n",
        "\n",
        "$ = \\sqrt{\\frac{n_B}{n}} n_B^{-1/2} \\nabla_\\theta \\log f_X(X_B; \\theta_B) + \\sqrt{n} \\frac{n_B}{n} (\\theta -\\theta_B)^T n_B^{-1} \\nabla_\\theta^2 \\log f_X(X_B; \\theta_B) $\n",
        "$ - \\sqrt{n} \\frac{n_A}{n} (\\theta - \\theta_A)^T \\mathcal{I} $\n",
        "\n",
        "Take $n \\to \\infty$ to produce 4 kinds of limit simultaneously: \n",
        "- $n_B/n \\to_{a.s.} \\pi$. \n",
        "- $n_B^{-1/2} \\nabla_\\theta \\log f \\to_D N_B \\mathcal{I}^{1/2}$ via CLT, where $N_B$ is a normally distributed variable. \n",
        "- $n_B^{-1} \\nabla_\\theta^2 \\log f \\to_{a.s.} -\\mathcal{I} $ via SLLN. \n",
        "- $\\sqrt{n}(\\theta - \\theta_B) \\to_D \\cdot$, by Lemma 2.\n",
        "\n",
        "All 4 of these limits can be combined with Slutksy's Theorem to produce convergence in distribution. \n",
        "\n",
        "$ \\Rightarrow \\lim_{n \\to \\infty} 0 $\n",
        "$ \\approx \\left( \\lim_{n \\to \\infty} \\sqrt{\\frac{n_B}{n}} \\right) $\n",
        "$ \\left( \\lim_{n \\to \\infty} n_B^{-1/2} \\nabla_\\theta \\log f_X(X_B; \\theta_B) \\right) $\n",
        "$ + \\left( \\lim_{n \\to \\infty} \\frac{n_B}{n} \\right) $\n",
        "$ \\left( \\lim_{n \\to \\infty} \\sqrt{n} (\\theta -\\theta_B)^T \\right) $\n",
        "$ \\left( \\lim_{n \\to \\infty} n_B^{-1} \\nabla_\\theta^2 \\log f_X(X_B; \\theta_B) \\right) $\n",
        "$ - \\left( \\lim_{n \\to \\infty} \\frac{n_A}{n} \\right) $\n",
        "$ \\left( \\lim_{n \\to \\infty} \\sqrt{n} (\\theta - \\theta_A)^T \\right) \\mathcal{I} $ \n",
        "\n",
        "$ \\approx_D \\sqrt{\\pi} N_B \\mathcal{I}^{1/2} - \\lim_{n \\to \\infty} \\sqrt{n} \\pi (\\theta - \\theta_A)^T \\mathcal{I} - \\lim_{n \\to \\infty} \\sqrt{n} (1-\\pi) (\\theta - \\theta_A)^T \\mathcal{I} $\n",
        "\n",
        "$ \\Rightarrow \\lim_{n \\to \\infty} \\sqrt{n} (\\theta - \\pi \\theta_B - (1-\\pi) \\theta_A) \\approx_D \\sqrt{\\pi} N_B \\mathcal{I}^{-1/2} $\n",
        "\n",
        "$ \\square $"
      ],
      "metadata": {
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Lemma 4: Multivariate CRLB**\n",
        "\n",
        "**Lemma 4:** For $\\hat \\theta \\in \\mathbb{R}^p, \\text{Cov}(\\hat \\theta) \\geq \\mathcal{I}^{-1}/n$.\n",
        "\n",
        "**Proof:** WLOG, take $n = 1$. \n",
        "\n",
        "Let $\\text{Cov}(\\hat \\theta) = \\Sigma = P \\Lambda P^T$, \n",
        "where $P$ orthogonal and $\\Lambda$ diagonal. \n",
        "\n",
        "Take $\\eta: \\Theta \\to H \\subset \\mathbb{R}^p$ as $\\eta(\\theta) = P^{-1} \\theta = P^T \\theta$, \n",
        "so $\\eta^{-1}(\\eta) = \\theta(\\eta) = P \\eta$. \n",
        "\n",
        "Use $\\eta$ to map $\\hat \\theta$ from $\\Theta$ to an uncorrelated space $H$. \n",
        "\n",
        "Thus, $\\text{Cov}(\\eta(\\hat \\theta)) = \\text{Cov}(P^T \\hat \\theta) = P^T \\text{Cov}(\\hat \\theta) P = P^T P \\Lambda P^T P = \\Lambda $. \n",
        "\n",
        "Now apply the univariate CRLB element-wise to the diagonal of $\\Lambda$ to get the minimum variance of our uncorrelated estimate $\\eta(\\hat \\theta)$. \n",
        "So, $\\Lambda \\geq \\mathcal{I}^{-1}_H$. \n",
        "\n",
        "To get the associated information matrix in $\\Theta$-space, apply the inverse transform on $H$-space. \n",
        "This transforms the Hessian $\\mathcal{I}_H$ with Jacobian $J = P$.\n",
        "\n",
        "$ \\mathcal{I}^{-1} = \\mathcal{I}_\\Theta^{-1} = \\left( J \\mathcal{I}_H J^T \\right)^{-1} $\n",
        "$ = \\left( P \\mathcal{I}_H P^T \\right)^{-1} = P \\mathcal{I}_H^{-1} P^T $\n",
        "$ \\leq \\text{Cov}\\left( \\theta( \\eta( \\hat \\theta)) \\right) = \\text{Cov}(\\hat \\theta)$. \n",
        "\n",
        "$ \\square $"
      ],
      "metadata": {
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**RL-adjusted CRLB (RL-CRLB)** \n",
        "\n",
        "**Result:** $\\mathbb{E}\\| \\hat \\theta_{AB} - \\theta_B \\|^2 \\gtrsim \\pi \\text{tr}[\\mathcal{I}^{-1}]/n + (1-\\pi)^2 \\| \\theta_B - \\theta_A \\|^2$, \n",
        "minimized over $\\pi$ when $ n_A \\approx n(1-\\pi) = \\text{tr}\\left[\\mathcal{I}^{-1}\\right]/ \\left(2 \\| \\theta_B - \\theta_A \\|^2 \\right) $. \n",
        "\n",
        "**Proof:** Before studying the mean squared error (MSE) $\\mathbb{E}\\| \\hat \\theta_{AB} - \\theta_B \\|^2$, we start with the matrix form, say $E$ for \"error\". \n",
        "\n",
        "$ E = \\mathbb{E}(\\hat \\theta_{AB} - \\theta_B)(\\hat \\theta_{AB} - \\theta_B)^T $\n",
        "\n",
        "Add $0 = \\mathbb{E} \\hat \\theta_{AB} - \\mathbb{E} \\hat \\theta_{AB}$\n",
        "\n",
        "$ = \\text{Cov}\\hat \\theta_{AB} + 0 + (\\mathbb{E} \\hat \\theta_{AB} - \\theta_B)(\\mathbb{E} \\hat \\theta_{AB} - \\theta_B)^T $\n",
        "\n",
        "Apply the Multivariate CRLB (Lemma 4) on transformed space $\\mathbb{E} \\hat \\theta_{AB} (\\Theta)$.\n",
        "\n",
        "$ \\geq \\left( \\nabla_{\\theta_B} \\mathbb{E}\\hat \\theta_{AB} \\right)^T \\mathcal{I}_B^{-1} n^{-1} \\left( \\nabla_{\\theta_B} \\mathbb{E}\\hat \\theta_{AB} \\right) $\n",
        "$ + (\\mathbb{E} \\hat \\theta_{AB} - \\theta_B)(\\mathbb{E} \\hat \\theta_{AB} - \\theta_B)^T$\n",
        "\n",
        "By assumption of $\\theta_B$ near $\\theta_A$, $\\mathcal{I}_B \\approx \\pi \\mathcal{I}$.\n",
        "\n",
        "$ \\approx \\left( \\nabla_{\\theta_B} \\mathbb{E}\\hat \\theta_{AB} \\right)^T \\pi^{-1} \\mathcal{I}^{-1} n^{-1} \\left( \\nabla_{\\theta_B} \\mathbb{E}\\hat \\theta_{AB} \\right) $\n",
        "$ + (\\mathbb{E} \\hat \\theta_{AB} - \\theta_B)(\\mathbb{E} \\hat \\theta_{AB} - \\theta_B)^T$\n",
        "\n",
        "Apply $\\mathbb{E} \\hat \\theta_{AB} \\approx \\pi \\theta_B + (1-\\pi) \\theta_A$ from Lemma 3.\n",
        "\n",
        "$ \\approx \\pi \\mathcal{I}^{-1} n^{-1} + (1-\\pi)^2 (\\theta_B - \\theta_A)(\\theta_B - \\theta_A)^T $\n",
        "\n",
        "$ \\Rightarrow \\mathbb{E}\\| \\hat \\theta_{AB} - \\theta_B \\|^2 = \\text{tr}[E] $\n",
        "$ \\gtrsim \\pi \\text{tr}[\\mathcal{I}^{-1}]/n + (1-\\pi)^2 \\| \\theta_B - \\theta_A \\|^2 $\n",
        "\n",
        "Find the critical point in $\\pi$ for optimality over $\\pi$. \n",
        "\n",
        "$ 0 = \\frac{\\partial}{\\partial \\pi} \\left( \\text{tr} \\left[ \\pi \\mathcal{I}^{-1} \\right]/n - 2(1-\\pi) \\| \\theta_B - \\theta_A \\|^2  \\right) $\n",
        "\n",
        "$ \\Rightarrow  1-\\pi = \\text{tr}\\left[\\mathcal{I}^{-1}\\right]/(2 n \\| \\theta_B - \\theta_A \\|^2) $. \n",
        "\n",
        "$ \\Rightarrow \\lambda = n_A \\approx n(1-\\pi) = \\text{tr}\\left[\\mathcal{I}^{-1}\\right]/(2 \\| \\theta_B - \\theta_A \\|^2) $\n",
        "\n",
        "$\\square$\n",
        "\n",
        "Leveraging Lemma 3, notice that this makes $\\hat \\theta_{AB}$ efficient under the RL-adjusted paradigm of estimation. \n",
        "Rigorously, $\\mathbb{E} \\| \\hat \\theta_{AB} - \\theta_B \\|^2 \\approx \\pi \\text{tr}[\\mathcal{I}^{-1}]/n + (1-\\pi)^2 \\| \\theta_B - \\theta_A \\|^2 $. \n",
        "Of course, normally the definition of efficiency assumes consistency, \n",
        "but in this context of mixing distributions, bias should be accommodated. \n",
        "So, we interpret \"efficient\" as \"minimizing MSE\"."
      ],
      "metadata": {
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Bring it all together**\n",
        "\n",
        "This work derives SSRs before producing the RL-CRLB, \n",
        "because it provides an applied context. \n",
        "The RL-CRLB only provides an optimal value for $\\pi$, say $\\hat \\pi$. \n",
        "This optimality can drive impact by informing us of the optimal value for our regularization term $\\lambda$. \n",
        "After all, SSR derivation shows $\\lambda$ acts equivalently to $n_A$. \n",
        "Thus, we are free to choose a $\\hat \\lambda$ which corresponds to $\\hat \\pi$ \n",
        "by taking $\\hat \\lambda = n(1 - \\hat \\pi) = \\text{tr}\\left[\\mathcal{I}^{-1}\\right]/\\left(2 \\| \\hat\\theta_B - \\hat\\theta_A \\|^2 \\right) $. \n",
        "Assuming our sample sizes $n_A$ and $n_B$ are sufficiently large that $\\hat \\theta_A$, $\\hat \\theta_B$, and \n",
        "$\\hat{\\mathcal{I}}$ are accurate, \n",
        "we are free to adjust $\\pi$ to optimal by using $\\hat \\lambda$. \n",
        "So, choosing $\\lambda = \\hat \\lambda$ \n",
        "causes $\\hat \\theta_{AB}$ to have optimally minimal MSE. "
      ],
      "metadata": {
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Experiments\n",
        "\n",
        "TODO: re-run experiments with correct $\\hat \\lambda$ value. "
      ],
      "metadata": {
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Experimental result 1: Q-Learning Cart Pole**\n",
        "\n",
        "This initial experiment demonstrates the effectiveness of SSRs, \n",
        "and studies the behavior of $\\| \\theta_A - \\theta_B \\|^2_F$ near the solution point. \n",
        "The experiment is kept purposefully simple to isolate experimental effects. \n",
        "We apply a [small deep net](https://github.com/wdurno/notebooks/commit/8e20a0ec7a5c2376b954d2a04a930064e8e77f69#diff-9067e1aea905e3792706d011ba5a0007ba0147bbc9f8b02e76a0b9b07acbd13d) \n",
        "to [Cart Pole with a 4-dimensional state space](https://www.gymlibrary.dev/environments/classic_control/cart_pole/). \n",
        "\n",
        "Experimental conditions are \n",
        "\n",
        "1. SSRs are applied with $\\lambda = n_B$. The observation cache is entirely cleared after each memorization event.\n",
        "2. SSRs are applied with approximately optimal $\\lambda = \\hat \\lambda = n_B (\\theta_A - \\theta_B)^T \\hat{\\mathcal{I}} (\\theta_A - \\theta_B)$. Since $\\theta_A$ is never known, we use the $\\theta_A - \\theta_B$ difference from the prior memorization event. The observation cache is entirely cleared after each memorization event.\n",
        "3. SSRs are applied with $\\lambda = \\hat \\lambda / 10$. The observation cache is entirely cleared after each memorization event.\n",
        "4. SSRs are applied with $\\lambda = \\hat \\lambda * 10$. The observation cache is entirely cleared after each memorization event. \n",
        "5. Control: No SSRs are applied, but the observation cache is cleared at moments coinciding with each memorization event. \n",
        "6. Control: No SSRs are applied, and observations caches are entirely retained. \n",
        "\n",
        "**TODO:** clean-up this graphic: axes, title, number conditions \n",
        "\n",
        "In the below graphic, the x-axis tracks the game iteration, \n",
        "and the y-axis tracks average game score over 1000 agents. \n",
        "Agents restart their games when they lose and during memorization events. \n",
        "Three memorization events can clearly be seen in the graph.\n",
        "\n",
        "![cart pole](./data/df-experiment-22.png)\n",
        "\n",
        "\n",
        "This graphic clearly supports the optimality of the SSR method in RL applications. \n",
        "Lift is clearly more-efficient, as the method uses data most-efficiently. \n",
        "Better yet, the method enjoys the miniaturization benefits of storing any amount of data in an $O(p)$ space. \n",
        "\n",
        "It can be seen that the lagged estimate of $\\hat \\lambda$ is decently accurate, \n",
        "but so is taking $\\hat \\lambda = 1$ even during early gameplay. \n",
        "\n",
        "Also note that miniaturization benefits are evident. \n",
        "The agent with SSR (no memory) and discarding data is the lowest performer. \n",
        "In this way, we see the benefit of a long memory. \n",
        "Further, we see the SSR (memory) providing its mathematically guaranteed memory equivalent, \n",
        "but in a miniaturized form. "
      ],
      "metadata": {
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Experimental result 2: robotics**\n",
        "\n",
        "This work's sufficiency and efficiency results are asymptotic results, \n",
        "so are theoretically valid for a large breadth of models. \n",
        "So, the sufficiency and efficiency should be demonstrated in another game beyond Cart Pole.\n",
        "Further, sufficiency and efficiency are particularly useful toward robotics, \n",
        "this new game is played by a real-world robot. \n",
        "\n",
        "The robot is a PiCar V \\[1\\] wheeled robot with articulated camera, \n",
        "capable of driving forward & backward, turning left & right, \n",
        "and looking up, forward, left & right. \n",
        "Video processing and servo articulation is processed by an on-board Raspberry Pi 4B.\n",
        "\n",
        "![robot](./data/robot.jpg)\n",
        "\n",
        "This PiCar is customized to minimize on-board processing, \n",
        "instead running [this](https://github.com/wdurno/picar-v-rl-env/blob/1d5f5e15b390ef7cceae3fbe8875f71fbc76995f/run_api.py) server, offloading deep net processing to \n",
        "[this](https://github.com/wdurno/notebooks/blob/814f7cfed779fc4990f770b20a5ad924fbd7c693/regularizers-as-memory/car.py)\n",
        "GPU-accelerated client. \n",
        "\n",
        "Similar to the out-of-the-box [software](https://github.com/sunfounder/SunFounder_PiCar-V/blob/master/ball_track/ball_tracker.py), \n",
        "the RL game is to chase a red ball and have the agent get close to it, \n",
        "confirming the presence visually. \n",
        "Experiments were conducted in the same household office, \n",
        "under near-consistent lighting conditions. \n",
        "\n",
        "Three experiments were run.\n",
        "\n",
        "1. (Control) standard Q-Learning, retaining all data in the memory buffer \n",
        "2. (Experimental 1) Using memorization, clearing the memory buffer after each memorization, \n",
        "using $\\hat \\lambda_t = (\\hat \\theta_{t} - \\hat \\theta_{t-1})^T \\hat{\\mathcal{I}}(\\hat \\theta_{t} - \\hat \\theta_{t-1}) $, where $\\hat{\\mathcal{I}}$ is estimated with a Krylov rank of 10 (see Appendix A).\n",
        "Memorization occurs 40 times.\n",
        "3. (Experimental 2) Same as experimental 1, but with $\\hat \\lambda = 1$ for every iteration.\n",
        "\n",
        "Data were all sampled by an agent following experimental condition 2.\n",
        "All three experimental conditions used the same datasets, \n",
        "with the agent being exposed to data in the same order it was sampled. \n",
        "Thus, this was an offline RL experiment. \n",
        "Since optimal offline RL metrics are unclear \\[2\\], \n",
        "we simply use expected discounted reward per batch at teach time step. \n",
        "\n",
        "![robot metrics](./data/df-experiment-24.png)\n",
        "\n",
        "As can be seen, this new game has exceptional results when \n",
        "SSRs are applied and $\\hat \\lambda$ is projected. \n",
        "This illustrates the potential for universal effectiveness of SSR efficiency. \n",
        "Further,  $\\hat \\lambda = 1 = n_A/n_B$ continues to be an adequate value. "
      ],
      "metadata": {
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Experimental result 3: actor-critic Cart Pole**\n",
        "\n",
        "Actor-critic methods feature actor and critic deep nets which co-evolve, \n",
        "effectively causing either models' regression target to move slowly. \n",
        "Interpreting this slow movement as continuity, \n",
        "we are free to apply the RL-CRLB. \n",
        "\n",
        "In this experiment, we modify Cart Pole to have a continuous action space \n",
        "thereby making actor-critic methods applicable. \n",
        "Instead of having the agent choose between two actions (left or right), \n",
        "we have the actor choose $\\mathbb{P}[\\text{left}] = 1 - \\mathbb{P}[\\text{right}]$. \n",
        "As programmed [here](https://github.com/wdurno/notebooks/blob/ccb0b401d4111e711868f997624442f07c8ef92b/regularizers-as-memory/regmem_ac.py), \n",
        "- in the _experimental condition_ both models get their own SSR which is updated every 500 game steps; \n",
        "- in the _control condition_, no SSRs were used; \n",
        "- 20000 game steps were observed, restarting games whenever they are done; \n",
        "- scores represent the average of 1000 control and 1000 experimental agents. \n",
        "\n",
        "The data illustrate how efficient RL estimates with RL-CRLB regularization generates metric lift through optimally-efficient utilization of data. \n",
        "\n",
        "![actor critic cart pole](./data/df-experiment-27.png)"
      ],
      "metadata": {
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Experimental result 4: GPT 2 Tuning**\n",
        "\n",
        "TODO Now that I've proven RL-CRLB applies to actor-critic methods, I am comfortable proceeding into this experiment.  \n",
        "\n",
        "This approach should involve a continuous transition from a language model loss to a reinforcement learning loss. \n",
        "My theory shows this transition to be optimal at each infinitesimal step in the path. \n",
        "Since the action space is large, an Actor-Critic (AC) approach is needed. \n",
        "\n",
        "As is, the AC paradigm is not sufficiently build-out from a probabilistic perspective to \n",
        "immediately activate classical statistical theory \\[18\\]. Let's quickly solve that \n",
        "problem here.\n",
        "\n",
        "AC models accommodate a large action space by adjusting probabilities $p$ of actions \n",
        "$a_t$ given state $s_t$, written as $p(a_t|s_t; \\theta)$. \n",
        "The choice action is selected at random, according to its probability. \n",
        "Further, to enable Bellman equation estimation, the estimated state value \n",
        "$\\hat V(s_t; \\theta)$ is fit to the observed, discounted value \n",
        "$V(s_t) = \\sum_{s=t}^T \\gamma^s r_s$. \n",
        "\n",
        "The loss is $\\ell = \\ell_{actor} + \\ell_{critic}$, where \n",
        "- $\\ell_{actor} = - \\sum_t^T (V(s_t) - \\hat V(s_t)) \\log p(a_t|s_t; \\theta) $, where $V(s_t) = V(s_t; \\theta)$ is at a fixed value of $\\theta$. \n",
        "- $\\ell_{critic} = L(V(s_t), \\hat V(s_t; \\theta))$, where $L$ is any convex loss with a unique, unbiased minimum. \n",
        "\n",
        "Assume $\\hat \\theta = \\arg\\min_\\theta \\ell(s_t;\\theta)$ exists uniquely, \n",
        "$s_t$ are Markovian over $t$, \n",
        "and $C = \\int_{s_t} e^{-\\ell(s_t;\\theta)} \\in \\mathbb{R}_{>0}$.\n",
        "Then $\\hat \\theta = \\arg\\max_\\theta e^{-\\ell(s_t;\\theta)}C^{-1} $ is an MLE\n",
        "for $s_t \\sim e^{-\\ell(s_t;\\theta)}C^{-1}$.\n",
        "So, by applying minor regularity assumptions, \n",
        "our loss is equivalent to a log likelihood, thereby activating my RL-CRLB theory. \n",
        "\n",
        "Since $V(s_t)$ is not a function of action $a_t$, it is really the projected value \n",
        "of the chosen action. Of course, the chosen action \n",
        "changes as the model is fit, so sampled data ages poorly. Ultimately, data re-use \n",
        "doesn't work for AC models. This requires data not be re-used after models use it for \n",
        "fitting. This challenges SSR calculation, which works best by recalculating gradients \n",
        "at $\\hat \\theta_B$. So, SSR calculation must be done near-continuously. Unfortunately, \n",
        "I've failed to do this so far, despite trying. I fear that applying AC and thus \n",
        "meaningfully tuning LLMs with RL will depend on me solving this problem first. \n",
        "So, I hope to solve my challenges in this order:\n",
        "\n",
        "1. Solve continuous SSR calculation for Q Learning. \n",
        "2. Demonstrate continuous SSR calculation with AC Cart Pole. \n",
        "3. Apply SSRs to AC-tuned LLMs. "
      ],
      "metadata": {
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Discussion "
      ],
      "metadata": {
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**When is RL-CRLB efficiency useful?** \n",
        "\n",
        "My efficiency result is likely immediately applicable to all RL applications, \n",
        "and any situations where sampling distributions drift slowly and continuously. \n",
        "This represents a most-optimal opportunity for all RL applications with enough data.\n",
        "\n",
        "This all depends heavily on the assumption that $\\text{MSE}(\\hat \\theta_{AB}) < \\text{MSE}(\\hat \\theta_B)$, \n",
        "which is very likely to occur when incremental sample sizes $n_B$ are small relative to the aggregate sample. \n",
        "This is what makes RL a prime target for application. "
      ],
      "metadata": {
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**What do likelihoods have to do with deep nets?**\n",
        "\n",
        "TODO a lot, lol "
      ],
      "metadata": {
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**How efficient do we need to be?**\n",
        "\n",
        "TODO: Simulations vs real world"
      ],
      "metadata": {
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Are these approximations rigorous?** \n",
        "\n",
        "TODO "
      ],
      "metadata": {
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**When will SSR miniaturization be useful?**\n",
        "\n",
        "The miniaturization benefits of SSRs in deep learning will not likely be useful until \n",
        "we start pursuing more-ambitious forms of data. \n",
        "Right now, we're spending millions on fitting language models on text data, \n",
        "so it is likely that miniaturization will be necessary for similarly-effective results \n",
        "on more-complex data. \n",
        "Imagine the sheer networking logistics required to handle exabytes of high-resolution \n",
        "video data. \n",
        "In that context, the $O(p)$ storage requirement, while definitely massive, \n",
        "is absolutely far more feasible than the $O(n)$ alternative without sufficient statistics. \n",
        "In this work, I've managed with $O(p) \\approx 10p$. \n",
        "So, when our datasets become 10 times larger than our models, \n",
        "we may perhaps begin considering SSRs in practical application.\n",
        "\n",
        "If you are unsure whether this will ever occur, consider the alternative. \n",
        "If $p \\gtrsim O(n)$ for all $n$, then we are forever fitting more parameters to fewer data. \n",
        "This is likely to result in over-fit and no interpolation. \n",
        "Such agents will never have any depth of understanding. "
      ],
      "metadata": {
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Why only optimize $\\pi$?** \n",
        "\n",
        "There is so much more work to do in the vast complexity of $\\mathcal{I}$. \n",
        "In the RL-CRLB equation $\\pi \\text{tr}[\\mathcal{I}^{-1}]/n + (1-\\pi)^2 \\| \\theta_B - \\theta_A \\|^2$, \n",
        "my choice to target $\\pi$ is largely one of convenience. \n",
        "Information Geometry \\[17\\] invites a deep exploration of metrics and model selection. \n",
        "Alternatively, one might explore strategies to optimally transport information \n",
        "from $\\theta_A$ to $\\theta_B$ over larger neighborhoods. \n",
        "Large neighborhoods are valuable, because they may free us from the _small differences assumption_, \n",
        "and allow this work's theory to contribute to _transfer learning_ meaningfully. \n",
        "For example, information may be optimally shared between two very different models. \n",
        "\n",
        "Further, it is likely that Information Geometry is the natural language of RL, \n",
        "because estimate covariance is a function of the statistical manifold's local tangent space, \n",
        "and this work phrases RL as traversal of paths on the manifold. \n",
        "The essential task is ensuring that traversal occurs most-efficiently. "
      ],
      "metadata": {
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**$n_A \\approx \\text{tr}\\left[\\mathcal{I}^{-1}\\right]/\\left(2 \\| \\hat\\theta_B - \\hat\\theta_A \\|^2 \\right)$ isn't an integer**\n",
        "\n",
        "In the era of big data, sample size matters far less, and information geometry matters far more. \n",
        "This work optimally combines information with no regard to the actual observed sample sizes. \n",
        "It is merely assumed that sample sizes are large enough to meet asymptotic normality requirements. \n",
        "\n",
        "As a motivating thought experiment, consider the following normally distributed data and imagine our task is to estimate $\\mu$. \n",
        "\n",
        "$$ \\begin{bmatrix} X \\\\ Y \\end{bmatrix} \\sim \\mathcal{N}\\left( \\begin{bmatrix} \\mu \\\\ \\mu \\end{bmatrix}, \\begin{bmatrix} 1 & \\rho \\\\ \\rho & 1 \\end{bmatrix} \\right) $$\n",
        "\n",
        "The Fisher Information $\\mathcal{I}_{\\mu \\mu} = 2(1 - \\rho)/(1 - \\rho^2)$ indicates that \n",
        "an efficient estimate will have variance $\\text{Var}(\\hat \\mu) = n^{-1}2^{-1}(1 - \\rho^2)/(1-\\rho)$. \n",
        "Take note of these 3 informative values:\n",
        "- $\\text{Var}(\\hat \\mu) \\to 0$ as $\\rho \\to -1$. So, only a single sample is needed to produce an accurate estimate when $\\rho \\approx -1$. \n",
        "- $\\text{Var}(\\hat \\mu) = (2n)^{-1}$ when $\\rho = 0$. So, only half as much data is needed to produce an accurate estimate when our dimensions are uncorrelated. \n",
        "- $\\text{Var}(\\hat \\mu) \\to 1/n$ as $\\rho \\to 1$. So, there is no efficiency premium when $\\rho \\approx 1$. \n",
        "\n",
        "Notice how $\\mathcal{I}$ structure strongly dictates sampling needs. \n",
        "By being sensitive to these opportunities, we can drop sampling requirements.\n",
        "If we are interested in using our data more efficiently, \n",
        "we can leverage opportunities like this more. \n",
        "This work takes a step in that direction by entirely disregarding actual sample sizes $n_A$ and $n_B$, \n",
        "and instead choosing such values optimally. \n",
        "It's not about sample size; it's about the shape of our information. "
      ],
      "metadata": {
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Better ways to estimate $\\hat{\\mathcal{I}}$**\n",
        "\n",
        "I'm using a method-of-moments estimate for my sufficient statistic $\\hat{\\mathcal{I}}$. \n",
        "There's a good chance you can do better. \n",
        "Your estimate need only be positive semi-definite. \n",
        "Conveniently, this can be obtained by estimating any $LL^T + \\Lambda$ form. \n",
        "For example, perhaps there is an ideal neural network architecture for estimating $L$. \n",
        "\n",
        "Similarly, my $(\\theta_B - \\theta_A)$ projection methods have been incredibly naive. \n",
        "There is plenty of room here to treat SSR estimation as an entirely parallel problem \n",
        "to model fitting. "
      ],
      "metadata": {
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Why not continuously integrate data into memory?**\n",
        "\n",
        "In experiment 1, we saw data memorized infrequently at clear punctuated times. \n",
        "The result is a very \"choppy\" progression of metrics. \n",
        "I do this because theoretical deduction is my guide in picking high-value experimental targets. \n",
        "I've stuck close to my theory and only aggregated information once asymptotic sample sizes were clearly met. \n",
        "This doesn't mean opportunities don't exist. \n",
        "This is an opportunity for both empirical and theoretical study. \n",
        "\n",
        "On the empirical front, it is worthwhile to study practical ways to continuously integrate data into memory (SSRs). \n",
        "The challenge will be maintaining competitive metrics, \n",
        "because deviation from asymptotic assumptions will cause results to degrade. \n",
        "\n",
        "On the theoretical front, it is worth asking why I only combine two points in $\\Theta$ at a time. \n",
        "For example, we may construct a mixture of 3 points $\\hat \\theta_{ABC} = \\pi_A \\theta_A + \\pi_B \\theta_B + \\pi_C \\theta_C$. Or, perhaps we pursue truly continuous integration and choose infinitely many \n",
        "points with a stochastic integral $\\hat \\theta = \\int \\hat \\theta_t \\pi_t dt$.\n",
        "Again, the challenge will be in ensuring that the distribution of $\\hat \\theta_t$ is truly known. \n",
        "Are the samples truly asymptotic in size? \n",
        "What does that even mean if every observation is immediately integrated?"
      ],
      "metadata": {
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Transfer learning**\n",
        "\n",
        "Assuming $\\theta_A$ and $\\theta_B$ are sufficiently near, \n",
        "this work provides theory for optimally combining information between two models. \n",
        "This is transfer learning on an infinitesimal scale. \n",
        "Reapplying the method along path $\\Theta_T = \\{\\theta_t\\}_{t \\in [0,1]} $, \n",
        "we obtain an optimized version of transfer learning as it's normally understood. \n",
        "There is likely more work required to efficiently transport information \n",
        "along non-infinitesimal paths. \n",
        "However, since this is a noisy walk on a sometimes billion-dimensional manifold, \n",
        "we may need to settle for heuristics. \n",
        "\n",
        "TODO finish experiment 4"
      ],
      "metadata": {
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Conclusion\n",
        "\n",
        "This work has derived the sufficient statistic regularizer (SSR) as a means to miniaturize models \n",
        "leveraging truly massive datasets, \n",
        "and has derived the reinforcement learning-adjusted Cramer Rao Lower Bound (RL-CRLB) \n",
        "which proves how to most-optimally utilize data in a reinforcement learning (RL) context. \n",
        "While the SSR miniaturization result is likely to only yield impact in the future, \n",
        "the RL-CRLB efficiency result is likely to deliver immediate impact to RL. \n",
        "Results are derived mathematically, then demonstrated experimentally. \n",
        "The paradigm deviates significantly from the classical statistics foundations of AI, \n",
        "violating the identical distribution assumption, \n",
        "yet still provides a mathematically coherent approach to combining such data. \n",
        "The overall result is a step away from experimentalist statistics as a foundation for AI, \n",
        "and toward the mathematical needs of AI. \n",
        "Particularly, this work accommodates the AI agent's ability to learn and change its sampling distribution accordingly. "
      ],
      "metadata": {
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## References \n",
        "\n",
        "\\[1\\] https://www.sunfounder.com/products/smart-video-car\n",
        "\n",
        "\\[2\\] Romain Deffayet, Thibaut Thonet, Jean-Michel Renders, & Maarten de Rijke (2022) \"Offline Evaluation for Reinforcement Learning-based Recommendation: A Critical Issue and Some Alternatives\", ACM SIGIR Forum, Vol. 56 No. 2. \n",
        "\n",
        "\\[3\\] Alexei Krylov (1931). On the numerical solution of equations whose solution determine the frequency of small vibrations of material systems. _Izv. Akad. Nauk. SSSR Otd Mat. Estest, 1, 491-539._ \n",
        "\n",
        "\\[4\\] Cornelius Lanczos (1950). An iteration method for the solution of the eigenvalue problem of linear differential and integral operators. _Journal of Research of the National Bureau of Standards_. 45 (4): 255–282. doi:10.6028/jres.045.026 \n",
        "\n",
        "\\[5\\] Ryo Karakida, Shotaro Akaho,  Shun-ichi Amari (2019). Universal Statistics of Fisher Information in Deep Neural Networks: Mean Field Approach. _arXiv_: 1806.01316v3.\n",
        "\n",
        "\\[6\\] Kirkpatrick et al. (2017) \"Overcoming catastrophic forgetting in neural networks\", PNAS, Vol. 114, No. 13.\n",
        "\n",
        "\\[7\\] Knight, Will. \"OpenAI's CEO Says the Age of Giant AI Models Is Already Over\". Wired. www.wired.com.\n",
        "\n",
        "\\[8\\] R. A. Fisher (1922) \"On the mathematical foundations of theoretical statistics\", The Royal Society, ISSN 0264-3952, eISSN 2053-9258. \n",
        "Retrieved from [https://royalsocietypublishing.org/doi/10.1098/rsta.1922.0009](https://royalsocietypublishing.org/doi/10.1098/rsta.1922.0009)\n",
        "on 1 Jan 2024. \n",
        "\n",
        "\\[9\\] David Silver, Satinder Singh, Doina Precup, Richard S. Sutton (2021) \"Reward is Enough\", Artificial Intelligence, https://doi.org/10.1016/j.artint.2021.103535.\n",
        "\n",
        "\\[10\\] James Kirkpatrick, Razvan Pascanu, Neil Rabinowitz, Raia Hadsell, et al. (2017) \"Overcoming catastrophic forgetting in neural networks\", PNAS, 114 (13), 3521-3526.\n",
        "\n",
        "\\[11\\] Yann LeCun, John Denker, Sara Solla (1990) \"Optimal Brain Damage\", Advances in Neural Information Processing Systems 2 (NIPS 1989).\n",
        "\n",
        "\\[12\\] Richard E. Bellman (1957) \"Dynamic Programming\", Princeton University Press, Princeton, New Jersey.\n",
        "\n",
        "\\[13\\] D. A. S. Fraser (1963) \"On Sufficiency and the Exponential Family\", Vol. 25, No. 1, pp. 115-123.\n",
        "\n",
        "\\[14\\] Herald Cramer (1946) \"Mathematical Methods Of Statistics\", Princeton University Press, Princeton. \n",
        "\n",
        "\\[15\\] C. R. Rao (1945) \"Information and the accuracy attainable in the estimation of statistical parameters\", Bull. Calcutta Math. Soc.37, 81-91.\n",
        "\n",
        "\\[16\\] S. S. Wilks (1938) \"The Large-Sample Distribution of the Likelihood Ratio for Testing Composite Hypotheses\", Annals of Mathematical Statististics 9(1): 60-62. DOI: 10.1214/aoms/1177732360\n",
        "\n",
        "\\[17\\] Shun-ichi Amari, Hiroshi Nagaoka (2000), \"Translations of Mathematical Monographs: Methods of Information Geometry\", American Mathematical Society, Oxford University Press, Volume 191.\n",
        "\n",
        "\\[18\\] Vijay Konda, John Tsitsiklis (1999), \"Actor-Critic Algorithms\", NIPS 12."
      ],
      "metadata": {
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Appendix A: Limited-Memory Lanczos algorithm \n",
        "\n",
        "Production-quality deep learning models will have intractably-large Fisher Information matrices.\n",
        "For a model with $p$ parameters, $\\mathcal{I}$ has $O(p^2)$ values.\n",
        "To overcome this, we'll use low rank approximation $LL^T + \\Lambda \\approx \\mathcal{I}$, \n",
        "$L \\in \\mathbb{R}^{p \\times r}$ and $\\Lambda \\in \\text{diag}(\\mathbb{R}_{\\geq 0}^{p \\times p})$, \n",
        "with $r$ significantly smaller than $p$. \n",
        "To estimate the $LL^T$ part, \n",
        "I've modified a Krylov method \\[3\\] to provide algorithmically-efficient updates to our approximation. \n",
        "We may justify our approximation through a combination of \n",
        "supporting experimental evidence in our robitics experiment \n",
        "and theory arguing only for a sharp drop-off of eigenvalues. \\[5\\].\n",
        "\n",
        "Unfortunately, we cannot use pre-existing software, \n",
        "because most eigenpair algorithms are designed to have all of $\\mathcal{I}$ as input.\n",
        "Since $\\mathcal{I}$ will not fit in memory, we have a challenge. \n",
        "Our only advantage is that we observe gradients $G_i \\sim_{idd} N_p(0, \\mathcal{I} )$. \n",
        "Fortunately, the _Lanczos algorithm_ \\[4\\] only requires we calculate $\\mathcal{I}v$, not that we actually store $\\mathcal{I}$. \n",
        "\n",
        "**Limited-Memory Lanczos Algorithm**\n",
        "\n",
        "The Lanczos algorithm is a _Krylov_ method, built around _Krylov subspace_ $\\text{span}\\left\\{ \\mathcal{I}v, \\mathcal{I}^2v, \\ldots, \\mathcal{I}^rv \\right\\}$.\n",
        "\n",
        "The key observation is this: we can calculate the _Krylov vectors_ $\\mathcal{I}v, \\mathcal{I}^2v, \\ldots, \\mathcal{I}^rv$ with computational \n",
        "efficiency when using estimate $ \\hat{\\mathcal{I}}  = n^{-1}\\sum_i^n G_i G_i^T$. With $G_i$ and $v$ in $\\mathbb{R}^{p \\times 1}$, \n",
        "we can expand recursively as follows.\n",
        "\n",
        "$$ \\hat{\\mathcal{I}}^m v = \\hat{\\mathcal{I}}^{m-1} \\left( \\sum_i^n G_i G_i^T \\right) v = \\hat{\\mathcal{I}}^{m-1} \\left( \\sum_i^n G_i G_i^Tv \\right) $$\n",
        "\n",
        "Notice how we now work with $O(nr)$ $O(p)$-time operations (totalling $O(nrp)$-time) and no $O(p^2)$-space operations. \n",
        "This is all possible because we only ever work with vector-vector operations, matrices are never used in forming the Krylov vectors. \n",
        "So, we should enjoy computational feasibility, if $nr$ is significantly smaller than $p^2$, which is expected in a deep learning context. "
      ],
      "metadata": {
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      }
    }
  ],
  "metadata": {
    "kernelspec": {
      "name": "python310-sdkv2",
      "language": "python",
      "display_name": "Python 3.10 - SDK V2"
    },
    "language_info": {
      "name": "python",
      "version": "3.10.6",
      "mimetype": "text/x-python",
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "pygments_lexer": "ipython3",
      "nbconvert_exporter": "python",
      "file_extension": ".py"
    },
    "microsoft": {
      "ms_spell_check": {
        "ms_spell_check_language": "en"
      }
    },
    "kernel_info": {
      "name": "python310-sdkv2"
    },
    "nteract": {
      "version": "nteract-front-end@1.0.0"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 2
}