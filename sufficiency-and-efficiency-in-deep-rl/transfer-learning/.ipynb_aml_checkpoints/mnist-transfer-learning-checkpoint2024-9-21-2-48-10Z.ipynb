{
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# Optimal transfer learning\n\nHere, we create two models and traverse a path on the statistical manifold between them.\nGiven my theory's optimal infinitesimal traversals of continuously changing distributions, \nthe theory should port cleanly from reinforcement learning to transfer learning. \nOf course, only each infinitesimal step along the path with be optimal, \nleaving room for data scientists' intuition to usefully bias retention. \nFor example, if early game information only becomes useful late in play, \nthen a retention spike will need to be added. \nRegardless, infinitesimal optimality is an important step toward a deep and coherent transfer learning theory. \n\nThe experiment will involve fitting a dense net to the MNIST dataset, classifying digits as usual. \nHowever, after the initial fit, we will embed the dense net into a much larger statistical manifold \nby making it part of a mixture model with a different, far more sparse model. \nWe'll then slowly and continuously traverse the mixture probability parameter $q$ from 0 to 1, \noptimally retaining information at each step. \nWe'll measure test set accuracy at each step and compare against different traversal strategies. \nA good result should find accuracy is optimally and usefully sustained despite transferring to a sparse model.\n\nIf successful, this experiment will illustrate the effectiveness of my general theory of transfer learning. \nThus, it'd be possible to optimally translate information optimally between arbitrary models, \nprovided they can handle the same dataset or a continuously transforming dataset between the models.\nThis is a powerful result, so I'm eager to run my experiment, but won't get my hopes up too much. \nThe truth is best found by the pursuit of ambitious targets and sensitively understanding negative results."
      ],
      "metadata": {
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "## Dense net code initially authored by Google's search engine GenAI on 20 Oct 2024. \n",
        "## I've applied minor modifications for generality, but the code worked great on first draft. \n",
        "\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "from torchvision import datasets, transforms\n",
        "\n",
        "# Define the DenseNet model\n",
        "class DenseNet(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(DenseNet, self).__init__()\n",
        "        self.features = nn.Sequential(\n",
        "            nn.Linear(784, 512),\n",
        "            nn.ReLU(),\n",
        "            nn.Linear(512, 256),\n",
        "            nn.ReLU(),\n",
        "            nn.Linear(256, 128),\n",
        "            nn.ReLU(),\n",
        "            nn.Linear(128, 10)\n",
        "        )\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = x.view(x.size(0), -1)\n",
        "        x = self.features(x)\n",
        "        return x\n",
        "\n",
        "# Load MNIST dataset\n",
        "train_dataset = datasets.MNIST(root='/tmp/data', train=True, transform=transforms.ToTensor(), download=True)\n",
        "test_dataset = datasets.MNIST(root='/tmp/data', train=False, transform=transforms.ToTensor())\n",
        "\n",
        "train_loader = torch.utils.data.DataLoader(train_dataset, batch_size=64, shuffle=True)\n",
        "test_loader = torch.utils.data.DataLoader(test_dataset, batch_size=64, shuffle=False)\n",
        "\n",
        "# Initialize the model, loss function and optimizer\n",
        "model = DenseNet()\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "optimizer = optim.Adam(model.parameters(), lr=0.001)\n",
        "\n",
        "# Train the model\n",
        "num_epochs = 5\n",
        "for epoch in range(num_epochs):\n",
        "    for i, (data, target) in enumerate(train_loader):\n",
        "        optimizer.zero_grad()\n",
        "        output = model(data)\n",
        "        loss = criterion(output, target)\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "        if i % 100 == 0:\n",
        "            print('Epoch [{}/{}], Step [{}/{}], Loss: {:.4f}'.format(epoch+1, num_epochs, i+1, len(train_loader), loss.item()))\n",
        "\n",
        "# Evaluate the model\n",
        "model.eval()\n",
        "correct = 0\n",
        "total = 0\n",
        "with torch.no_grad():\n",
        "    for data, target in test_loader:\n",
        "        output = model(data)\n",
        "        _, predicted = torch.max(output.data, 1)\n",
        "        total += target.size(0)\n",
        "        correct += (predicted == target).sum().item()\n",
        "\n",
        "print('Accuracy of the network on the 10000 test images: {} %'.format(100 * correct / total))"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": "/anaconda/envs/azureml_py38/lib/python3.8/site-packages/torch/autograd/graph.py:769: UserWarning: CUDA initialization: The NVIDIA driver on your system is too old (found version 11040). Please update your GPU driver by downloading and installing a new version from the URL: http://www.nvidia.com/Download/index.aspx Alternatively, go to: https://pytorch.org to install a PyTorch version that has been compiled with your version of the CUDA driver. (Triggered internally at ../c10/cuda/CUDAFunctions.cpp:108.)\n  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n"
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": "Epoch [1/5], Step [1/938], Loss: 2.2946\nEpoch [1/5], Step [101/938], Loss: 0.3633\nEpoch [1/5], Step [201/938], Loss: 0.1715\nEpoch [1/5], Step [301/938], Loss: 0.2084\nEpoch [1/5], Step [401/938], Loss: 0.3679\nEpoch [1/5], Step [501/938], Loss: 0.2522\nEpoch [1/5], Step [601/938], Loss: 0.1443\nEpoch [1/5], Step [701/938], Loss: 0.1262\nEpoch [1/5], Step [801/938], Loss: 0.1290\nEpoch [1/5], Step [901/938], Loss: 0.1676\nEpoch [2/5], Step [1/938], Loss: 0.0586\nEpoch [2/5], Step [101/938], Loss: 0.1659\nEpoch [2/5], Step [201/938], Loss: 0.0710\nEpoch [2/5], Step [301/938], Loss: 0.1123\nEpoch [2/5], Step [401/938], Loss: 0.0921\nEpoch [2/5], Step [501/938], Loss: 0.0941\nEpoch [2/5], Step [601/938], Loss: 0.1603\nEpoch [2/5], Step [701/938], Loss: 0.0231\nEpoch [2/5], Step [801/938], Loss: 0.0420\nEpoch [2/5], Step [901/938], Loss: 0.1315\nEpoch [3/5], Step [1/938], Loss: 0.0339\nEpoch [3/5], Step [101/938], Loss: 0.0512\nEpoch [3/5], Step [201/938], Loss: 0.0050\nEpoch [3/5], Step [301/938], Loss: 0.0695\nEpoch [3/5], Step [401/938], Loss: 0.0071\nEpoch [3/5], Step [501/938], Loss: 0.0424\nEpoch [3/5], Step [601/938], Loss: 0.0967\nEpoch [3/5], Step [701/938], Loss: 0.0176\nEpoch [3/5], Step [801/938], Loss: 0.2357\nEpoch [3/5], Step [901/938], Loss: 0.0463\nEpoch [4/5], Step [1/938], Loss: 0.0990\nEpoch [4/5], Step [101/938], Loss: 0.0078\nEpoch [4/5], Step [201/938], Loss: 0.1075\nEpoch [4/5], Step [301/938], Loss: 0.0852\nEpoch [4/5], Step [401/938], Loss: 0.0207\nEpoch [4/5], Step [501/938], Loss: 0.0084\nEpoch [4/5], Step [601/938], Loss: 0.0404\nEpoch [4/5], Step [701/938], Loss: 0.0086\nEpoch [4/5], Step [801/938], Loss: 0.0344\nEpoch [4/5], Step [901/938], Loss: 0.0529\nEpoch [5/5], Step [1/938], Loss: 0.0108\nEpoch [5/5], Step [101/938], Loss: 0.0223\nEpoch [5/5], Step [201/938], Loss: 0.0454\nEpoch [5/5], Step [301/938], Loss: 0.0389\nEpoch [5/5], Step [401/938], Loss: 0.0446\nEpoch [5/5], Step [501/938], Loss: 0.0045\nEpoch [5/5], Step [601/938], Loss: 0.0552\nEpoch [5/5], Step [701/938], Loss: 0.0083\nEpoch [5/5], Step [801/938], Loss: 0.0040\nEpoch [5/5], Step [901/938], Loss: 0.1019\nAccuracy of the network on the 10000 test images: 97.76 %\n"
        }
      ],
      "execution_count": 1,
      "metadata": {
        "gather": {
          "logged": 1729478608345
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "## Models for transfer learning to sparse nets \n",
        "from ssr_agent import SSRAgent \n",
        "from replay_buffer import ReplayBuffer \n",
        "\n",
        "class SparseActivation(nn.Module): \n",
        "    '''Softmax that zeros-out small values. \n",
        "    Transfer-learning from a prefit model recommended. \n",
        "    '''\n",
        "    def __init__(self, K=1, next_linearity=None):\n",
        "        'K: determines maximum number of non-zero dimensions.'\n",
        "        super(SparseActivation, self).__init__()\n",
        "        self.K = K \n",
        "        self.softmax = nn.Softmax(dim=1) \n",
        "        self.next_linearity = next_linearity \n",
        "        pass \n",
        "    def forward(self, x, next_linearity=None): \n",
        "        '''inputs:\n",
        "        - x: [n, ...]-shaped tensor \n",
        "        - next_linearity: instance of nn.Linear is applied efficiently to output of this activation. Autodetects next_nonlinearity if it was provided during init. \n",
        "        ouputs: \n",
        "        - idx: indicies of softmax(x) that are greater than 1/K. \n",
        "        - softmax(x)[idx]: values of softmax(x) that are greater than 1/K. Returns None if idx is empty. \n",
        "        '''\n",
        "        ## calculate \n",
        "        x = self.softmax(x) \n",
        "        idx = (x > 1/self.K).nonzero() \n",
        "        x_idx = None \n",
        "        if int(idx.shape[0]) > 0: \n",
        "            x_idx = x[idx] \n",
        "        if next_linearity is None and self.next_linearity is None: \n",
        "            return idx, x_idx \n",
        "        if next_linearity is None and self.next_linearity is not None: \n",
        "            next_linearity = self.next_linearity \n",
        "            pass \n",
        "        ## sparsely apply next_linearity \n",
        "        if int(idx.shape[0]) > 0: \n",
        "            y = x_idx.matmul(next_linearity.weights[idx,:]) \n",
        "        else: \n",
        "            y = 0. \n",
        "            pass \n",
        "        y += next_linearity.bias \n",
        "        return idx, x_idx, y \n",
        "    pass \n",
        "\n",
        "class SparseNet(nn.Module): \n",
        "    def __init__(self, K=10): \n",
        "        super(SparseNet, self).__init__() \n",
        "        self.K = K \n",
        "        self.linear1 = nn.Linear(784, 512) \n",
        "        self.linear2 = nn.Linear(512, 256) \n",
        "        self.linear3 = nn.Linear(256, 128) \n",
        "        self.linear4 = nn.Linear(128, 10) \n",
        "        self.activation1 = SparseActivation(K=self.K, next_linearity=self.linear2) \n",
        "        self.activation2 = SparseActivation(K=self.K, next_linearity=self.linear3) \n",
        "        self.activation3 = SparseActivation(K=self.K, next_linearity=self.linear4) \n",
        "        self.activation4 = nn.Softmax(dim=1) \n",
        "        pass \n",
        "    def forward(self, x): \n",
        "        x = self.activation1(self.linear1(x)) \n",
        "        x = self.activation2(self.linear2(x)) \n",
        "        x = self.activation3(self.linear3(x)) \n",
        "        x = self.activation4(self.linear4(x)) \n",
        "        return x\n",
        "\n",
        "class MixtureModel(nn.Module): \n",
        "    'join two models with a Bernoulli random variable'\n",
        "    def __init__(self, model1, model2, p): \n",
        "        'mix models 1 and 2, selecting model 2 with probability p'\n",
        "        super(MixtureModel, self).__init__() \n",
        "        self.model1 = model1 \n",
        "        self.model2 = model2 \n",
        "        self.p = p \n",
        "        pass \n",
        "    def forward(self, x): \n",
        "        n = x.shape[0] \n",
        "        b = torch.rand(n) >= self.p \n",
        "        b_sum = b.sum() \n",
        "        y = torch.zeros([n,1]) \n",
        "        if b_sum < n: \n",
        "            y[b.logical_not()] = self.model1(x[b.logical_not(),:]) \n",
        "        if b_sum > 0: \n",
        "            y[b] = self.model2(x[b,:]) \n",
        "            pass \n",
        "        return y \n",
        "    pass \n",
        "\n",
        "class Model(SSRAgent): \n",
        "    'Run transfer learning experiments with this model' \n",
        "    def __init__(self, p, K=10, ssr_rank=5): \n",
        "        'p: probability of the mixture model selecting the sparse model' \n",
        "        super(Model, self).__init__(replay_buffer=ReplayBuffer(), ssr_rank=ssr_rank) \n",
        "        self.mixture_model = MixtureModel( \n",
        "            model1 = DenseNet(), \n",
        "            model2 = SparseNet(K=K), \n",
        "            p=p \n",
        "        ) \n",
        "        self.criterion = nn.CrossEntropyLoss() \n",
        "        self.optimizer = optim.Adam(self.parameters(), lr=0.001) \n",
        "        pass \n",
        "    def loss(self, data): \n",
        "        y_hat = self.mixture_model(data.x) \n",
        "        return self.criterion(y_hat, data.y) \n",
        "    def fit_iters(self, n_iters=100, batch_size=256, pi_max=.9): \n",
        "        model.train() \n",
        "        pi = model.optimal_lambda(pi_max=pi_max) \n",
        "        for _ in range(n_iters): \n",
        "            self.optimizer.zero_grad() \n",
        "            data = self.replay_buffer.sample(256) \n",
        "            loss = pi * self.loss(data) + (1 - pi) * self.ssr() \n",
        "            loss.backward() \n",
        "            optimizer.step() \n",
        "            pass \n",
        "        return pi  \n",
        "    def eval(self): \n",
        "        self.eval()\n",
        "        correct = 0\n",
        "        total = 0\n",
        "        with torch.no_grad():\n",
        "            for x, y in test_loader:\n",
        "                output = self(x)\n",
        "                _, y_hat = torch.max(output.data, 1)\n",
        "                total += y.size(0)\n",
        "                correct += (y_hat == y).sum().item() \n",
        "                pass \n",
        "            pass \n",
        "        return correct / total \n",
        "    pass \n"
      ],
      "outputs": [],
      "execution_count": 4,
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "gather": {
          "logged": 1729478711399
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "## heavier compute starts here \n",
        "from tqdm import tqdm \n",
        "\n",
        "N = 100 ## number of path steps over p \n",
        "\n",
        "model = Model(p=0.) \n",
        "\n",
        "## load data \n",
        "for x, y in train_loader: \n",
        "    model.replay_buffer.add(x=x, y=y) \n",
        "    pass \n",
        "\n",
        "## traverse p \n",
        "acc = [] \n",
        "pi = [] \n",
        "tq = tqdm(range(N+1)) \n",
        "for i in tq: \n",
        "    model.p = i/N \n",
        "    n_iters = 100 if i == 0 else 10 \n",
        "    p = model.fit_iters(n_iters=n_iters) \n",
        "    a = model.eval() \n",
        "    acc.append(a) \n",
        "    pi.append(p) \n",
        "    tq.set_description(f'acc: {round(a,3)}, pi: {round(p, 3)}') \n",
        "    pass "
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": "\r  0%|          | 0/101 [00:00<?, ?it/s]\r  0%|          | 0/101 [00:00<?, ?it/s]\n"
        },
        {
          "output_type": "error",
          "ename": "RuntimeError",
          "evalue": "mat1 and mat2 shapes cannot be multiplied (7168x28 and 784x512)",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
            "Cell \u001b[0;32mIn [5], line 20\u001b[0m\n\u001b[1;32m     18\u001b[0m model\u001b[38;5;241m.\u001b[39mp \u001b[38;5;241m=\u001b[39m i\u001b[38;5;241m/\u001b[39mN \n\u001b[1;32m     19\u001b[0m n_iters \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m100\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m i \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m0\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;241m10\u001b[39m \n\u001b[0;32m---> 20\u001b[0m p \u001b[38;5;241m=\u001b[39m \u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit_iters\u001b[49m\u001b[43m(\u001b[49m\u001b[43mn_iters\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mn_iters\u001b[49m\u001b[43m)\u001b[49m \n\u001b[1;32m     21\u001b[0m a \u001b[38;5;241m=\u001b[39m model\u001b[38;5;241m.\u001b[39meval() \n\u001b[1;32m     22\u001b[0m acc\u001b[38;5;241m.\u001b[39mappend(a) \n",
            "Cell \u001b[0;32mIn [4], line 109\u001b[0m, in \u001b[0;36mModel.fit_iters\u001b[0;34m(self, n_iters, batch_size, pi_max)\u001b[0m\n\u001b[1;32m    107\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39moptimizer\u001b[38;5;241m.\u001b[39mzero_grad() \n\u001b[1;32m    108\u001b[0m data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mreplay_buffer\u001b[38;5;241m.\u001b[39msample(\u001b[38;5;241m256\u001b[39m) \n\u001b[0;32m--> 109\u001b[0m loss \u001b[38;5;241m=\u001b[39m pi \u001b[38;5;241m*\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mloss\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdata\u001b[49m\u001b[43m)\u001b[49m \u001b[38;5;241m+\u001b[39m (\u001b[38;5;241m1\u001b[39m \u001b[38;5;241m-\u001b[39m pi) \u001b[38;5;241m*\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mssr() \n\u001b[1;32m    110\u001b[0m loss\u001b[38;5;241m.\u001b[39mbackward() \n\u001b[1;32m    111\u001b[0m optimizer\u001b[38;5;241m.\u001b[39mstep() \n",
            "Cell \u001b[0;32mIn [4], line 101\u001b[0m, in \u001b[0;36mModel.loss\u001b[0;34m(self, data)\u001b[0m\n\u001b[1;32m    100\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mloss\u001b[39m(\u001b[38;5;28mself\u001b[39m, data): \n\u001b[0;32m--> 101\u001b[0m     y_hat \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmixture_model\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdata\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mx\u001b[49m\u001b[43m)\u001b[49m \n\u001b[1;32m    102\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcriterion(y_hat, data\u001b[38;5;241m.\u001b[39my)\n",
            "File \u001b[0;32m/anaconda/envs/azureml_py38/lib/python3.8/site-packages/torch/nn/modules/module.py:1553\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1551\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1552\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1553\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
            "File \u001b[0;32m/anaconda/envs/azureml_py38/lib/python3.8/site-packages/torch/nn/modules/module.py:1562\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1557\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1558\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1559\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1560\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1561\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1562\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1564\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m   1565\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
            "Cell \u001b[0;32mIn [4], line 82\u001b[0m, in \u001b[0;36mMixtureModel.forward\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m     80\u001b[0m     y[b\u001b[38;5;241m.\u001b[39mlogical_not()] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmodel1(x[b\u001b[38;5;241m.\u001b[39mlogical_not(),:]) \n\u001b[1;32m     81\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m b_sum \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m0\u001b[39m: \n\u001b[0;32m---> 82\u001b[0m     y[b] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmodel2\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m[\u001b[49m\u001b[43mb\u001b[49m\u001b[43m,\u001b[49m\u001b[43m:\u001b[49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m \n\u001b[1;32m     83\u001b[0m     \u001b[38;5;28;01mpass\u001b[39;00m \n\u001b[1;32m     84\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m y\n",
            "File \u001b[0;32m/anaconda/envs/azureml_py38/lib/python3.8/site-packages/torch/nn/modules/module.py:1553\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1551\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1552\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1553\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
            "File \u001b[0;32m/anaconda/envs/azureml_py38/lib/python3.8/site-packages/torch/nn/modules/module.py:1562\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1557\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1558\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1559\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1560\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1561\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1562\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1564\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m   1565\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
            "Cell \u001b[0;32mIn [4], line 59\u001b[0m, in \u001b[0;36mSparseNet.forward\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m     58\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, x): \n\u001b[0;32m---> 59\u001b[0m     x \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mactivation1(\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mlinear1\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m)\u001b[49m) \n\u001b[1;32m     60\u001b[0m     x \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mactivation2(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mlinear2(x)) \n\u001b[1;32m     61\u001b[0m     x \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mactivation3(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mlinear3(x)) \n",
            "File \u001b[0;32m/anaconda/envs/azureml_py38/lib/python3.8/site-packages/torch/nn/modules/module.py:1553\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1551\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1552\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1553\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
            "File \u001b[0;32m/anaconda/envs/azureml_py38/lib/python3.8/site-packages/torch/nn/modules/module.py:1562\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1557\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1558\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1559\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1560\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1561\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1562\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1564\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m   1565\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
            "File \u001b[0;32m/anaconda/envs/azureml_py38/lib/python3.8/site-packages/torch/nn/modules/linear.py:117\u001b[0m, in \u001b[0;36mLinear.forward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    116\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;28minput\u001b[39m: Tensor) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Tensor:\n\u001b[0;32m--> 117\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mF\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mlinear\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mweight\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbias\u001b[49m\u001b[43m)\u001b[49m\n",
            "\u001b[0;31mRuntimeError\u001b[0m: mat1 and mat2 shapes cannot be multiplied (7168x28 and 784x512)"
          ]
        }
      ],
      "execution_count": 5,
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "gather": {
          "logged": 1729478752846
        }
      }
    }
  ],
  "metadata": {
    "kernelspec": {
      "name": "python3",
      "language": "python",
      "display_name": "Python 3 (ipykernel)"
    },
    "language_info": {
      "name": "python",
      "version": "3.8.5",
      "mimetype": "text/x-python",
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "pygments_lexer": "ipython3",
      "nbconvert_exporter": "python",
      "file_extension": ".py"
    },
    "microsoft": {
      "ms_spell_check": {
        "ms_spell_check_language": "en"
      },
      "host": {
        "AzureML": {
          "notebookHasBeenCompleted": true
        }
      }
    },
    "nteract": {
      "version": "nteract-front-end@1.0.0"
    },
    "kernel_info": {
      "name": "python3"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 2
}